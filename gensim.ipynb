{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import re\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix, WordEmbeddingSimilarityIndex\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "from googletrans import Translator\n",
    "\n",
    "from FlaskApp.transform import *\n",
    "\n",
    "from job_model import JobModel\n",
    "from app_model import AppModel\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(stopwords, texts):\n",
    "    split_text = texts.split()\n",
    "    clean_text = []\n",
    "    for text in split_text:\n",
    "        if text not in stopwords:\n",
    "            clean_text.append(text)\n",
    "    return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'huda'\n",
    "password = 'Vancha12'\n",
    "host = '127.0.0.1'\n",
    "port = 1433\n",
    "database = 'HRSystemDB'\n",
    "\n",
    "\n",
    "def get_connection():         \n",
    "    return create_engine(\n",
    "        url=f\"mssql+pyodbc://{user}:{password}@{host}:{port}/{database}?driver=SQL Server\",\n",
    "    )\n",
    "\n",
    "engine = get_connection()\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT Job.JobID, Job.UsiaMax, Job.SalaryMin, Job.SalaryMax, City.Name AS CityName, Province.Name AS ProvinceName, EducationLevel.EducationLevelName, Major.MajorName, Job.DriverLicenseType, Job.UsingGlasses, Job.Gender, Job.MaritalStatus, Job.JobTitle, FunctionPosition.FunctionPositionName, Job.Description, Job.Requirement\n",
    "    FROM (((((Job\n",
    "    RIGHT JOIN FunctionPosition ON Job.FunctionPositionID = FunctionPosition.FunctionPositionID)\n",
    "    RIGHT JOIN EducationLevel ON Job.EducationLevelID = EducationLevel.EducationLevelID)\n",
    "    RIGHT JOIN City ON Job.CityID = City.CityID)\n",
    "    RIGHT JOIN Province ON Job.ProvinceID = Province.ProvinceID)\n",
    "    RIGHT JOIN Major ON Job.MajorID = Major.MajorID)\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_function = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT FunctionPositionID, FunctionPositionName\n",
    "    FROM FunctionPosition\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_education = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT EducationLevelID, EducationLevelName\n",
    "    FROM EducationLevel\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_city = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT CityID, Name AS CityName\n",
    "    FROM City\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_province = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT ProvinceID, Name AS ProvinceName\n",
    "    FROM Province\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_major = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT MajorID, MajorName\n",
    "    FROM Major\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT Applicant.ApplicantID, Applicant.Dob, Applicant.ExpectedSalary, City.Name AS CityName, Province.Name AS ProvinceName, Applicant.DriverLicenseType, Applicant.IsUsingGlasses, Applicant.Gender, Applicant.MaritalStatus, Applicant.Strengthness\n",
    "    FROM (((Applicant\n",
    "    RIGHT JOIN City ON Applicant.CurrentAddressCityID = City.CityID)\n",
    "    RIGHT JOIN Province ON Applicant.CurrentAddressProvinceID = Province.ProvinceID)\n",
    "    LEFT JOIN Pipeline ON Applicant.ApplicantID = Pipeline.ApplicantID)\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant_education = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT ApplicantEducation.ApplicantID, ApplicantEducation.DateStart, ApplicantEducation.DateEnd, EducationLevel.EducationLevelName, Major.MajorName\n",
    "    FROM (((ApplicantEducation\n",
    "    RIGHT JOIN EducationLevel ON ApplicantEducation.EducationLevelID = EducationLevel.EducationLevelID)\n",
    "    RIGHT JOIN Major ON ApplicantEducation.MajorID = Major.MajorID)\n",
    "    LEFT JOIN Pipeline ON ApplicantEducation.ApplicantID = Pipeline.ApplicantID)\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant_experience = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT ApplicantExperience.ApplicantID, ApplicantExperience.DateFrom, ApplicantExperience.DateTo, ApplicantExperience.Position, ApplicantExperience.JobDescription\n",
    "    FROM (ApplicantExperience\n",
    "    LEFT JOIN Pipeline ON ApplicantExperience.ApplicantID = Pipeline.ApplicantID)\n",
    "    \"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save json'''\n",
    "# with open('data/englishwords.json', 'w') as file:\n",
    "#     json.dump(englishwords, file)\n",
    "\n",
    "# with open('data/slangwords.json', 'w') as file:\n",
    "#     json.dump(slangwords, file)\n",
    "\n",
    "'''load json'''\n",
    "with open('data/englishwords.json', 'r') as file:\n",
    "    englishwords = json.load(file)\n",
    "\n",
    "with open('data/slangwords.json', 'r') as file:\n",
    "    slangwords = json.load(file)\n",
    "\n",
    "'''load csv'''\n",
    "stopwords = [i[0] for i in pd.read_csv('data/stopwords.csv').astype(str).values] + ['dst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pendekatan baru: tokenizing kemudian ditranslate satu-satu dan di cek satu-satu terhadap kata yang gagal di translate kemudian membuat set dari hasil translate token tesebut\n",
    "# description_corpus = []\n",
    "# for token in df_job.Description.values:\n",
    "#     description_corpus.append(token)\n",
    "# else:\n",
    "    \n",
    "#     description_corpus = set(description_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantID</th>\n",
       "      <th>Dob</th>\n",
       "      <th>ExpectedSalary</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ProvinceName</th>\n",
       "      <th>DriverLicenseType</th>\n",
       "      <th>IsUsingGlasses</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Strengthness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-04-10 00:00:00.0000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SURABAYA</td>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>None</td>\n",
       "      <td>strength</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantID                          Dob  ExpectedSalary  CityName  \\\n",
       "0          2.0  2018-04-10 00:00:00.0000000             0.0  SURABAYA   \n",
       "\n",
       "  ProvinceName DriverLicenseType IsUsingGlasses Gender MaritalStatus  \\\n",
       "0   JAWA TIMUR                 A          False   Male          None   \n",
       "\n",
       "  Strengthness  \n",
       "0     strength  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''applicant'''\n",
    "df_applicant = df_applicant.dropna(subset=['ApplicantID'])\n",
    "df_applicant.ApplicantID = df_applicant.ApplicantID.astype(int)\n",
    "df_applicant = df_applicant.drop_duplicates()\n",
    "df_applicant = df_applicant.fillna('')\n",
    "# age column\n",
    "df_applicant['Age'] = pd.to_datetime(\n",
    "    df_applicant.Dob.map(pick_date).apply(lambda x: filter_date(x, 1958, 2006))\n",
    ").map(get_age)\n",
    "\n",
    "df_applicant.drop(columns=['Dob'], inplace=True)\n",
    "\n",
    "df_applicant.Age = df_applicant.Age.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantID</th>\n",
       "      <th>DateStart</th>\n",
       "      <th>DateEnd</th>\n",
       "      <th>EducationLevelName</th>\n",
       "      <th>MajorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-07-01 00:00:00.0000000</td>\n",
       "      <td>2016-01-01 00:00:00.0000000</td>\n",
       "      <td>S1</td>\n",
       "      <td>SEMUA JURUSAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantID                    DateStart                      DateEnd  \\\n",
       "0            3  2011-07-01 00:00:00.0000000  2016-01-01 00:00:00.0000000   \n",
       "\n",
       "  EducationLevelName      MajorName  \n",
       "0                 S1  SEMUA JURUSAN  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant_education.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''education'''\n",
    "df_applicant_education = df_applicant_education.fillna('')\n",
    "# datetime column\n",
    "df_applicant_education.DateStart = pd.to_datetime(\n",
    "    df_applicant_education.DateStart.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_education.DateEnd = pd.to_datetime(\n",
    "    df_applicant_education.DateEnd.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_education = df_applicant_education[~(df_applicant_education.DateStart.isna()) & ~(df_applicant_education.DateEnd.isna())]\n",
    "df_applicant_education = df_applicant_education.sort_values('DateStart').groupby(['ApplicantID']).agg('last')\n",
    "df_applicant_education.drop(columns=['DateStart', 'DateEnd'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantID</th>\n",
       "      <th>DateFrom</th>\n",
       "      <th>DateTo</th>\n",
       "      <th>Position</th>\n",
       "      <th>JobDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-01 00:00:00.0000000</td>\n",
       "      <td>2017-04-01 00:00:00.0000000</td>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>&lt;p&gt;- Maintenance Dealer (cek stock dealer apak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantID                     DateFrom                       DateTo  \\\n",
       "0            3  2016-04-01 00:00:00.0000000  2017-04-01 00:00:00.0000000   \n",
       "\n",
       "          Position                                     JobDescription  \n",
       "0  Sales Executive  <p>- Maintenance Dealer (cek stock dealer apak...  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant_experience.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''experience'''\n",
    "df_applicant_experience = df_applicant_experience.fillna('')\n",
    "\n",
    "# datetime column\n",
    "df_applicant_experience.DateFrom = pd.to_datetime(\n",
    "    df_applicant_experience.DateFrom.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_experience.DateTo = pd.to_datetime(\n",
    "    df_applicant_experience.DateTo.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_experience = df_applicant_experience[~(df_applicant_experience.DateFrom.isna()) & ~(df_applicant_experience.DateTo.isna())]\n",
    "\n",
    "# add YearsOfExperience column\n",
    "df_applicant_experience['YearsOfExperience'] = substract_months(\n",
    "    df_applicant_experience.DateFrom, df_applicant_experience.DateTo\n",
    ")\n",
    "df_applicant_experience = df_applicant_experience.sort_values('DateFrom').groupby(['ApplicantID']).agg({\n",
    "    'DateFrom': 'last',\n",
    "    'DateTo': 'last',\n",
    "    'JobDescription': ' '.join,\n",
    "    'Position': ' '.join,\n",
    "    'YearsOfExperience': 'sum',\n",
    "})\n",
    "df_applicant_experience.drop(columns=['DateFrom', 'DateTo'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantID</th>\n",
       "      <th>ExpectedSalary</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ProvinceName</th>\n",
       "      <th>DriverLicenseType</th>\n",
       "      <th>IsUsingGlasses</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Strengthness</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SURABAYA</td>\n",
       "      <td>JAWA TIMUR</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td></td>\n",
       "      <td>strength</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantID  ExpectedSalary  CityName ProvinceName DriverLicenseType  \\\n",
       "0            2             0.0  SURABAYA   JAWA TIMUR                 A   \n",
       "\n",
       "   IsUsingGlasses Gender MaritalStatus Strengthness  Age  \n",
       "0           False   Male                   strength    0  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''merge'''\n",
    "df_applicant = pd.merge(df_applicant, df_applicant_experience, on=['ApplicantID'])\n",
    "df_applicant = pd.merge(df_applicant, df_applicant_education, on=['ApplicantID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eats\\miniconda3\\envs\\p1\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "'''PRE-PROCESSING APPLICANT'''\n",
    "df_applicant.set_index(['ApplicantID'], inplace=True)\n",
    "\n",
    "app_str = ['CityName', 'ProvinceName', 'EducationLevelName', 'MajorName', 'DriverLicenseType', 'Gender', 'MaritalStatus', 'Position', 'JobDescription', 'Strengthness']\n",
    "app_num = ['Age', 'ExpectedSalary', 'YearsOfExperience']\n",
    "app_bol = ['IsUsingGlasses']\n",
    "\n",
    "df_applicant = df_applicant[app_num + app_bol + app_str]\n",
    "\n",
    "'''str'''\n",
    "df_applicant[app_str] = df_applicant[app_str].applymap(str.lower)\n",
    "\n",
    "df_applicant.JobDescription = df_applicant.JobDescription.map(clean_text).map(maintain_alphabet).map(remove_single).map(remove_morespace)\n",
    "\n",
    "df_applicant.Strengthness = df_applicant.Strengthness.map(clean_text).map(maintain_alphabet).map(remove_single).map(remove_morespace)\n",
    "\n",
    "df_applicant.Position = df_applicant.Position\n",
    "df_applicant.MajorName = df_applicant.MajorName\n",
    "\n",
    "# concat\n",
    "df_applicant.JobDescription = df_applicant.JobDescription.str.cat(\n",
    "    df_applicant.Strengthness, sep=' '\n",
    ")\n",
    "df_applicant.rename(columns={'JobDescription': 'DescriptionStrengthness'}, inplace=True)\n",
    "df_applicant.drop(columns=['Strengthness'], inplace=True)\n",
    "\n",
    "'''bool'''\n",
    "df_applicant.IsUsingGlasses = df_applicant.IsUsingGlasses.astype(str).map(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UsiaMax                 0\n",
       "SalaryMin               0\n",
       "SalaryMax               0\n",
       "CityName                0\n",
       "ProvinceName            0\n",
       "EducationLevelName      0\n",
       "MajorName               0\n",
       "DriverLicenseType       0\n",
       "UsingGlasses            0\n",
       "Gender                  0\n",
       "MaritalStatus           0\n",
       "JobTitle                0\n",
       "FunctionPositionName    0\n",
       "Description             0\n",
       "Requirement             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_str = ['CityName', 'ProvinceName', 'EducationLevelName', 'MajorName', 'DriverLicenseType', 'Gender', 'MaritalStatus', 'JobTitle', 'FunctionPositionName', 'Description', 'Requirement']\n",
    "job_num = ['UsiaMax', 'SalaryMin', 'SalaryMax']\n",
    "job_bol = ['UsingGlasses']\n",
    "\n",
    "'''general'''\n",
    "df_job.set_index(['JobID'], inplace=True)\n",
    "df_job.fillna('', inplace=True)\n",
    "\n",
    "'''str'''\n",
    "df_job[job_str] = df_job[job_str].applymap(str.lower)\n",
    "df_job.replace('none', '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UsiaMax</th>\n",
       "      <th>SalaryMin</th>\n",
       "      <th>SalaryMax</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ProvinceName</th>\n",
       "      <th>EducationLevelName</th>\n",
       "      <th>MajorName</th>\n",
       "      <th>DriverLicenseType</th>\n",
       "      <th>UsingGlasses</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>JobTitle</th>\n",
       "      <th>FunctionPositionName</th>\n",
       "      <th>Description</th>\n",
       "      <th>Requirement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3300000.0</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>d3</td>\n",
       "      <td>perhotelan</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>night audit</td>\n",
       "      <td>night audit</td>\n",
       "      <td>under asst. front office manager at gunawangsa...</td>\n",
       "      <td>&lt;p&gt;\\r\\n\\r\\n&lt;/p&gt;&lt;div style=\"language:en-us;marg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UsiaMax  SalaryMin  SalaryMax  CityName ProvinceName EducationLevelName  \\\n",
       "JobID                                                                           \n",
       "1         0.0  3300000.0  3600000.0  surabaya   jawa timur                 d3   \n",
       "\n",
       "        MajorName DriverLicenseType UsingGlasses Gender MaritalStatus  \\\n",
       "JobID                                                                   \n",
       "1      perhotelan                          False                        \n",
       "\n",
       "          JobTitle FunctionPositionName  \\\n",
       "JobID                                     \n",
       "1      night audit          night audit   \n",
       "\n",
       "                                             Description  \\\n",
       "JobID                                                      \n",
       "1      under asst. front office manager at gunawangsa...   \n",
       "\n",
       "                                             Requirement  \n",
       "JobID                                                     \n",
       "1      <p>\\r\\n\\r\\n</p><div style=\"language:en-us;marg...  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PRE-PROCESSING JOB\"\"\"\n",
    "df_job.Description = df_job.Description.map(clean_text).map(maintain_alphabet).map(remove_single).map(remove_morespace)\n",
    "df_job.Requirement = df_job.Requirement.map(clean_text).map(maintain_alphabet).map(remove_single).map(remove_morespace)\n",
    "\n",
    "# concatenate JobTitle and FunctionPositionName to be textual feature together\n",
    "df_job.JobTitle = df_job.JobTitle.str.cat(\n",
    "    df_job.FunctionPositionName, sep=' '\n",
    ")\n",
    "df_job.rename(columns={'JobTitle': 'JobTitlePosition'}, inplace=True)\n",
    "df_job.drop(columns=['FunctionPositionName'], inplace=True)\n",
    "\n",
    "# concatenate Description and Requirement to be textual feature together\n",
    "df_job.Description = df_job.Description.str.cat(\n",
    "    df_job.Requirement, sep=' '\n",
    ")\n",
    "df_job.rename(columns={'Description': 'DescriptionRequirement'}, inplace=True)\n",
    "df_job.drop(columns=['Requirement'], inplace=True)\n",
    "\n",
    "df_job = df_job[~(df_job.DescriptionRequirement == ' ')]\n",
    "\n",
    "'''int'''\n",
    "df_job[job_num] = df_job[job_num].replace('', 0)\n",
    "df_job[job_num] = df_job[job_num].astype(int)\n",
    "\n",
    "# get mean from SalaryMin and SalaryMax\n",
    "df_job.SalaryMin = (df_job.SalaryMax + df_job.SalaryMin) // 2\n",
    "df_job.rename(columns={'SalaryMin': 'SalaryMean'}, inplace=True)\n",
    "df_job.SalaryMean = df_job.SalaryMean.apply(lambda x: 0 if x < 1_000_000 else x)\n",
    "df_job.drop(columns=['SalaryMax'], inplace=True)\n",
    "\n",
    "'''bool'''\n",
    "df_job.UsingGlasses = df_job.UsingGlasses.astype(str).map(str.lower)\n",
    "\n",
    "\n",
    "# load table for vocabulary\n",
    "df_function.FunctionPositionName = df_function.FunctionPositionName.map(str.lower).apply(lambda x: function_replacement(x)).map(remove_insideparentheses).map(remove_morespace).map(str.strip)\n",
    "df_education.EducationLevelName = df_education.EducationLevelName.map(str.lower)\n",
    "df_city.CityName = df_city.CityName.map(str.lower)\n",
    "df_province.ProvinceName = df_province.ProvinceName.map(str.lower)\n",
    "df_major.MajorName = df_major.MajorName.map(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UsiaMax</th>\n",
       "      <th>SalaryMean</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ProvinceName</th>\n",
       "      <th>EducationLevelName</th>\n",
       "      <th>MajorName</th>\n",
       "      <th>DriverLicenseType</th>\n",
       "      <th>UsingGlasses</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>JobTitlePosition</th>\n",
       "      <th>DescriptionRequirement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3450000</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>d3</td>\n",
       "      <td>perhotelan</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>night audit night audit</td>\n",
       "      <td>under asst front office manager at gunawangsa ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UsiaMax  SalaryMean  CityName ProvinceName EducationLevelName  \\\n",
       "JobID                                                                  \n",
       "1            0     3450000  surabaya   jawa timur                 d3   \n",
       "\n",
       "        MajorName DriverLicenseType UsingGlasses Gender MaritalStatus  \\\n",
       "JobID                                                                   \n",
       "1      perhotelan                          false                        \n",
       "\n",
       "              JobTitlePosition  \\\n",
       "JobID                            \n",
       "1      night audit night audit   \n",
       "\n",
       "                                  DescriptionRequirement  \n",
       "JobID                                                     \n",
       "1      under asst front office manager at gunawangsa ...  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job['Texts'] = df_job.JobTitlePosition + ' ' + df_job.DescriptionRequirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicant['Texts'] = df_applicant.Position + ' ' + df_applicant.DescriptionStrengthness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UsiaMax</th>\n",
       "      <th>SalaryMean</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ProvinceName</th>\n",
       "      <th>EducationLevelName</th>\n",
       "      <th>MajorName</th>\n",
       "      <th>DriverLicenseType</th>\n",
       "      <th>UsingGlasses</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>JobTitlePosition</th>\n",
       "      <th>DescriptionRequirement</th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3450000</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>d3</td>\n",
       "      <td>perhotelan</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>night audit night audit</td>\n",
       "      <td>under asst front office manager at gunawangsa ...</td>\n",
       "      <td>night audit night audit under asst front offic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UsiaMax  SalaryMean  CityName ProvinceName EducationLevelName  \\\n",
       "JobID                                                                  \n",
       "1            0     3450000  surabaya   jawa timur                 d3   \n",
       "\n",
       "        MajorName DriverLicenseType UsingGlasses Gender MaritalStatus  \\\n",
       "JobID                                                                   \n",
       "1      perhotelan                          false                        \n",
       "\n",
       "              JobTitlePosition  \\\n",
       "JobID                            \n",
       "1      night audit night audit   \n",
       "\n",
       "                                  DescriptionRequirement  \\\n",
       "JobID                                                      \n",
       "1      under asst front office manager at gunawangsa ...   \n",
       "\n",
       "                                                   Texts  \n",
       "JobID                                                     \n",
       "1      night audit night audit under asst front offic...  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ExpectedSalary</th>\n",
       "      <th>YearsOfExperience</th>\n",
       "      <th>IsUsingGlasses</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ProvinceName</th>\n",
       "      <th>EducationLevelName</th>\n",
       "      <th>MajorName</th>\n",
       "      <th>DriverLicenseType</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Position</th>\n",
       "      <th>DescriptionStrengthness</th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApplicantID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>false</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>s1</td>\n",
       "      <td>semua jurusan</td>\n",
       "      <td>c</td>\n",
       "      <td>male</td>\n",
       "      <td>single</td>\n",
       "      <td>sales executive whole sales credit marketing o...</td>\n",
       "      <td>maintenance dealer cek stock dealer apakah mas...</td>\n",
       "      <td>sales executive whole sales credit marketing o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age  ExpectedSalary  YearsOfExperience IsUsingGlasses  CityName  \\\n",
       "ApplicantID                                                                    \n",
       "3             29       4000000.0           1.833333          false  surabaya   \n",
       "\n",
       "            ProvinceName EducationLevelName      MajorName DriverLicenseType  \\\n",
       "ApplicantID                                                                    \n",
       "3             jawa timur                 s1  semua jurusan                 c   \n",
       "\n",
       "            Gender MaritalStatus  \\\n",
       "ApplicantID                        \n",
       "3             male        single   \n",
       "\n",
       "                                                      Position  \\\n",
       "ApplicantID                                                      \n",
       "3            sales executive whole sales credit marketing o...   \n",
       "\n",
       "                                       DescriptionStrengthness  \\\n",
       "ApplicantID                                                      \n",
       "3            maintenance dealer cek stock dealer apakah mas...   \n",
       "\n",
       "                                                         Texts  \n",
       "ApplicantID                                                     \n",
       "3            sales executive whole sales credit marketing o...  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "# get dataset\n",
    "# dataset = api.load(\"text8\")\n",
    "dataset = list(df_job.Texts.apply(lambda x: x.split()).values)\n",
    "data =[]\n",
    "for w in dataset:\n",
    "    data.append(w)\n",
    "\n",
    "# To train the model we need a list of tagged documents\n",
    "def tagged_document(list_of_ListOfWords):\n",
    "    for x, ListOfWords in enumerate(list_of_ListOfWords):\n",
    "        yield doc2vec.TaggedDocument(ListOfWords, [x])\n",
    "\n",
    "# training data\n",
    "data_train = list(tagged_document(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 10:38:48,628 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d120,n5,w5,mc10,s0.001,t3>', 'datetime': '2023-04-17T10:38:48.628419', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-17 10:38:48,628 : INFO : collecting all words and their counts\n",
      "2023-04-17 10:38:48,629 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-04-17 10:38:48,640 : INFO : collected 3703 word types and 1006 unique tags from a corpus of 1006 examples and 102767 words\n",
      "2023-04-17 10:38:48,640 : INFO : Creating a fresh vocabulary\n",
      "2023-04-17 10:38:48,647 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 1450 unique words (39.16% of original 3703, drops 2253)', 'datetime': '2023-04-17T10:38:48.647114', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-17 10:38:48,648 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 95427 word corpus (92.86% of original 102767, drops 7340)', 'datetime': '2023-04-17T10:38:48.648061', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-17 10:38:48,655 : INFO : deleting the raw counts dictionary of 3703 items\n",
      "2023-04-17 10:38:48,656 : INFO : sample=0.001 downsamples 61 most-common words\n",
      "2023-04-17 10:38:48,657 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 78026.46987472735 word corpus (81.8%% of prior 95427)', 'datetime': '2023-04-17T10:38:48.657037', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-17 10:38:48,666 : INFO : estimated required memory for 1450 words and 120 dimensions: 2801080 bytes\n",
      "2023-04-17 10:38:48,667 : INFO : resetting layer weights\n",
      "2023-04-17 10:38:48,669 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1450 vocabulary and 120 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-17T10:38:48.669004', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-17 10:38:48,733 : INFO : EPOCH 0: training on 102767 raw words (79027 effective words) took 0.1s, 1277022 effective words/s\n",
      "2023-04-17 10:38:48,793 : INFO : EPOCH 1: training on 102767 raw words (79006 effective words) took 0.1s, 1379189 effective words/s\n",
      "2023-04-17 10:38:48,841 : INFO : EPOCH 2: training on 102767 raw words (79083 effective words) took 0.1s, 1385178 effective words/s\n",
      "2023-04-17 10:38:48,911 : INFO : EPOCH 3: training on 102767 raw words (79016 effective words) took 0.1s, 1393305 effective words/s\n",
      "2023-04-17 10:38:48,970 : INFO : EPOCH 4: training on 102767 raw words (78994 effective words) took 0.1s, 1392414 effective words/s\n",
      "2023-04-17 10:38:49,030 : INFO : EPOCH 5: training on 102767 raw words (78875 effective words) took 0.1s, 1395240 effective words/s\n",
      "2023-04-17 10:38:49,080 : INFO : EPOCH 6: training on 102767 raw words (78948 effective words) took 0.1s, 1388490 effective words/s\n",
      "2023-04-17 10:38:49,149 : INFO : EPOCH 7: training on 102767 raw words (78919 effective words) took 0.1s, 1291533 effective words/s\n",
      "2023-04-17 10:38:49,215 : INFO : EPOCH 8: training on 102767 raw words (79093 effective words) took 0.1s, 1330985 effective words/s\n",
      "2023-04-17 10:38:49,283 : INFO : EPOCH 9: training on 102767 raw words (79001 effective words) took 0.1s, 1218172 effective words/s\n",
      "2023-04-17 10:38:49,350 : INFO : EPOCH 10: training on 102767 raw words (79102 effective words) took 0.1s, 1232134 effective words/s\n",
      "2023-04-17 10:38:49,408 : INFO : EPOCH 11: training on 102767 raw words (78830 effective words) took 0.1s, 1403148 effective words/s\n",
      "2023-04-17 10:38:49,455 : INFO : EPOCH 12: training on 102767 raw words (78931 effective words) took 0.1s, 1465803 effective words/s\n",
      "2023-04-17 10:38:49,523 : INFO : EPOCH 13: training on 102767 raw words (78992 effective words) took 0.1s, 1398697 effective words/s\n",
      "2023-04-17 10:38:49,579 : INFO : EPOCH 14: training on 102767 raw words (79100 effective words) took 0.1s, 1466066 effective words/s\n",
      "2023-04-17 10:38:49,626 : INFO : EPOCH 15: training on 102767 raw words (78872 effective words) took 0.1s, 1456060 effective words/s\n",
      "2023-04-17 10:38:49,695 : INFO : EPOCH 16: training on 102767 raw words (79129 effective words) took 0.1s, 1401170 effective words/s\n",
      "2023-04-17 10:38:49,754 : INFO : EPOCH 17: training on 102767 raw words (79030 effective words) took 0.1s, 1411240 effective words/s\n",
      "2023-04-17 10:38:49,813 : INFO : EPOCH 18: training on 102767 raw words (79072 effective words) took 0.1s, 1402655 effective words/s\n",
      "2023-04-17 10:38:49,864 : INFO : EPOCH 19: training on 102767 raw words (78951 effective words) took 0.1s, 1411271 effective words/s\n",
      "2023-04-17 10:38:49,929 : INFO : EPOCH 20: training on 102767 raw words (79048 effective words) took 0.1s, 1444683 effective words/s\n",
      "2023-04-17 10:38:49,987 : INFO : EPOCH 21: training on 102767 raw words (79112 effective words) took 0.1s, 1439447 effective words/s\n",
      "2023-04-17 10:38:50,031 : INFO : EPOCH 22: training on 102767 raw words (79106 effective words) took 0.1s, 1445352 effective words/s\n",
      "2023-04-17 10:38:50,098 : INFO : EPOCH 23: training on 102767 raw words (79034 effective words) took 0.1s, 1403143 effective words/s\n",
      "2023-04-17 10:38:50,162 : INFO : EPOCH 24: training on 102767 raw words (79080 effective words) took 0.1s, 1401360 effective words/s\n",
      "2023-04-17 10:38:50,220 : INFO : EPOCH 25: training on 102767 raw words (78975 effective words) took 0.1s, 1462343 effective words/s\n",
      "2023-04-17 10:38:50,267 : INFO : EPOCH 26: training on 102767 raw words (79000 effective words) took 0.1s, 1484162 effective words/s\n",
      "2023-04-17 10:38:50,334 : INFO : EPOCH 27: training on 102767 raw words (78977 effective words) took 0.1s, 1411501 effective words/s\n",
      "2023-04-17 10:38:50,390 : INFO : EPOCH 28: training on 102767 raw words (79072 effective words) took 0.1s, 1458374 effective words/s\n",
      "2023-04-17 10:38:50,437 : INFO : EPOCH 29: training on 102767 raw words (79195 effective words) took 0.1s, 1448079 effective words/s\n",
      "2023-04-17 10:38:50,503 : INFO : EPOCH 30: training on 102767 raw words (78995 effective words) took 0.1s, 1473103 effective words/s\n",
      "2023-04-17 10:38:50,560 : INFO : EPOCH 31: training on 102767 raw words (79117 effective words) took 0.1s, 1470287 effective words/s\n",
      "2023-04-17 10:38:50,604 : INFO : EPOCH 32: training on 102767 raw words (79113 effective words) took 0.1s, 1491997 effective words/s\n",
      "2023-04-17 10:38:50,673 : INFO : EPOCH 33: training on 102767 raw words (78999 effective words) took 0.1s, 1388688 effective words/s\n",
      "2023-04-17 10:38:50,730 : INFO : EPOCH 34: training on 102767 raw words (78904 effective words) took 0.1s, 1487629 effective words/s\n",
      "2023-04-17 10:38:50,773 : INFO : EPOCH 35: training on 102767 raw words (79227 effective words) took 0.1s, 1448990 effective words/s\n",
      "2023-04-17 10:38:50,846 : INFO : EPOCH 36: training on 102767 raw words (79038 effective words) took 0.1s, 1425217 effective words/s\n",
      "2023-04-17 10:38:50,906 : INFO : EPOCH 37: training on 102767 raw words (78918 effective words) took 0.1s, 1359966 effective words/s\n",
      "2023-04-17 10:38:50,959 : INFO : EPOCH 38: training on 102767 raw words (78985 effective words) took 0.1s, 1454542 effective words/s\n",
      "2023-04-17 10:38:51,021 : INFO : EPOCH 39: training on 102767 raw words (79026 effective words) took 0.1s, 1438406 effective words/s\n",
      "2023-04-17 10:38:51,077 : INFO : EPOCH 40: training on 102767 raw words (79052 effective words) took 0.1s, 1493878 effective words/s\n",
      "2023-04-17 10:38:51,125 : INFO : EPOCH 41: training on 102767 raw words (79021 effective words) took 0.1s, 1482109 effective words/s\n",
      "2023-04-17 10:38:51,209 : INFO : EPOCH 42: training on 102767 raw words (79027 effective words) took 0.1s, 1077890 effective words/s\n",
      "2023-04-17 10:38:51,273 : INFO : EPOCH 43: training on 102767 raw words (79066 effective words) took 0.1s, 1285551 effective words/s\n",
      "2023-04-17 10:38:51,318 : INFO : EPOCH 44: training on 102767 raw words (79015 effective words) took 0.1s, 1495714 effective words/s\n",
      "2023-04-17 10:38:51,384 : INFO : EPOCH 45: training on 102767 raw words (78914 effective words) took 0.1s, 1461947 effective words/s\n",
      "2023-04-17 10:38:51,440 : INFO : EPOCH 46: training on 102767 raw words (78895 effective words) took 0.1s, 1472817 effective words/s\n",
      "2023-04-17 10:38:51,485 : INFO : EPOCH 47: training on 102767 raw words (79108 effective words) took 0.1s, 1475637 effective words/s\n",
      "2023-04-17 10:38:51,553 : INFO : EPOCH 48: training on 102767 raw words (78954 effective words) took 0.1s, 1433747 effective words/s\n",
      "2023-04-17 10:38:51,611 : INFO : EPOCH 49: training on 102767 raw words (79143 effective words) took 0.1s, 1432198 effective words/s\n",
      "2023-04-17 10:38:51,656 : INFO : EPOCH 50: training on 102767 raw words (79171 effective words) took 0.1s, 1431009 effective words/s\n",
      "2023-04-17 10:38:51,722 : INFO : EPOCH 51: training on 102767 raw words (78998 effective words) took 0.1s, 1451803 effective words/s\n",
      "2023-04-17 10:38:51,783 : INFO : EPOCH 52: training on 102767 raw words (78972 effective words) took 0.1s, 1430873 effective words/s\n",
      "2023-04-17 10:38:51,840 : INFO : EPOCH 53: training on 102767 raw words (79146 effective words) took 0.1s, 1463534 effective words/s\n",
      "2023-04-17 10:38:51,889 : INFO : EPOCH 54: training on 102767 raw words (79128 effective words) took 0.1s, 1450094 effective words/s\n",
      "2023-04-17 10:38:51,954 : INFO : EPOCH 55: training on 102767 raw words (79026 effective words) took 0.1s, 1451699 effective words/s\n",
      "2023-04-17 10:38:52,009 : INFO : EPOCH 56: training on 102767 raw words (79023 effective words) took 0.1s, 1487187 effective words/s\n",
      "2023-04-17 10:38:52,060 : INFO : EPOCH 57: training on 102767 raw words (79097 effective words) took 0.1s, 1439978 effective words/s\n",
      "2023-04-17 10:38:52,124 : INFO : EPOCH 58: training on 102767 raw words (79311 effective words) took 0.1s, 1452463 effective words/s\n",
      "2023-04-17 10:38:52,180 : INFO : EPOCH 59: training on 102767 raw words (78988 effective words) took 0.1s, 1466366 effective words/s\n",
      "2023-04-17 10:38:52,229 : INFO : EPOCH 60: training on 102767 raw words (78947 effective words) took 0.1s, 1474341 effective words/s\n",
      "2023-04-17 10:38:52,295 : INFO : EPOCH 61: training on 102767 raw words (78957 effective words) took 0.1s, 1407539 effective words/s\n",
      "2023-04-17 10:38:52,350 : INFO : EPOCH 62: training on 102767 raw words (79074 effective words) took 0.1s, 1473068 effective words/s\n",
      "2023-04-17 10:38:52,399 : INFO : EPOCH 63: training on 102767 raw words (79116 effective words) took 0.1s, 1493456 effective words/s\n",
      "2023-04-17 10:38:52,464 : INFO : EPOCH 64: training on 102767 raw words (78968 effective words) took 0.1s, 1432056 effective words/s\n",
      "2023-04-17 10:38:52,522 : INFO : EPOCH 65: training on 102767 raw words (79108 effective words) took 0.1s, 1434363 effective words/s\n",
      "2023-04-17 10:38:52,586 : INFO : EPOCH 66: training on 102767 raw words (79049 effective words) took 0.1s, 1264157 effective words/s\n",
      "2023-04-17 10:38:52,633 : INFO : EPOCH 67: training on 102767 raw words (79082 effective words) took 0.1s, 1412729 effective words/s\n",
      "2023-04-17 10:38:52,700 : INFO : EPOCH 68: training on 102767 raw words (79133 effective words) took 0.1s, 1410259 effective words/s\n",
      "2023-04-17 10:38:52,760 : INFO : EPOCH 69: training on 102767 raw words (79024 effective words) took 0.1s, 1443698 effective words/s\n",
      "2023-04-17 10:38:52,819 : INFO : EPOCH 70: training on 102767 raw words (79048 effective words) took 0.1s, 1406723 effective words/s\n",
      "2023-04-17 10:38:52,869 : INFO : EPOCH 71: training on 102767 raw words (79123 effective words) took 0.1s, 1348351 effective words/s\n",
      "2023-04-17 10:38:52,936 : INFO : EPOCH 72: training on 102767 raw words (79028 effective words) took 0.1s, 1436429 effective words/s\n",
      "2023-04-17 10:38:53,004 : INFO : EPOCH 73: training on 102767 raw words (79003 effective words) took 0.1s, 1218270 effective words/s\n",
      "2023-04-17 10:38:53,067 : INFO : EPOCH 74: training on 102767 raw words (79015 effective words) took 0.1s, 1312454 effective words/s\n",
      "2023-04-17 10:38:53,138 : INFO : EPOCH 75: training on 102767 raw words (79022 effective words) took 0.1s, 1131613 effective words/s\n",
      "2023-04-17 10:38:53,199 : INFO : EPOCH 76: training on 102767 raw words (78958 effective words) took 0.1s, 1376551 effective words/s\n",
      "2023-04-17 10:38:53,242 : INFO : EPOCH 77: training on 102767 raw words (78968 effective words) took 0.1s, 1476907 effective words/s\n",
      "2023-04-17 10:38:53,309 : INFO : EPOCH 78: training on 102767 raw words (79048 effective words) took 0.1s, 1182083 effective words/s\n",
      "2023-04-17 10:38:53,375 : INFO : EPOCH 79: training on 102767 raw words (79028 effective words) took 0.1s, 1444994 effective words/s\n",
      "2023-04-17 10:38:53,438 : INFO : EPOCH 80: training on 102767 raw words (78973 effective words) took 0.1s, 1446379 effective words/s\n",
      "2023-04-17 10:38:53,494 : INFO : EPOCH 81: training on 102767 raw words (79131 effective words) took 0.1s, 1493128 effective words/s\n",
      "2023-04-17 10:38:53,542 : INFO : EPOCH 82: training on 102767 raw words (78995 effective words) took 0.1s, 1472595 effective words/s\n",
      "2023-04-17 10:38:53,606 : INFO : EPOCH 83: training on 102767 raw words (78995 effective words) took 0.1s, 1458600 effective words/s\n",
      "2023-04-17 10:38:53,663 : INFO : EPOCH 84: training on 102767 raw words (79069 effective words) took 0.1s, 1453442 effective words/s\n",
      "2023-04-17 10:38:53,720 : INFO : EPOCH 85: training on 102767 raw words (79097 effective words) took 0.1s, 1454235 effective words/s\n",
      "2023-04-17 10:38:53,766 : INFO : EPOCH 86: training on 102767 raw words (78901 effective words) took 0.1s, 1487856 effective words/s\n",
      "2023-04-17 10:38:53,832 : INFO : EPOCH 87: training on 102767 raw words (79029 effective words) took 0.1s, 1438374 effective words/s\n",
      "2023-04-17 10:38:53,887 : INFO : EPOCH 88: training on 102767 raw words (78998 effective words) took 0.1s, 1504162 effective words/s\n",
      "2023-04-17 10:38:53,932 : INFO : EPOCH 89: training on 102767 raw words (79237 effective words) took 0.1s, 1502123 effective words/s\n",
      "2023-04-17 10:38:53,932 : INFO : Doc2Vec lifecycle event {'msg': 'training on 9249030 raw words (7113071 effective words) took 5.3s, 1348527 effective words/s', 'datetime': '2023-04-17T10:38:53.932826', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "d2v_model = doc2vec.Doc2Vec(vector_size=120, min_count=10, epochs=90)\n",
    "\n",
    "# build the vocabulary\n",
    "d2v_model.build_vocab(data_train)\n",
    "\n",
    "# Train Doc2Vec model\n",
    "d2v_model.train(data_train, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[230], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m user_i \u001b[39m=\u001b[39m {}\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m df_applicant\u001b[39m.\u001b[39mindex:\n\u001b[1;32m----> 6\u001b[0m     similarity \u001b[39m=\u001b[39m d2v_model\u001b[39m.\u001b[39;49msimilarity_unseen_docs(\n\u001b[0;32m      7\u001b[0m         df_job\u001b[39m.\u001b[39;49mTexts\u001b[39m.\u001b[39;49mloc[i]\u001b[39m.\u001b[39;49msplit(),\n\u001b[0;32m      8\u001b[0m         df_applicant\u001b[39m.\u001b[39;49mTexts\u001b[39m.\u001b[39;49mloc[j]\u001b[39m.\u001b[39;49msplit()\n\u001b[0;32m      9\u001b[0m     )\n\u001b[0;32m     10\u001b[0m     user_i[i] \u001b[39m=\u001b[39m similarity\n\u001b[0;32m     11\u001b[0m results[j] \u001b[39m=\u001b[39m user_i\n",
      "File \u001b[1;32mc:\\Users\\eats\\miniconda3\\envs\\p1\\lib\\site-packages\\gensim\\models\\doc2vec.py:1087\u001b[0m, in \u001b[0;36mDoc2Vec.similarity_unseen_docs\u001b[1;34m(self, doc_words1, doc_words2, alpha, min_alpha, epochs)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_unseen_docs\u001b[39m(\u001b[39mself\u001b[39m, doc_words1, doc_words2, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, min_alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, epochs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1064\u001b[0m     \u001b[39m\"\"\"Compute cosine similarity between two post-bulk out of training documents.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \n\u001b[0;32m   1066\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \n\u001b[0;32m   1086\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1087\u001b[0m     d1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer_vector(doc_words\u001b[39m=\u001b[39;49mdoc_words1, alpha\u001b[39m=\u001b[39;49malpha, min_alpha\u001b[39m=\u001b[39;49mmin_alpha, epochs\u001b[39m=\u001b[39;49mepochs)\n\u001b[0;32m   1088\u001b[0m     d2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer_vector(doc_words\u001b[39m=\u001b[39mdoc_words2, alpha\u001b[39m=\u001b[39malpha, min_alpha\u001b[39m=\u001b[39mmin_alpha, epochs\u001b[39m=\u001b[39mepochs)\n\u001b[0;32m   1089\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdot(matutils\u001b[39m.\u001b[39munitvec(d1), matutils\u001b[39m.\u001b[39munitvec(d2))\n",
      "File \u001b[1;32mc:\\Users\\eats\\miniconda3\\envs\\p1\\lib\\site-packages\\gensim\\models\\doc2vec.py:651\u001b[0m, in \u001b[0;36mDoc2Vec.infer_vector\u001b[1;34m(self, doc_words, alpha, min_alpha, epochs)\u001b[0m\n\u001b[0;32m    646\u001b[0m         train_document_dm_concat(\n\u001b[0;32m    647\u001b[0m             \u001b[39mself\u001b[39m, doc_words, doctag_indexes, alpha, work, neu1,\n\u001b[0;32m    648\u001b[0m             learn_words\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, learn_hidden\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, doctag_vectors\u001b[39m=\u001b[39mdoctag_vectors, doctags_lockf\u001b[39m=\u001b[39mdoctags_lockf\n\u001b[0;32m    649\u001b[0m         )\n\u001b[0;32m    650\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 651\u001b[0m         train_document_dm(\n\u001b[0;32m    652\u001b[0m             \u001b[39mself\u001b[39;49m, doc_words, doctag_indexes, alpha, work, neu1,\n\u001b[0;32m    653\u001b[0m             learn_words\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, learn_hidden\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, doctag_vectors\u001b[39m=\u001b[39;49mdoctag_vectors, doctags_lockf\u001b[39m=\u001b[39;49mdoctags_lockf\n\u001b[0;32m    654\u001b[0m         )\n\u001b[0;32m    655\u001b[0m     alpha \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m alpha_delta\n\u001b[0;32m    657\u001b[0m \u001b[39mreturn\u001b[39;00m doctag_vectors[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for i in df_job.index:\n",
    "    user_i = {}\n",
    "    for j in df_applicant.index:\n",
    "        similarity = d2v_model.similarity_unseen_docs(\n",
    "            df_job.Texts.loc[i].split(),\n",
    "            df_applicant.Texts.loc[j].split()\n",
    "        )\n",
    "        user_i[i] = similarity\n",
    "    results[j] = user_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.similarity_unseen_docs(df_job.Texts.index[27].split(), df_applicant.Texts.loc[15].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2v_model.save('data/d2c_model.model')\n",
    "# loaded_model = Word2Vec.load('data/d2c_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.infer_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.similarity_unseen_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
