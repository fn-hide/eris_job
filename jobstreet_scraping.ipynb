{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_name(var_value, namespace):\n",
    "    \"\"\"\n",
    "    Given a variable value and namespace (e.g. globals() or locals()),\n",
    "    returns the name of the variable as a string.\n",
    "    \"\"\"\n",
    "    for name in namespace:\n",
    "        if namespace[name] is var_value:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def remove_field(element):\n",
    "    element.send_keys(Keys.CONTROL + 'A')\n",
    "    element.send_keys(Keys.DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'driver/chromedriver.exe'\n",
    "driver = webdriver.Chrome(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window() \n",
    "driver.minimize_window() \n",
    "driver.maximize_window() \n",
    "driver.switch_to.window(driver.current_window_handle)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.jobstreet.co.id/')\n",
    "driver.implicitly_wait(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 127 data.\n"
     ]
    }
   ],
   "source": [
    "'''next\n",
    "ios, java, php, react, node.js, android, .Net, 3D Studio Max, 3D Video, Accounting, Accurate, ACLS, Acting, Administrasi, Administrasi BPJS, Adobe Skills, Advokat, Alat Tes, Analisis Data, Android Development, Android Studio, Animator, Artificial Intelligence, Audit, AutoCad, Autodesk, Baby Sitter, Bahasa Inggris, Bahasa Jepang, Bahasa Mandarin, Bakery, Barista, Bartender, Berpikir Kritis, Blender, Brevet A/B, BTCLS, C#, C++, CAD, CDE, Chinese Food, Chiropractic, Cinematografi, Cisco, CMS, CNA, Codeigniter, Coffee Roasting, Content Creator, Content Marketing, Content Planning, Content Strategy, Content Writing, Cook Helper, Cooking, Copywriting, Corel Draw, Critical Thinking, CRM, CRNA, CSS, Data Analysis, Data Entry, Data Management, Data Visualisation, Data Warehouse, Database, Detail-oriented, Digital Marketing, Drafting, Driver Manual, Driver Matic, Drone, Dubbing, Editor, EDP, Ekspor-Impor, Electrical, ENPC, EQ, ERP, Estimator, Facebook Ads, Fiber Optik, Figma, Finance, Fokus, Forecasting, Fotografi, GELS, General Affair, Git, Gizi, Google Ads, Graphic Design, Grill, Ground Crew, Guide, Hairdo, Hairstylist, Helpdesk, Housekeeping, HRIS, HSE, HTML, Hubspot, ICU, Ilustrator, Indesign, Instalasi, Interior, Interview, IOS Development, IPCN, ISO, Japanese Food, Java, Java Script, K3, Kasir, Ketelitian, Ketenagakerjaan, Kolaborasi, Komunikasi, Konsultan Keuangan, Kreativitas, Kreativitas, Landscape, Laravel, Laundry, Legal Drafting, Legal Opinion, Litigasi, Machine Learning, Maintenance Hardware, Maintenance Software, Make Up artist, Maket, Manajemen Projek, Manufacture, Marketing, MatLab, Mechanical Electric, Mekanik Hidrolik, Mendengarkan Secara Aktif, Menjahit, Meta Ads, Microsoft Excel, Microsoft Office, Microsoft Word, Mikrotik, Montir, Motion Graphic, Multitasking, Music, MVC, My SQL, MYOB, Nail Art, Negosiasi, Networking/Jaringan, Node JS, OBS Studio, Operator, Operator Alat Berat, Operator Bulldozer, Operator Conveyer, Operator Excavator, Operator Forklift, Operator Mesin, Opertor Alat Berat, Origami, Otomasi, PABX, PALS , Paper Cutting, Pastry, Payroll, PCP/IP, Pengambilan Keputusan, Pengecatan, Pengelasan, Penyelesaian Masalah, Perencanaan & Penjadwalan, Perencanaan Budget, Perhitungan, Perundang-undangan, Photoshop, Pidato, PLC, Plumbing, Power BI, PPGD, PPIC, Premiere, Presentasi, Problem-solving, Product Knowledge, Programming, Psikolog, Psikotes, Public Speaking, QC, Racik Obat, Receptionist, Refleksiologi, Rekrutmen, Resep, Revit, Robotics, Sabar, Salesforce, SAP\n",
    "'''\n",
    "job_name = 'ios'\n",
    "\n",
    "job_title = '-'.join(job_name.split())\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "driver.get(f'https://www.jobstreet.co.id/id/job-search/{job_title}-jobs-in-indonesia/')\n",
    "\n",
    "jobs = []\n",
    "job_num = 1\n",
    "job_idx = 0\n",
    "\n",
    "driver.implicitly_wait(1)\n",
    "total_data = driver.find_element_by_css_selector('[data-automation=\"searchResultBar\"]').text.split()[-2]\n",
    "\n",
    "print('Total', total_data, 'data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = pd.read_csv('data/scraped/all_jobstreet.csv')\n",
    "\n",
    "with open('data/scraped/all_jobstreet.pickle', 'rb') as file:\n",
    "    pickle_job = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No.    [Scraped, Page, Total]                           Job Title                           Info\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "2.           [1, 1, 127]                  IT Mobile Apps (Android Developer) Staff           scraped successfully ... 😊👍\n",
      "3.           [2, 1, 127]                              Mobile Developer                       scraped successfully ... 😊👍\n",
      "💔 The same data:(\n",
      "4.           [3, 1, 127]                      IT Mobile Application Supervisor               scraped successfully ... 😊👍\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "5.           [4, 2, 127]                         Mobile Developer (Flutter)                  scraped successfully ... 😊👍\n",
      "6.           [5, 2, 127]                     Web & Mobile Application Developer              scraped successfully ... 😊👍\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "7.           [6, 2, 127]                         Android Developer (Remote)                  scraped successfully ... 😊👍\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "❌PASS❌ Programmer Web / Mobile Apps\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "8.           [7, 3, 127]                    Back-end Developer - Java Programmer             scraped successfully ... 😊👍\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "9.           [8, 4, 127]                        FLUTTER MOBILE CHAPTER LEAD                  scraped successfully ... 😊👍\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "10.          [9, 4, 127]                             Quality Assurance                       scraped successfully ... 😊👍\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "💔 The same data:(\n",
      "> raise break <\n"
     ]
    }
   ],
   "source": [
    "print('No.'.center(5), '[Scraped, Page, Total]'.center(25), 'Job Title'.center(60), 'Info')\n",
    "\n",
    "while True:\n",
    "    job_cards = driver.find_elements_by_css_selector('[data-search-sol-meta]')\n",
    "\n",
    "    # halaman\n",
    "    try:\n",
    "        curr_page = int(driver.find_element_by_id('pagination').get_attribute('value'))\n",
    "        driver.implicitly_wait(2)\n",
    "    except:\n",
    "        curr_page = 1\n",
    "\n",
    "    # job list\n",
    "    for job_card in job_cards:\n",
    "        job = {}\n",
    "        \n",
    "        title = job_card.text.split('\\n')[0]\n",
    "        df_title = df_job[df_job.Title == title]\n",
    "\n",
    "        # scroll to center\n",
    "        driver.execute_script('arguments[0].scrollIntoView({block: \"center\"});', job_card)\n",
    "\n",
    "        # sudah pernah di klik atau belum\n",
    "        try:\n",
    "            title_class = job_card.find_element_by_css_selector('h1.z1s6m00').find_element_by_xpath('a/div/span').get_attribute('class').split()\n",
    "\n",
    "            if len(title_class) > 1:\n",
    "                job_idx += 1\n",
    "                continue\n",
    "        except:\n",
    "            print('❌PASS❌', title)\n",
    "            continue\n",
    "\n",
    "        # hanya mencoba 2x\n",
    "        try:\n",
    "            job_card.find_element_by_css_selector('[rel]').click()\n",
    "            driver.implicitly_wait(10)\n",
    "        except:\n",
    "            job_card.find_element_by_css_selector('[rel]').click()\n",
    "            driver.implicitly_wait(10)\n",
    "        \n",
    "\n",
    "        '''scraping'''\n",
    "        # job header: list of header information\n",
    "        try:\n",
    "            job_header = driver.find_element_by_css_selector('[data-automation=\"jobDetailsHeader\"]').text.split('\\n')[:3]\n",
    "            driver.implicitly_wait(5)\n",
    "\n",
    "            job['Title'], job['Company'], job['Area'] = job_header\n",
    "        except:\n",
    "            print('❌ JobTitle raise exception!')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            job_detail = driver.find_element_by_css_selector('[data-automation=\"splitModeJobDetailsScrollWrapper\"]')\n",
    "            driver.implicitly_wait(5)\n",
    "\n",
    "            # job description: list of description\n",
    "            try:\n",
    "                job_description = driver.find_element_by_css_selector('[data-automation=\"jobDescription\"]').text.split('\\n')\n",
    "                driver.implicitly_wait(5)\n",
    "\n",
    "                job['Description'] = ' \\n '.join(job_description)\n",
    "\n",
    "                if len(df_title[df_title.Description == job['Description']]) > 0:\n",
    "                    print('💔 The same description:( >>>', job['Title'])\n",
    "                    continue\n",
    "            except:\n",
    "                print('❌ JobDescription raise exception!')\n",
    "                continue\n",
    "\n",
    "            # additional information: list of information\n",
    "            try:\n",
    "                job_additional_information = job_detail.find_element_by_xpath('div/div[2]/div/div[1]/div/div[2]').text.split('\\n')[1:][1::2]\n",
    "                driver.implicitly_wait(5)\n",
    "\n",
    "                job_additional_information = [i for i in job_additional_information if i.lower() != 'tidak terspesifikasi']\n",
    "\n",
    "                job['Information'] = ' \\n '.join(job_additional_information)\n",
    "            except:\n",
    "                print('❌ JobInformation raise exception!')\n",
    "                job['Information'] = None\n",
    "        except:\n",
    "            print('❌ JobDescription and JobInformation raise exception!')\n",
    "            continue\n",
    "\n",
    "        # append to jobs\n",
    "        jobs.append(job)\n",
    "\n",
    "        # log\n",
    "        print(f\"{job_idx}.\".ljust(5), f\"[{job_num}, {curr_page}, {total_data}]\".center(25), f\"{job['Title']}\".center(60), 'scraped successfully ... 😊👍')\n",
    "\n",
    "        job_num += 1\n",
    "        job_idx += 1\n",
    "    \n",
    "    try:\n",
    "        # scroll to \"lanjut\"\n",
    "        driver.execute_script('arguments[0].scrollIntoView({block: \"center\"});', driver.find_element_by_xpath(\"//span[contains(text(), 'Lanjut')]\"))\n",
    "    except:\n",
    "        print('> raise break when scroll <')\n",
    "        break\n",
    "\n",
    "    # go to the next page\n",
    "    driver.find_element_by_xpath(\"//span[contains(text(), 'Lanjut')]\").click()\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    next_page = int(driver.find_element_by_id('pagination').get_attribute('value'))\n",
    "\n",
    "    if curr_page == next_page:\n",
    "        print('> raise break <')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = pd.concat([df_job, pd.DataFrame(jobs)], axis=0)\n",
    "pickle_job = pickle_job + jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tambahkan save csv dan pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'jobstreet_' + ''.join(job_name.title().split())\n",
    "\n",
    "with open(f'data/scraped/{filename}.pickle', 'wb') as file:\n",
    "    pickle.dump(jobs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORTS saved!\n"
     ]
    }
   ],
   "source": [
    "filepaths = glob('data/scraped/jobstreet_*.pickle')\n",
    "\n",
    "filenames = [filepath.split('.')[0].split('_')[-1].lower() for filepath in filepaths]\n",
    "\n",
    "if ''.join(job_name.lower().split()) in filenames:\n",
    "    print(job_name.upper(), 'saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198\n"
     ]
    }
   ],
   "source": [
    "# with open(\"data/scraped/jobstreet_Akuntansi.pickle\", \"rb\") as f:\n",
    "#     my_list = pickle.load(f)\n",
    "\n",
    "# print(len(my_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body = driver.find_element_by_tag_name(\"body\")\n",
    "# body.send_keys(Keys.CONTROL + '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_search = driver.find_element_by_css_selector('#global-nav-typeahead > input')\n",
    "\n",
    "# job_search.click()\n",
    "# job_search.send_keys(Keys.CONTROL + 'a')\n",
    "# job_search.send_keys(Keys.DELETE)\n",
    "# job_search.send_keys('ios developer')\n",
    "\n",
    "# location_search = driver.find_element_by_css_selector('#jobs-search-box-location-id-ember1360')\n",
    "\n",
    "# location_search.click()\n",
    "# location_search.send_keys(Keys.CONTROL + 'a')\n",
    "# location_search.send_keys(Keys.DELETE)\n",
    "# location_search.send_keys('indonesia')\n",
    "\n",
    "# search_button = driver.find_element_by_xpath('//*[@id=\"global-nav-search\"]/div/div[2]/button[1]')\n",
    "# search_button.click()\n",
    "\n",
    "# actions = ActionChains(driver)\n",
    "# actions.send_keys(Keys.ENTER)\n",
    "# actions.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
