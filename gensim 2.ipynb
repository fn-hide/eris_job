{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import re\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix, WordEmbeddingSimilarityIndex\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "from googletrans import Translator\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from FlaskApp.transform import *\n",
    "\n",
    "from job_model import JobModel\n",
    "from app_model import AppModel\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "rootwords = [i[0] for i in pd.read_csv('data/rootwords.txt').values]\n",
    "\n",
    "with open('data/slangwords.json', 'r') as file:\n",
    "    slangwords = json.load(file)\n",
    "\n",
    "with open('data/englishwords.json', 'r') as file:\n",
    "    englishwords = json.load(file)\n",
    "\n",
    "with open('data/slangjobs.json', 'r') as file:\n",
    "    slangjobs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'huda'\n",
    "password = 'Vancha12'\n",
    "host = '127.0.0.1'\n",
    "port = 1433\n",
    "database = 'HRSystemDB'\n",
    "\n",
    "\n",
    "def get_connection():         \n",
    "    return create_engine(\n",
    "        url=f\"mssql+pyodbc://{user}:{password}@{host}:{port}/{database}?driver=SQL Server\",\n",
    "    )\n",
    "\n",
    "engine = get_connection()\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicant_id = 31790\n",
    "\n",
    "df_job = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT Job.JobID, Job.UsiaMax, Job.SalaryMin, Job.SalaryMax, City.Name AS CityName, Province.Name AS ProvinceName, EducationLevel.EducationLevelName, Major.MajorName, Job.DriverLicenseType, Job.UsingGlasses, Job.Gender, Job.MaritalStatus, Job.JobTitle, FunctionPosition.FunctionPositionName, Job.Description, Job.Requirement\n",
    "    FROM (((((Job\n",
    "    RIGHT JOIN FunctionPosition ON Job.FunctionPositionID = FunctionPosition.FunctionPositionID)\n",
    "    RIGHT JOIN EducationLevel ON Job.EducationLevelID = EducationLevel.EducationLevelID)\n",
    "    RIGHT JOIN City ON Job.CityID = City.CityID)\n",
    "    RIGHT JOIN Province ON Job.ProvinceID = Province.ProvinceID)\n",
    "    RIGHT JOIN Major ON Job.MajorID = Major.MajorID)\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_function = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT FunctionPositionID, FunctionPositionName\n",
    "    FROM FunctionPosition\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_education = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT EducationLevelID, EducationLevelName\n",
    "    FROM EducationLevel\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_city = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT CityID, Name AS CityName\n",
    "    FROM City\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_province = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT ProvinceID, Name AS ProvinceName\n",
    "    FROM Province\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_major = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT MajorID, MajorName\n",
    "    FROM Major\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT Applicant.ApplicantID, Applicant.Dob, Applicant.ExpectedSalary, City.Name AS CityName, Province.Name AS ProvinceName, Applicant.DriverLicenseType, Applicant.IsUsingGlasses, Applicant.Gender, Applicant.MaritalStatus, Applicant.Strengthness\n",
    "    FROM (((Applicant\n",
    "    RIGHT JOIN City ON Applicant.CurrentAddressCityID = City.CityID)\n",
    "    RIGHT JOIN Province ON Applicant.CurrentAddressProvinceID = Province.ProvinceID)\n",
    "    LEFT JOIN Pipeline ON Applicant.ApplicantID = Pipeline.ApplicantID)\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant_education = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT ApplicantEducation.ApplicantID, ApplicantEducation.DateStart, ApplicantEducation.DateEnd, EducationLevel.EducationLevelName, Major.MajorName\n",
    "    FROM (((ApplicantEducation\n",
    "    RIGHT JOIN EducationLevel ON ApplicantEducation.EducationLevelID = EducationLevel.EducationLevelID)\n",
    "    RIGHT JOIN Major ON ApplicantEducation.MajorID = Major.MajorID)\n",
    "    LEFT JOIN Pipeline ON ApplicantEducation.ApplicantID = Pipeline.ApplicantID)\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant_experience = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT ApplicantExperience.ApplicantID, ApplicantExperience.DateFrom, ApplicantExperience.DateTo, ApplicantExperience.Position, ApplicantExperience.JobDescription\n",
    "    FROM (ApplicantExperience\n",
    "    LEFT JOIN Pipeline ON ApplicantExperience.ApplicantID = Pipeline.ApplicantID)\n",
    "    \"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_str = ['CityName', 'ProvinceName', 'EducationLevelName', 'MajorName', 'DriverLicenseType', 'Gender', 'MaritalStatus', 'JobTitle', 'FunctionPositionName', 'Description', 'Requirement']\n",
    "job_num = ['UsiaMax', 'SalaryMin', 'SalaryMax']\n",
    "job_bol = ['UsingGlasses']\n",
    "\n",
    "'''general'''\n",
    "df_job.set_index(['JobID'], inplace=True)\n",
    "df_job.fillna('', inplace=True)\n",
    "\n",
    "'''str'''\n",
    "df_job[job_str] = df_job[job_str].applymap(str.lower)\n",
    "df_job.replace('none', '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job.Description = df_job.Description.map(\n",
    "    clean_text\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(englishwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").map(\n",
    "    stemmer.stem\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job.Requirement = df_job.Requirement.map(\n",
    "    clean_text\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(englishwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").map(\n",
    "    stemmer.stem\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(set(' '.join([i for i in df_job.Requirement.values]).split()))\n",
    "corpus = [i for i in corpus if i not in rootwords]\n",
    "corpus.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adwords\n",
      "aldo\n",
      "alphard\n",
      "aplication\n",
      "atu\n",
      "audisi\n",
      "auravita\n",
      "berpengalan\n",
      "campaignare\n",
      "cctv\n",
      "clearil\n",
      "co\n",
      "competency\n",
      "cslr\n",
      "delivering\n",
      "dki\n",
      "dna\n",
      "drafter\n",
      "drone\n",
      "drupal\n",
      "ds\n",
      "effect\n",
      "estimator\n",
      "excell\n",
      "fbm\n",
      "firebase\n",
      "foodteria\n",
      "freshgraduated\n",
      "gadget\n",
      "gcg\n",
      "gm\n",
      "grapis\n",
      "handphone\n",
      "hrga\n",
      "hsk\n",
      "html\n",
      "http\n",
      "ifca\n",
      "instagramable\n",
      "intrapersonal\n",
      "io\n",
      "iso\n",
      "ivena\n",
      "javascript\n",
      "jquery\n",
      "json\n",
      "kta\n",
      "lainnnya\n",
      "litigasi\n",
      "maks\n",
      "matic\n",
      "mcse\n",
      "mempu\n",
      "mengoptimasi\n",
      "merapihkan\n",
      "mikrotik\n",
      "mou\n",
      "multi\n",
      "myob\n",
      "nat\n",
      "novianti\n",
      "od\n",
      "paced\n",
      "pb\n",
      "pc\n",
      "pdf\n",
      "penempatakan\n",
      "perjalalanan\n",
      "php\n",
      "pkwt\n",
      "pkwtt\n",
      "placement\n",
      "pods\n",
      "porsi\n",
      "powerpoint\n",
      "preschool\n",
      "programmer\n",
      "proposional\n",
      "proxy\n",
      "qlikview\n",
      "rekon\n",
      "respon\n",
      "router\n",
      "sbb\n",
      "sd\n",
      "sejeniis\n",
      "seo\n",
      "serentak\n",
      "sitac\n",
      "skalatis\n",
      "sketchup\n",
      "skill\n",
      "sma\n",
      "smartphone\n",
      "smp\n",
      "smu\n",
      "solving\n",
      "sony\n",
      "spesialisasi\n",
      "sq\n",
      "sqlserver\n",
      "ssas\n",
      "ssis\n",
      "staadpro\n",
      "stm\n",
      "strategic\n",
      "sudirman\n",
      "supir\n",
      "taiwan\n",
      "tamb\n",
      "tekana\n",
      "teknisi\n",
      "tekut\n",
      "ten\n",
      "terstuktur\n",
      "thingking\n",
      "tr\n",
      "treassury\n",
      "usi\n",
      "uud\n",
      "vb\n",
      "vegas\n",
      "videotron\n",
      "wafel\n",
      "waze\n",
      "willingness\n",
      "winbox\n",
      "wp\n",
      "yo\n",
      "zahir\n"
     ]
    }
   ],
   "source": [
    "for i in corpus:\n",
    "    if i not in rootwords:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: cleansing requirement belum selesai\n",
    "# TODO: buat istilah paten mengenai skill dan keperluan tertentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job.JobTitle = df_job.JobTitle.map(\n",
    "    remove_insideparentheses\n",
    ").map(\n",
    "    remove_standalonesymbols\n",
    ").map(\n",
    "    remove_morespace\n",
    ").apply(\n",
    "    lambda x: change_words(slangjobs, x)\n",
    ")\n",
    "df_job.FunctionPositionName = df_job.FunctionPositionName.map(\n",
    "    remove_insideparentheses\n",
    ").map(\n",
    "    remove_standalonesymbols\n",
    ").map(\n",
    "    remove_morespace\n",
    ").apply(\n",
    "    lambda x: change_words(slangjobs, x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(set(' '.join([i for i in df_job.Description.values]).split()))\n",
    "corpus = [i for i in corpus if i not in rootwords]\n",
    "corpus.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english_corpus = []\n",
    "# for i in corpus:\n",
    "#     translated = translator.detect(i)\n",
    "#     if translated.lang == 'en' and translated.confidence > .75:\n",
    "#         english_corpus.append(i)\n",
    "\n",
    "# indonesian_corpus = []\n",
    "# for i in corpus:\n",
    "#     translated = translator.detect(i)\n",
    "#     if translated.lang == 'in' and translated.confidence > .75:\n",
    "#         indonesian_corpus.append(i)\n",
    "\n",
    "# another_corpus = []\n",
    "\n",
    "# for i in corpus:\n",
    "#     if i not in english_corpus and i not in indonesian_corpus:\n",
    "#         another_corpus.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translator = GoogleTranslator(source='en', target='id')\n",
    "\n",
    "# corpus.sort()\n",
    "\n",
    "# corpused = {}\n",
    "# for original in corpus:\n",
    "#     translated = translator.translate(original)\n",
    "#     corpused[original] = str.lower(translated)\n",
    "\n",
    "# no_translate = []\n",
    "# for key in corpused:\n",
    "#     if key == corpused[key]:\n",
    "#         no_translate.append(key)\n",
    "\n",
    "# for key in no_translate:\n",
    "#     del corpused[key]\n",
    "\n",
    "# slang_2 = []\n",
    "\n",
    "# for i,j in zip(slang, stemmed):\n",
    "#     if i == j:\n",
    "#         slang_2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eats\\AppData\\Local\\Temp\\ipykernel_6088\\1545315867.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_applicant.ApplicantID = df_applicant.ApplicantID.astype(int)\n"
     ]
    }
   ],
   "source": [
    "'''applicant'''\n",
    "df_applicant = df_applicant.dropna(subset=['ApplicantID'])\n",
    "df_applicant.ApplicantID = df_applicant.ApplicantID.astype(int)\n",
    "df_applicant = df_applicant.drop_duplicates()\n",
    "df_applicant = df_applicant.fillna('')\n",
    "# age column\n",
    "df_applicant['Age'] = pd.to_datetime(\n",
    "    df_applicant.Dob.map(pick_date).apply(lambda x: filter_date(x, 1958, 2006))\n",
    ").map(get_age)\n",
    "\n",
    "df_applicant.drop(columns=['Dob'], inplace=True)\n",
    "\n",
    "df_applicant.Age = df_applicant.Age.fillna(0).astype(int)\n",
    "'''education'''\n",
    "df_applicant_education = df_applicant_education.fillna('')\n",
    "# datetime column\n",
    "df_applicant_education.DateStart = pd.to_datetime(\n",
    "    df_applicant_education.DateStart.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_education.DateEnd = pd.to_datetime(\n",
    "    df_applicant_education.DateEnd.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_education = df_applicant_education[~(df_applicant_education.DateStart.isna()) & ~(df_applicant_education.DateEnd.isna())]\n",
    "df_applicant_education = df_applicant_education.sort_values('DateStart').groupby(['ApplicantID']).agg('last')\n",
    "df_applicant_education.drop(columns=['DateStart', 'DateEnd'], inplace=True)\n",
    "'''experience'''\n",
    "df_applicant_experience = df_applicant_experience.fillna('')\n",
    "\n",
    "# datetime column\n",
    "df_applicant_experience.DateFrom = pd.to_datetime(\n",
    "    df_applicant_experience.DateFrom.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_experience.DateTo = pd.to_datetime(\n",
    "    df_applicant_experience.DateTo.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_experience = df_applicant_experience[~(df_applicant_experience.DateFrom.isna()) & ~(df_applicant_experience.DateTo.isna())]\n",
    "\n",
    "# add YearsOfExperience column\n",
    "df_applicant_experience['YearsOfExperience'] = substract_months(\n",
    "    df_applicant_experience.DateFrom, df_applicant_experience.DateTo\n",
    ")\n",
    "df_applicant_experience = df_applicant_experience.sort_values('DateFrom').groupby(['ApplicantID']).agg({\n",
    "    'DateFrom': 'last',\n",
    "    'DateTo': 'last',\n",
    "    'JobDescription': ' '.join,\n",
    "    'Position': ' '.join,\n",
    "    'YearsOfExperience': 'sum',\n",
    "})\n",
    "df_applicant_experience.drop(columns=['DateFrom', 'DateTo'], inplace=True)\n",
    "'''merge'''\n",
    "df_applicant = pd.merge(df_applicant, df_applicant_experience, on=['ApplicantID'])\n",
    "df_applicant = pd.merge(df_applicant, df_applicant_education, on=['ApplicantID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PRE-PROCESSING APPLICANT'''\n",
    "df_applicant.set_index(['ApplicantID'], inplace=True)\n",
    "\n",
    "app_str = ['CityName', 'ProvinceName', 'EducationLevelName', 'MajorName', 'DriverLicenseType', 'Gender', 'MaritalStatus', 'Position', 'JobDescription', 'Strengthness']\n",
    "app_num = ['Age', 'ExpectedSalary', 'YearsOfExperience']\n",
    "app_bol = ['IsUsingGlasses']\n",
    "\n",
    "df_applicant = df_applicant[app_num + app_bol + app_str]\n",
    "\n",
    "'''str'''\n",
    "df_applicant[app_str] = df_applicant[app_str].applymap(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eats\\miniconda3\\envs\\p1\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_applicant.JobDescription = df_applicant.JobDescription.map(\n",
    "    clean_text\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(englishwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").map(\n",
    "    stemmer.stem\n",
    ")\n",
    "\n",
    "df_applicant.Strengthness = df_applicant.Strengthness.map(\n",
    "    clean_text\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(englishwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").map(\n",
    "    stemmer.stem\n",
    ")\n",
    "\n",
    "df_applicant.Position = df_applicant.Position.map(\n",
    "    remove_insideparentheses\n",
    ").map(\n",
    "    remove_standalonesymbols\n",
    ").map(\n",
    "    remove_morespace\n",
    ").apply(\n",
    "    lambda x: change_words(slangjobs, x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat\n",
    "df_applicant.JobDescription = df_applicant.JobDescription.str.cat(\n",
    "    df_applicant.Strengthness, sep=' '\n",
    ")\n",
    "df_applicant.rename(columns={'JobDescription': 'DescriptionStrengthness'}, inplace=True)\n",
    "df_applicant.drop(columns=['Strengthness'], inplace=True)\n",
    "\n",
    "'''bool'''\n",
    "df_applicant.IsUsingGlasses = df_applicant.IsUsingGlasses.astype(str).map(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate JobTitle and FunctionPositionName to be textual feature together\n",
    "df_job.JobTitle = df_job.JobTitle.str.cat(\n",
    "    df_job.FunctionPositionName, sep=' '\n",
    ")\n",
    "df_job.rename(columns={'JobTitle': 'JobTitlePosition'}, inplace=True)\n",
    "df_job.drop(columns=['FunctionPositionName'], inplace=True)\n",
    "\n",
    "# concatenate Description and Requirement to be textual feature together\n",
    "df_job.Description = df_job.Description.str.cat(\n",
    "    df_job.Requirement, sep=' '\n",
    ")\n",
    "df_job.rename(columns={'Description': 'DescriptionRequirement'}, inplace=True)\n",
    "df_job.drop(columns=['Requirement'], inplace=True)\n",
    "\n",
    "df_job = df_job[~(df_job.DescriptionRequirement == ' ')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job['Texts'] = df_job.JobTitlePosition + ' ' + df_job.DescriptionRequirement\n",
    "df_applicant['Texts'] = df_applicant.Position + ' ' + df_applicant.DescriptionStrengthness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "# get dataset\n",
    "# dataset = api.load(\"text8\")\n",
    "dataset = list(df_job.Texts.apply(lambda x: x.split()).values)\n",
    "data =[]\n",
    "for w in dataset:\n",
    "    data.append(w)\n",
    "\n",
    "# To train the model we need a list of tagged documents\n",
    "def tagged_document(list_of_ListOfWords):\n",
    "    for x, ListOfWords in enumerate(list_of_ListOfWords):\n",
    "        yield doc2vec.TaggedDocument(ListOfWords, [x])\n",
    "\n",
    "# training data\n",
    "data_train = list(tagged_document(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:56:35,207 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d120,n5,w5,mc10,s0.001,t3>', 'datetime': '2023-04-18T16:56:35.207108', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-18 16:56:35,209 : INFO : collecting all words and their counts\n",
      "2023-04-18 16:56:35,209 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-04-18 16:56:35,253 : INFO : collected 12888 word types and 1006 unique tags from a corpus of 1006 examples and 393745 words\n",
      "2023-04-18 16:56:35,254 : INFO : Creating a fresh vocabulary\n",
      "2023-04-18 16:56:35,263 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 2639 unique words (20.48% of original 12888, drops 10249)', 'datetime': '2023-04-18T16:56:35.263122', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-18 16:56:35,265 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 367290 word corpus (93.28% of original 393745, drops 26455)', 'datetime': '2023-04-18T16:56:35.265117', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-18 16:56:35,275 : INFO : deleting the raw counts dictionary of 12888 items\n",
      "2023-04-18 16:56:35,276 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2023-04-18 16:56:35,276 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 240503.8328983912 word corpus (65.5%% of prior 367290)', 'datetime': '2023-04-18T16:56:35.276515', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-18 16:56:35,291 : INFO : estimated required memory for 2639 words and 120 dimensions: 4537020 bytes\n",
      "2023-04-18 16:56:35,292 : INFO : resetting layer weights\n",
      "2023-04-18 16:56:35,294 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 2639 vocabulary and 120 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-18T16:56:35.294466', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-18 16:56:35,427 : INFO : EPOCH 0: training on 393745 raw words (241439 effective words) took 0.1s, 1850608 effective words/s\n",
      "2023-04-18 16:56:35,551 : INFO : EPOCH 1: training on 393745 raw words (241351 effective words) took 0.1s, 1963552 effective words/s\n",
      "2023-04-18 16:56:35,673 : INFO : EPOCH 2: training on 393745 raw words (241359 effective words) took 0.1s, 2035512 effective words/s\n",
      "2023-04-18 16:56:35,801 : INFO : EPOCH 3: training on 393745 raw words (241393 effective words) took 0.1s, 1913007 effective words/s\n",
      "2023-04-18 16:56:35,924 : INFO : EPOCH 4: training on 393745 raw words (241336 effective words) took 0.1s, 1985564 effective words/s\n",
      "2023-04-18 16:56:36,047 : INFO : EPOCH 5: training on 393745 raw words (241408 effective words) took 0.1s, 2002281 effective words/s\n",
      "2023-04-18 16:56:36,167 : INFO : EPOCH 6: training on 393745 raw words (241454 effective words) took 0.1s, 2066918 effective words/s\n",
      "2023-04-18 16:56:36,300 : INFO : EPOCH 7: training on 393745 raw words (241560 effective words) took 0.1s, 1845185 effective words/s\n",
      "2023-04-18 16:56:36,419 : INFO : EPOCH 8: training on 393745 raw words (241319 effective words) took 0.1s, 2061062 effective words/s\n",
      "2023-04-18 16:56:36,542 : INFO : EPOCH 9: training on 393745 raw words (241805 effective words) took 0.1s, 2017155 effective words/s\n",
      "2023-04-18 16:56:36,660 : INFO : EPOCH 10: training on 393745 raw words (241370 effective words) took 0.1s, 2068084 effective words/s\n",
      "2023-04-18 16:56:36,781 : INFO : EPOCH 11: training on 393745 raw words (241589 effective words) took 0.1s, 2038440 effective words/s\n",
      "2023-04-18 16:56:36,898 : INFO : EPOCH 12: training on 393745 raw words (241517 effective words) took 0.1s, 2091514 effective words/s\n",
      "2023-04-18 16:56:37,015 : INFO : EPOCH 13: training on 393745 raw words (241679 effective words) took 0.1s, 2098524 effective words/s\n",
      "2023-04-18 16:56:37,129 : INFO : EPOCH 14: training on 393745 raw words (241445 effective words) took 0.1s, 2152210 effective words/s\n",
      "2023-04-18 16:56:37,248 : INFO : EPOCH 15: training on 393745 raw words (241571 effective words) took 0.1s, 2064995 effective words/s\n",
      "2023-04-18 16:56:37,365 : INFO : EPOCH 16: training on 393745 raw words (241450 effective words) took 0.1s, 2103923 effective words/s\n",
      "2023-04-18 16:56:37,506 : INFO : EPOCH 17: training on 393745 raw words (241538 effective words) took 0.1s, 1745454 effective words/s\n",
      "2023-04-18 16:56:37,625 : INFO : EPOCH 18: training on 393745 raw words (241413 effective words) took 0.1s, 2051542 effective words/s\n",
      "2023-04-18 16:56:37,741 : INFO : EPOCH 19: training on 393745 raw words (241770 effective words) took 0.1s, 2128664 effective words/s\n",
      "2023-04-18 16:56:37,855 : INFO : EPOCH 20: training on 393745 raw words (241498 effective words) took 0.1s, 2157159 effective words/s\n",
      "2023-04-18 16:56:37,969 : INFO : EPOCH 21: training on 393745 raw words (241530 effective words) took 0.1s, 2141199 effective words/s\n",
      "2023-04-18 16:56:38,077 : INFO : EPOCH 22: training on 393745 raw words (241871 effective words) took 0.1s, 2147647 effective words/s\n",
      "2023-04-18 16:56:38,200 : INFO : EPOCH 23: training on 393745 raw words (241256 effective words) took 0.1s, 2101844 effective words/s\n",
      "2023-04-18 16:56:38,315 : INFO : EPOCH 24: training on 393745 raw words (241647 effective words) took 0.1s, 2135719 effective words/s\n",
      "2023-04-18 16:56:38,434 : INFO : EPOCH 25: training on 393745 raw words (241185 effective words) took 0.1s, 2069497 effective words/s\n",
      "2023-04-18 16:56:38,555 : INFO : EPOCH 26: training on 393745 raw words (241199 effective words) took 0.1s, 2020754 effective words/s\n",
      "2023-04-18 16:56:38,669 : INFO : EPOCH 27: training on 393745 raw words (241498 effective words) took 0.1s, 2163030 effective words/s\n",
      "2023-04-18 16:56:38,782 : INFO : EPOCH 28: training on 393745 raw words (241611 effective words) took 0.1s, 2175049 effective words/s\n",
      "2023-04-18 16:56:38,898 : INFO : EPOCH 29: training on 393745 raw words (241530 effective words) took 0.1s, 2122531 effective words/s\n",
      "2023-04-18 16:56:39,012 : INFO : EPOCH 30: training on 393745 raw words (241885 effective words) took 0.1s, 2167726 effective words/s\n",
      "2023-04-18 16:56:39,130 : INFO : EPOCH 31: training on 393745 raw words (241475 effective words) took 0.1s, 2082591 effective words/s\n",
      "2023-04-18 16:56:39,241 : INFO : EPOCH 32: training on 393745 raw words (241627 effective words) took 0.1s, 2197448 effective words/s\n",
      "2023-04-18 16:56:39,357 : INFO : EPOCH 33: training on 393745 raw words (241388 effective words) took 0.1s, 2121246 effective words/s\n",
      "2023-04-18 16:56:39,472 : INFO : EPOCH 34: training on 393745 raw words (241392 effective words) took 0.1s, 2136541 effective words/s\n",
      "2023-04-18 16:56:39,592 : INFO : EPOCH 35: training on 393745 raw words (241682 effective words) took 0.1s, 2045715 effective words/s\n",
      "2023-04-18 16:56:39,707 : INFO : EPOCH 36: training on 393745 raw words (241072 effective words) took 0.1s, 2164715 effective words/s\n",
      "2023-04-18 16:56:39,824 : INFO : EPOCH 37: training on 393745 raw words (241334 effective words) took 0.1s, 2102509 effective words/s\n",
      "2023-04-18 16:56:39,936 : INFO : EPOCH 38: training on 393745 raw words (241381 effective words) took 0.1s, 2176433 effective words/s\n",
      "2023-04-18 16:56:40,054 : INFO : EPOCH 39: training on 393745 raw words (241616 effective words) took 0.1s, 2084032 effective words/s\n",
      "2023-04-18 16:56:40,169 : INFO : EPOCH 40: training on 393745 raw words (241452 effective words) took 0.1s, 2129723 effective words/s\n",
      "2023-04-18 16:56:40,290 : INFO : EPOCH 41: training on 393745 raw words (241523 effective words) took 0.1s, 2043490 effective words/s\n",
      "2023-04-18 16:56:40,404 : INFO : EPOCH 42: training on 393745 raw words (241699 effective words) took 0.1s, 2150217 effective words/s\n",
      "2023-04-18 16:56:40,521 : INFO : EPOCH 43: training on 393745 raw words (241429 effective words) took 0.1s, 2090374 effective words/s\n",
      "2023-04-18 16:56:40,633 : INFO : EPOCH 44: training on 393745 raw words (241340 effective words) took 0.1s, 2189192 effective words/s\n",
      "2023-04-18 16:56:40,750 : INFO : EPOCH 45: training on 393745 raw words (241261 effective words) took 0.1s, 2103178 effective words/s\n",
      "2023-04-18 16:56:40,865 : INFO : EPOCH 46: training on 393745 raw words (241548 effective words) took 0.1s, 2134842 effective words/s\n",
      "2023-04-18 16:56:40,983 : INFO : EPOCH 47: training on 393745 raw words (241927 effective words) took 0.1s, 2102249 effective words/s\n",
      "2023-04-18 16:56:41,099 : INFO : EPOCH 48: training on 393745 raw words (241812 effective words) took 0.1s, 2122733 effective words/s\n",
      "2023-04-18 16:56:41,217 : INFO : EPOCH 49: training on 393745 raw words (241305 effective words) took 0.1s, 2102755 effective words/s\n",
      "2023-04-18 16:56:41,333 : INFO : EPOCH 50: training on 393745 raw words (241092 effective words) took 0.1s, 2134154 effective words/s\n",
      "2023-04-18 16:56:41,450 : INFO : EPOCH 51: training on 393745 raw words (241768 effective words) took 0.1s, 2091757 effective words/s\n",
      "2023-04-18 16:56:41,566 : INFO : EPOCH 52: training on 393745 raw words (241358 effective words) took 0.1s, 2122633 effective words/s\n",
      "2023-04-18 16:56:41,681 : INFO : EPOCH 53: training on 393745 raw words (241389 effective words) took 0.1s, 2150480 effective words/s\n",
      "2023-04-18 16:56:41,795 : INFO : EPOCH 54: training on 393745 raw words (241894 effective words) took 0.1s, 2160796 effective words/s\n",
      "2023-04-18 16:56:41,908 : INFO : EPOCH 55: training on 393745 raw words (241670 effective words) took 0.1s, 2165574 effective words/s\n",
      "2023-04-18 16:56:42,020 : INFO : EPOCH 56: training on 393745 raw words (241304 effective words) took 0.1s, 2185564 effective words/s\n",
      "2023-04-18 16:56:42,141 : INFO : EPOCH 57: training on 393745 raw words (241615 effective words) took 0.1s, 2049812 effective words/s\n",
      "2023-04-18 16:56:42,256 : INFO : EPOCH 58: training on 393745 raw words (241424 effective words) took 0.1s, 2127035 effective words/s\n",
      "2023-04-18 16:56:42,390 : INFO : EPOCH 59: training on 393745 raw words (241358 effective words) took 0.1s, 1827489 effective words/s\n",
      "2023-04-18 16:56:42,507 : INFO : EPOCH 60: training on 393745 raw words (241635 effective words) took 0.1s, 2096165 effective words/s\n",
      "2023-04-18 16:56:42,627 : INFO : EPOCH 61: training on 393745 raw words (241496 effective words) took 0.1s, 2054521 effective words/s\n",
      "2023-04-18 16:56:42,739 : INFO : EPOCH 62: training on 393745 raw words (241205 effective words) took 0.1s, 2191912 effective words/s\n",
      "2023-04-18 16:56:42,858 : INFO : EPOCH 63: training on 393745 raw words (241807 effective words) took 0.1s, 2072029 effective words/s\n",
      "2023-04-18 16:56:42,974 : INFO : EPOCH 64: training on 393745 raw words (241530 effective words) took 0.1s, 2118025 effective words/s\n",
      "2023-04-18 16:56:43,091 : INFO : EPOCH 65: training on 393745 raw words (241478 effective words) took 0.1s, 2096223 effective words/s\n",
      "2023-04-18 16:56:43,206 : INFO : EPOCH 66: training on 393745 raw words (241220 effective words) took 0.1s, 2136437 effective words/s\n",
      "2023-04-18 16:56:43,321 : INFO : EPOCH 67: training on 393745 raw words (241353 effective words) took 0.1s, 2149780 effective words/s\n",
      "2023-04-18 16:56:43,435 : INFO : EPOCH 68: training on 393745 raw words (241710 effective words) took 0.1s, 2141367 effective words/s\n",
      "2023-04-18 16:56:43,551 : INFO : EPOCH 69: training on 393745 raw words (241426 effective words) took 0.1s, 2123300 effective words/s\n",
      "2023-04-18 16:56:43,667 : INFO : EPOCH 70: training on 393745 raw words (241604 effective words) took 0.1s, 2109611 effective words/s\n",
      "2023-04-18 16:56:43,784 : INFO : EPOCH 71: training on 393745 raw words (241437 effective words) took 0.1s, 2105597 effective words/s\n",
      "2023-04-18 16:56:43,905 : INFO : EPOCH 72: training on 393745 raw words (241311 effective words) took 0.1s, 2025600 effective words/s\n",
      "2023-04-18 16:56:44,020 : INFO : EPOCH 73: training on 393745 raw words (241574 effective words) took 0.1s, 2136203 effective words/s\n",
      "2023-04-18 16:56:44,138 : INFO : EPOCH 74: training on 393745 raw words (241376 effective words) took 0.1s, 2077783 effective words/s\n",
      "2023-04-18 16:56:44,257 : INFO : EPOCH 75: training on 393745 raw words (241310 effective words) took 0.1s, 2080947 effective words/s\n",
      "2023-04-18 16:56:44,368 : INFO : EPOCH 76: training on 393745 raw words (241175 effective words) took 0.1s, 2205684 effective words/s\n",
      "2023-04-18 16:56:44,484 : INFO : EPOCH 77: training on 393745 raw words (241809 effective words) took 0.1s, 2112646 effective words/s\n",
      "2023-04-18 16:56:44,597 : INFO : EPOCH 78: training on 393745 raw words (242082 effective words) took 0.1s, 2183772 effective words/s\n",
      "2023-04-18 16:56:44,708 : INFO : EPOCH 79: training on 393745 raw words (241822 effective words) took 0.1s, 2217053 effective words/s\n",
      "2023-04-18 16:56:44,819 : INFO : EPOCH 80: training on 393745 raw words (241448 effective words) took 0.1s, 2210767 effective words/s\n",
      "2023-04-18 16:56:44,934 : INFO : EPOCH 81: training on 393745 raw words (241622 effective words) took 0.1s, 2144562 effective words/s\n",
      "2023-04-18 16:56:45,054 : INFO : EPOCH 82: training on 393745 raw words (241552 effective words) took 0.1s, 2043980 effective words/s\n",
      "2023-04-18 16:56:45,169 : INFO : EPOCH 83: training on 393745 raw words (241131 effective words) took 0.1s, 2135343 effective words/s\n",
      "2023-04-18 16:56:45,284 : INFO : EPOCH 84: training on 393745 raw words (241656 effective words) took 0.1s, 2117605 effective words/s\n",
      "2023-04-18 16:56:45,406 : INFO : EPOCH 85: training on 393745 raw words (241805 effective words) took 0.1s, 2010541 effective words/s\n",
      "2023-04-18 16:56:45,521 : INFO : EPOCH 86: training on 393745 raw words (241424 effective words) took 0.1s, 2152798 effective words/s\n",
      "2023-04-18 16:56:45,636 : INFO : EPOCH 87: training on 393745 raw words (241771 effective words) took 0.1s, 2127382 effective words/s\n",
      "2023-04-18 16:56:45,765 : INFO : EPOCH 88: training on 393745 raw words (241129 effective words) took 0.1s, 1893954 effective words/s\n",
      "2023-04-18 16:56:45,880 : INFO : EPOCH 89: training on 393745 raw words (241542 effective words) took 0.1s, 2150297 effective words/s\n",
      "2023-04-18 16:56:45,881 : INFO : Doc2Vec lifecycle event {'msg': 'training on 35437050 raw words (21735051 effective words) took 10.6s, 2053104 effective words/s', 'datetime': '2023-04-18T16:56:45.881376', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "d2v_model = doc2vec.Doc2Vec(vector_size=120, min_count=10, epochs=90)\n",
    "\n",
    "# build the vocabulary\n",
    "d2v_model.build_vocab(data_train)\n",
    "\n",
    "# Train Doc2Vec model\n",
    "d2v_model.train(data_train, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22350791"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.similarity_unseen_docs(df_job.JobTitlePosition.loc[1607].split(), df_applicant.Position.loc[39348].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_job.DescriptionRequirement.map(str.split).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:26:48,643 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2023-04-18T16:26:48.643431', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = models.Word2Vec(min_count=20, window=2, vector_size=300, sample=6e-5,  alpha=0.03,  min_alpha=0.0007,  negative=20, workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:26:49,780 : INFO : collecting all words and their counts\n",
      "2023-04-18 16:26:49,781 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-18 16:26:49,791 : INFO : collected 1624 word types from a corpus of 104133 raw words and 1005 sentences\n",
      "2023-04-18 16:26:49,792 : INFO : Creating a fresh vocabulary\n",
      "2023-04-18 16:26:49,795 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=20 retains 609 unique words (37.50% of original 1624, drops 1015)', 'datetime': '2023-04-18T16:26:49.795381', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-18 16:26:49,795 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=20 leaves 98239 word corpus (94.34% of original 104133, drops 5894)', 'datetime': '2023-04-18T16:26:49.795381', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-18 16:26:49,799 : INFO : deleting the raw counts dictionary of 1624 items\n",
      "2023-04-18 16:26:49,800 : INFO : sample=6e-05 downsamples 609 most-common words\n",
      "2023-04-18 16:26:49,800 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 19239.575622160475 word corpus (19.6%% of prior 98239)', 'datetime': '2023-04-18T16:26:49.800839', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-18 16:26:49,804 : INFO : estimated required memory for 609 words and 300 dimensions: 1766100 bytes\n",
      "2023-04-18 16:26:49,805 : INFO : resetting layer weights\n",
      "2023-04-18 16:26:49,806 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-18T16:26:49.806836', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(texts, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:26:51,422 : INFO : Word2Vec lifecycle event {'msg': 'training model with 15 workers on 609 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2 shrink_windows=True', 'datetime': '2023-04-18T16:26:51.421296', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-18 16:26:51,454 : INFO : EPOCH 0: training on 104133 raw words (19157 effective words) took 0.0s, 743808 effective words/s\n",
      "2023-04-18 16:26:51,485 : INFO : EPOCH 1: training on 104133 raw words (19146 effective words) took 0.0s, 788953 effective words/s\n",
      "2023-04-18 16:26:51,521 : INFO : EPOCH 2: training on 104133 raw words (19135 effective words) took 0.0s, 807234 effective words/s\n",
      "2023-04-18 16:26:51,553 : INFO : EPOCH 3: training on 104133 raw words (19377 effective words) took 0.0s, 916569 effective words/s\n",
      "2023-04-18 16:26:51,585 : INFO : EPOCH 4: training on 104133 raw words (19174 effective words) took 0.0s, 766837 effective words/s\n",
      "2023-04-18 16:26:51,618 : INFO : EPOCH 5: training on 104133 raw words (19347 effective words) took 0.0s, 775248 effective words/s\n",
      "2023-04-18 16:26:51,649 : INFO : EPOCH 6: training on 104133 raw words (19170 effective words) took 0.0s, 804887 effective words/s\n",
      "2023-04-18 16:26:51,681 : INFO : EPOCH 7: training on 104133 raw words (19344 effective words) took 0.0s, 785463 effective words/s\n",
      "2023-04-18 16:26:51,716 : INFO : EPOCH 8: training on 104133 raw words (19143 effective words) took 0.0s, 821694 effective words/s\n",
      "2023-04-18 16:26:51,753 : INFO : EPOCH 9: training on 104133 raw words (19330 effective words) took 0.0s, 747128 effective words/s\n",
      "2023-04-18 16:26:51,785 : INFO : EPOCH 10: training on 104133 raw words (19301 effective words) took 0.0s, 791057 effective words/s\n",
      "2023-04-18 16:26:51,815 : INFO : EPOCH 11: training on 104133 raw words (19221 effective words) took 0.0s, 793600 effective words/s\n",
      "2023-04-18 16:26:51,846 : INFO : EPOCH 12: training on 104133 raw words (19108 effective words) took 0.0s, 741543 effective words/s\n",
      "2023-04-18 16:26:51,878 : INFO : EPOCH 13: training on 104133 raw words (19178 effective words) took 0.0s, 757048 effective words/s\n",
      "2023-04-18 16:26:51,908 : INFO : EPOCH 14: training on 104133 raw words (19240 effective words) took 0.0s, 818692 effective words/s\n",
      "2023-04-18 16:26:51,938 : INFO : EPOCH 15: training on 104133 raw words (19092 effective words) took 0.0s, 799046 effective words/s\n",
      "2023-04-18 16:26:51,970 : INFO : EPOCH 16: training on 104133 raw words (19158 effective words) took 0.0s, 867306 effective words/s\n",
      "2023-04-18 16:26:52,000 : INFO : EPOCH 17: training on 104133 raw words (19346 effective words) took 0.0s, 855057 effective words/s\n",
      "2023-04-18 16:26:52,030 : INFO : EPOCH 18: training on 104133 raw words (19349 effective words) took 0.0s, 777168 effective words/s\n",
      "2023-04-18 16:26:52,059 : INFO : EPOCH 19: training on 104133 raw words (19219 effective words) took 0.0s, 839551 effective words/s\n",
      "2023-04-18 16:26:52,089 : INFO : EPOCH 20: training on 104133 raw words (19181 effective words) took 0.0s, 834109 effective words/s\n",
      "2023-04-18 16:26:52,120 : INFO : EPOCH 21: training on 104133 raw words (19173 effective words) took 0.0s, 912644 effective words/s\n",
      "2023-04-18 16:26:52,152 : INFO : EPOCH 22: training on 104133 raw words (19252 effective words) took 0.0s, 766603 effective words/s\n",
      "2023-04-18 16:26:52,183 : INFO : EPOCH 23: training on 104133 raw words (18921 effective words) took 0.0s, 770242 effective words/s\n",
      "2023-04-18 16:26:52,216 : INFO : EPOCH 24: training on 104133 raw words (19094 effective words) took 0.0s, 746974 effective words/s\n",
      "2023-04-18 16:26:52,253 : INFO : EPOCH 25: training on 104133 raw words (19329 effective words) took 0.0s, 660744 effective words/s\n",
      "2023-04-18 16:26:52,286 : INFO : EPOCH 26: training on 104133 raw words (19243 effective words) took 0.0s, 799081 effective words/s\n",
      "2023-04-18 16:26:52,318 : INFO : EPOCH 27: training on 104133 raw words (19243 effective words) took 0.0s, 867759 effective words/s\n",
      "2023-04-18 16:26:52,347 : INFO : EPOCH 28: training on 104133 raw words (19204 effective words) took 0.0s, 823538 effective words/s\n",
      "2023-04-18 16:26:52,379 : INFO : EPOCH 29: training on 104133 raw words (19281 effective words) took 0.0s, 834181 effective words/s\n",
      "2023-04-18 16:26:52,379 : INFO : Word2Vec lifecycle event {'msg': 'training on 3123990 raw words (576456 effective words) took 1.0s, 602123 effective words/s', 'datetime': '2023-04-18T16:26:52.379632', 'gensim': '4.3.1', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(576456, 3123990)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(texts, total_examples=model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eats\\AppData\\Local\\Temp\\ipykernel_6088\\1992334471.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n",
      "2023-04-18 16:26:53,910 : WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'teknologi hukum' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mwv\u001b[39m.\u001b[39;49msimilarity(\u001b[39m'\u001b[39;49m\u001b[39mkembang\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mteknologi hukum\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\eats\\miniconda3\\envs\\p1\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1234\u001b[0m, in \u001b[0;36mKeyedVectors.similarity\u001b[1;34m(self, w1, w2)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity\u001b[39m(\u001b[39mself\u001b[39m, w1, w2):\n\u001b[0;32m   1219\u001b[0m     \u001b[39m\"\"\"Compute cosine similarity between two keys.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \n\u001b[0;32m   1233\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1234\u001b[0m     \u001b[39mreturn\u001b[39;00m dot(matutils\u001b[39m.\u001b[39munitvec(\u001b[39mself\u001b[39m[w1]), matutils\u001b[39m.\u001b[39munitvec(\u001b[39mself\u001b[39;49m[w2]))\n",
      "File \u001b[1;32mc:\\Users\\eats\\miniconda3\\envs\\p1\\lib\\site-packages\\gensim\\models\\keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[0;32m    391\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[1;32m--> 403\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_vector(key_or_keys)\n\u001b[0;32m    405\u001b[0m \u001b[39mreturn\u001b[39;00m vstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_vector(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m key_or_keys])\n",
      "File \u001b[1;32mc:\\Users\\eats\\miniconda3\\envs\\p1\\lib\\site-packages\\gensim\\models\\keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_vector\u001b[39m(\u001b[39mself\u001b[39m, key, norm\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    423\u001b[0m     \u001b[39m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \n\u001b[0;32m    425\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m \n\u001b[0;32m    445\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_index(key)\n\u001b[0;32m    447\u001b[0m     \u001b[39mif\u001b[39;00m norm:\n\u001b[0;32m    448\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_norms()\n",
      "File \u001b[1;32mc:\\Users\\eats\\miniconda3\\envs\\p1\\lib\\site-packages\\gensim\\models\\keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m default\n\u001b[0;32m    419\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not present\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'teknologi hukum' not present\""
     ]
    }
   ],
   "source": [
    "model.wv.infe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'riset'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant.DescriptionStrengthness.loc[39348].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ios pengembang teknologi informasi'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job.JobTitlePosition.loc[3060]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teknologi informasi teknologi informasi teknologi informasi'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant.Position.loc[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015874676"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.similarity_unseen_docs([df_job.JobTitlePosition.loc[1607]], [df_applicant.Position.loc[39348]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ExpectedSalary</th>\n",
       "      <th>YearsOfExperience</th>\n",
       "      <th>IsUsingGlasses</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ProvinceName</th>\n",
       "      <th>EducationLevelName</th>\n",
       "      <th>MajorName</th>\n",
       "      <th>DriverLicenseType</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Position</th>\n",
       "      <th>DescriptionStrengthness</th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApplicantID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39348</th>\n",
       "      <td>25</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>false</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>s1</td>\n",
       "      <td>teknik informatika</td>\n",
       "      <td>c</td>\n",
       "      <td>male</td>\n",
       "      <td>single</td>\n",
       "      <td>ios pengembang</td>\n",
       "      <td>riset dan masalah validation ada umum dan doma...</td>\n",
       "      <td>ios pengembang riset dan masalah validation ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age  ExpectedSalary  YearsOfExperience IsUsingGlasses  CityName  \\\n",
       "ApplicantID                                                                    \n",
       "39348         25       6000000.0           0.833333          false  surabaya   \n",
       "\n",
       "            ProvinceName EducationLevelName           MajorName  \\\n",
       "ApplicantID                                                       \n",
       "39348         jawa timur                 s1  teknik informatika   \n",
       "\n",
       "            DriverLicenseType Gender MaritalStatus        Position  \\\n",
       "ApplicantID                                                          \n",
       "39348                       c   male        single  ios pengembang   \n",
       "\n",
       "                                       DescriptionStrengthness  \\\n",
       "ApplicantID                                                      \n",
       "39348        riset dan masalah validation ada umum dan doma...   \n",
       "\n",
       "                                                         Texts  \n",
       "ApplicantID                                                     \n",
       "39348        ios pengembang riset dan masalah validation ad...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant[df_applicant.Position.str.contains('ios')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UsiaMax</th>\n",
       "      <th>SalaryMin</th>\n",
       "      <th>SalaryMax</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ProvinceName</th>\n",
       "      <th>EducationLevelName</th>\n",
       "      <th>MajorName</th>\n",
       "      <th>DriverLicenseType</th>\n",
       "      <th>UsingGlasses</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>JobTitlePosition</th>\n",
       "      <th>DescriptionRequirement</th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>d3</td>\n",
       "      <td>teknik informatika</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ios pengembang website pembuat program</td>\n",
       "      <td>kembang aplikasi ios dan integrasi dengan laya...</td>\n",
       "      <td>ios pengembang website pembuat program kembang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>d3</td>\n",
       "      <td>teknik informatika</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ios pengembang website pembuat program</td>\n",
       "      <td>kembang aplikasi ios dan integrasi dengan laya...</td>\n",
       "      <td>ios pengembang website pembuat program kembang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>d3</td>\n",
       "      <td>teknik informatika</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ios pengembang teknologi informasi</td>\n",
       "      <td>kembang aplikasi ios dan integrasi dengan laya...</td>\n",
       "      <td>ios pengembang teknologi informasi kembang apl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>d3</td>\n",
       "      <td>teknik komputer</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ios pengembang teknologi informasi</td>\n",
       "      <td>kembang aplikasi ios dan integrasi dengan laya...</td>\n",
       "      <td>ios pengembang teknologi informasi kembang apl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UsiaMax  SalaryMin  SalaryMax  CityName ProvinceName EducationLevelName  \\\n",
       "JobID                                                                           \n",
       "1607      0.0        0.0        0.0  surabaya   jawa timur                 d3   \n",
       "2753      0.0        0.0        0.0  surabaya   jawa timur                 d3   \n",
       "2756      0.0        0.0        0.0  surabaya   jawa timur                 d3   \n",
       "3060      0.0        0.0        0.0  surabaya   jawa timur                 d3   \n",
       "\n",
       "                MajorName DriverLicenseType UsingGlasses Gender MaritalStatus  \\\n",
       "JobID                                                                           \n",
       "1607   teknik informatika                          False                        \n",
       "2753   teknik informatika                          False                        \n",
       "2756   teknik informatika                          False                        \n",
       "3060      teknik komputer                          False                        \n",
       "\n",
       "                             JobTitlePosition  \\\n",
       "JobID                                           \n",
       "1607   ios pengembang website pembuat program   \n",
       "2753   ios pengembang website pembuat program   \n",
       "2756       ios pengembang teknologi informasi   \n",
       "3060       ios pengembang teknologi informasi   \n",
       "\n",
       "                                  DescriptionRequirement  \\\n",
       "JobID                                                      \n",
       "1607   kembang aplikasi ios dan integrasi dengan laya...   \n",
       "2753   kembang aplikasi ios dan integrasi dengan laya...   \n",
       "2756   kembang aplikasi ios dan integrasi dengan laya...   \n",
       "3060   kembang aplikasi ios dan integrasi dengan laya...   \n",
       "\n",
       "                                                   Texts  \n",
       "JobID                                                     \n",
       "1607   ios pengembang website pembuat program kembang...  \n",
       "2753   ios pengembang website pembuat program kembang...  \n",
       "2756   ios pengembang teknologi informasi kembang apl...  \n",
       "3060   ios pengembang teknologi informasi kembang apl...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job[df_job.JobTitlePosition.str.contains('ios')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ApplicantID\n",
       "3        penjualan eksekutif whole penjualan credit pem...\n",
       "13       teknologi informasi teknologi informasi teknol...\n",
       "21             java website pengembang android pengembang \n",
       "22                                asisten dosen supervisor\n",
       "25                     pemula progammer progammer  analis \n",
       "                               ...                        \n",
       "40027                                            pengemudi\n",
       "40031                                     hukum kordinator\n",
       "40033                                        hukum petugas\n",
       "41402    senior data pelayanan resepsionis cum administ...\n",
       "43028                                            pengemudi\n",
       "Name: Position, Length: 3629, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant.Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
