{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eats\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from transformx import remove_html, maintain_alpha, remove_single, remove_morespace, remove_enumerate, clean_text, remove_insideparentheses, remove_standalonesymbols, stopwords_remover\n",
    "\n",
    "from eris import ErisRecommender\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(stopwords, text):\n",
    "    list_text = text.split(' ')\n",
    "\n",
    "    for text in list_text:\n",
    "        if text in stopwords:\n",
    "            list_text.remove(text)\n",
    "            # print(text)\n",
    "    return ' '.join(list_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'huda'\n",
    "password = 'Vancha12'\n",
    "host = '127.0.0.1'\n",
    "port = 1433\n",
    "database = 'HRSystemDB'\n",
    "\n",
    "\n",
    "def get_connection():         \n",
    "    return create_engine(\n",
    "        url=f\"mssql+pyodbc://{user}:{password}@{host}:{port}/{database}?driver=SQL Server\",\n",
    "    )\n",
    "\n",
    "engine = get_connection()\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicant = pd.DataFrame(engine.execute('SELECT ApplicantID, DiseaseHistory, Dob, ExpectedSalary, IsAbleToWorkRemote, CityID, ProvinceID, DriverLicenseType, Gender, IsUsingGlasses, Height, MaritalStatus, Nationality, Strengthness, Weaknesses, TypeOfVehicle FROM Applicant'))\n",
    "df_applicant_education = pd.DataFrame(engine.execute('SELECT ApplicantEducationID, ApplicantID, DateStart, DateEnd, EducationInstituteName, Score, EducationLevelID, MajorID, Degree FROM ApplicantEducation'))\n",
    "df_applicant_experience = pd.DataFrame(engine.execute('SELECT ApplicantExperienceID, ApplicantID, DateFrom, DateTo, Industry, CompanyName, JobDescription, Position, Salary FROM ApplicantExperience'))\n",
    "df_applicant_document = pd.DataFrame(engine.execute('SELECT ApplicantID, DocumentName FROM ApplicantDocument'))\n",
    "df_applicant_certificate = pd.DataFrame(engine.execute('SELECT ApplicantID, Description FROM ApplicantCertificate'))\n",
    "\n",
    "df_pipeline = pd.DataFrame(engine.execute('SELECT PipelineID, ApplicantID, JobID, StageID FROM Pipeline'))\n",
    "df_stage = pd.DataFrame(engine.execute('SELECT StageID, Label FROM Stage'))\n",
    "\n",
    "df_job = pd.DataFrame(engine.execute('SELECT * FROM Job'))\n",
    "df_function_position = pd.DataFrame(engine.execute('SELECT FunctionPositionID, FunctionPositionName FROM FunctionPosition'))\n",
    "df_department = pd.DataFrame(engine.execute('SELECT DepartmentID, Name AS DepartmentName FROM Department'))\n",
    "df_city = pd.DataFrame(engine.execute('SELECT CityID, Name AS CityName FROM City'))\n",
    "df_province = pd.DataFrame(engine.execute('SELECT ProvinceID, Name AS ProvinceName FROM Province'))\n",
    "df_major = pd.DataFrame(engine.execute('SELECT MajorID, MajorName FROM Major'))\n",
    "df_education_level = pd.DataFrame(engine.execute('SELECT EducationLevelID, EducationLevelName FROM EducationLevel'))\n",
    "df_company = pd.DataFrame(engine.execute('SELECT CompanyID, Name AS CompanyName FROM Company'))\n",
    "\n",
    "# df_job = df_job[['JobID', 'Description', 'EducationLevelID', 'FunctionPositionID', 'DepartmentID', 'JobTitle', 'Requirement', 'CityID', 'ProvinceID', 'MajorID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_job.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fillna'''\n",
    "df_job.Description.fillna('', inplace=True)\n",
    "df_job.Requirement.fillna('', inplace=True)\n",
    "\n",
    "'''merge'''\n",
    "job_merged = pd.merge(df_job, df_education_level, on=['EducationLevelID'])\n",
    "job_merged = pd.merge(job_merged, df_city, on=['CityID'])\n",
    "job_merged = pd.merge(job_merged, df_province, on=['ProvinceID'])\n",
    "job_merged = pd.merge(job_merged, df_function_position, on=['FunctionPositionID'])\n",
    "job_merged = pd.merge(job_merged, df_department, on=['DepartmentID'])\n",
    "job_merged = pd.merge(job_merged, df_major, on=['MajorID'])\n",
    "\n",
    "job_merged.drop(columns=['EducationLevelID', 'CityID', 'ProvinceID', 'FunctionPositionID', 'DepartmentID', 'MajorID'], inplace=True)\n",
    "\n",
    "job_merged.drop(\n",
    "    index=job_merged.index[job_merged.JobTitle.map(str.lower).str.contains('test|123')].values, inplace=True\n",
    ")\n",
    "\n",
    "job_merged = job_merged[['JobID', 'JobTitle', 'FunctionPositionName', 'EducationLevelName', 'CityName', 'ProvinceName', 'Description', 'Requirement', 'MajorName']]\n",
    "\n",
    "\n",
    "'''cleansing'''\n",
    "job_merged.Description = job_merged.Description.map(clean_text)\n",
    "\n",
    "job_merged.Requirement = job_merged.Requirement.map(remove_html).map(remove_enumerate).map(maintain_alpha).map(remove_single).map(remove_morespace).map(str.strip).map(str.lower)\n",
    "\n",
    "job_merged.JobTitle = job_merged.JobTitle.map(str.lower).map(remove_insideparentheses).map(remove_standalonesymbols).map(remove_morespace)\n",
    "\n",
    "job_merged.EducationLevelName = job_merged.EducationLevelName.replace('None', '').map(str.lower)\n",
    "\n",
    "job_merged.CityName = job_merged.CityName.map(str.lower)\n",
    "job_merged.ProvinceName = job_merged.ProvinceName.map(str.lower)\n",
    "\n",
    "job_merged.FunctionPositionName = job_merged.FunctionPositionName.map(remove_standalonesymbols).apply(lambda x: re.sub('[\\(\\)0-9]', '', x)).map(remove_morespace).map(str.strip).map(str.lower)\n",
    "\n",
    "job_merged.MajorName = job_merged.MajorName.map(str.lower)\n",
    "\n",
    "\n",
    "'''stopwords'''\n",
    "sastrawi_stopwords = StopWordRemoverFactory().get_stop_words()\n",
    "nltk_stopwords_in =  stopwords.words('indonesian')\n",
    "nltk_stopwords_en =  stopwords.words('english')\n",
    "user_stopwords = ['perusahaan', 'sesuai', 'become', 'becoming', 'gunawangsa', 'hotel', 'merr']\n",
    "\n",
    "stopwords_in = list(set(sastrawi_stopwords + nltk_stopwords_in + nltk_stopwords_en + user_stopwords))\n",
    "\n",
    "'''cleansing'''\n",
    "# cara 1\n",
    "job_merged.Description = job_merged.Description.apply(lambda x: re.sub('\\s+', '   ', '   ' + x + '   ')).apply(lambda x: re.sub('(' + ' | '.join(stopwords_in) + ')', ' ', x)).map(remove_morespace).map(str.strip)\n",
    "\n",
    "# cara 2\n",
    "# job_merged.Description.apply(lambda x: remove_stopwords(stopwords_in, x))\n",
    "\n",
    "job_merged.Requirement = job_merged.Requirement.apply(lambda x: re.sub('\\s+', '   ', '   ' + x + '   ')).apply(lambda x: re.sub('(' + ' | '.join(stopwords_in) + ')', ' ', x)).map(remove_morespace).map(str.strip)\n",
    "\n",
    "'''concatenation'''\n",
    "# job_merged = job_merged.set_index(['JobID'])\n",
    "\n",
    "job_train = pd.DataFrame([], index=job_merged.index)\n",
    "\n",
    "job_train['Text'] = job_merged.JobTitle.str.cat(\n",
    "    job_merged.FunctionPositionName.str.cat(\n",
    "        job_merged.EducationLevelName.str.cat(\n",
    "            job_merged.MajorName.str.cat(\n",
    "                job_merged.CityName.str.cat(\n",
    "                    job_merged.ProvinceName.str.cat(\n",
    "                        job_merged.Description.str.cat(\n",
    "                            job_merged.Requirement\n",
    "                        , sep=' ')\n",
    "                    , sep=' ')\n",
    "                , sep=' ')\n",
    "            , sep=' ')\n",
    "        , sep=' ')\n",
    "    , sep=' ')\n",
    ", sep=' ')\n",
    "\n",
    "'''recommender'''\n",
    "encoder = TfidfVectorizer(vocabulary=)\n",
    "bank = encoder.fit_transform(job_train.Text)\n",
    "\n",
    "# code = encoder.transform(job_train.Text)\n",
    "# dist = cosine_similarity(code, bank)[0]*100\n",
    "\n",
    "eris = ErisRecommender(job_merged, job_train.copy(), 'Text')\n",
    "eris.fit()\n",
    "eris.recommend('android')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicant = pd.read_csv('data/cdf_applicant.csv')\n",
    "df_applicant_experience = pd.read_csv('data/cdf_applicant_experience.csv')\n",
    "df_applicant_experience.fillna('', inplace=True)\n",
    "df_applicant_education = pd.read_csv('data/cdf_applicant_education.csv')\n",
    "\n",
    "df_city = pd.read_csv('data/df_city.csv')\n",
    "df_province = pd.read_csv('data/df_province.csv')\n",
    "\n",
    "df_applicant_education = pd.merge(df_applicant_education, df_education_level, on=['EducationLevelID'])\n",
    "df_applicant_education = pd.merge(df_applicant_education, df_major, on=['MajorID'])\n",
    "df_applicant_education = df_applicant_education[['ApplicantID', 'EducationLevelName', 'MajorName']]\n",
    "\n",
    "df_applicant = df_applicant[['ApplicantID', 'Age', 'CityID', 'ProvinceID', 'Strengthness', 'Weaknesses']]\n",
    "df_applicant_experience = df_applicant_experience[['ApplicantID', 'Industry', 'JobDescription', 'Position', 'YearsOfExperience']]\n",
    "\n",
    "app_merged = pd.merge(df_applicant, df_applicant_experience, on=['ApplicantID'])\n",
    "app_merged = pd.merge(app_merged, df_city, on=['CityID'])\n",
    "app_merged = pd.merge(app_merged, df_province, on=['ProvinceID'])\n",
    "app_merged = pd.merge(app_merged, df_applicant_education, on=['ApplicantID'])\n",
    "app_merged.drop(columns=['CityID', 'ProvinceID'], inplace=True)\n",
    "\n",
    "'''menjadi text feature'''\n",
    "app_merged.Age = app_merged.Age.apply(lambda x: 'usia ' + str(x) + ' tahun' if x != 0 else '')\n",
    "app_merged.YearsOfExperience = app_merged.YearsOfExperience.apply(lambda x: 'pengalaman ' + str(x) + ' tahun' if x != 0 else '')\n",
    "app_merged.EducationLevelName = app_merged.EducationLevelName.apply(lambda x: 'lulusan ' + x.lower())\n",
    "app_merged.MajorName = app_merged.MajorName.map(str.lower)\n",
    "\n",
    "app_merged.Strengthness = app_merged.Strengthness.map(clean_text)\n",
    "app_merged.Weaknesses = app_merged.Weaknesses.map(clean_text)\n",
    "\n",
    "app_merged.Strengthness = app_merged.Strengthness.apply(lambda x: re.sub('\\s+', '   ', '   ' + x + '   ')).apply(lambda x: re.sub('(' + ' | '.join(stopwords_in) + ')', ' ', x)).map(remove_morespace).map(str.strip)\n",
    "app_merged.Weaknesses = app_merged.Weaknesses.apply(lambda x: re.sub('\\s+', '   ', '   ' + x + '   ')).apply(lambda x: re.sub('(' + ' | '.join(stopwords_in) + ')', ' ', x)).map(remove_morespace).map(str.strip)\n",
    "app_merged.JobDescription = app_merged.JobDescription.apply(lambda x: re.sub('\\s+', '   ', '   ' + x + '   ')).apply(lambda x: re.sub('(' + ' | '.join(stopwords_in) + ')', ' ', x)).map(remove_morespace).map(str.strip)\n",
    "\n",
    "'''concatenate'''\n",
    "app_train = pd.DataFrame([], index=app_merged.index)\n",
    "\n",
    "app_train['Text'] = app_merged.Position.str.cat(\n",
    "    app_merged.EducationLevelName.str.cat(\n",
    "        app_merged.MajorName.str.cat(\n",
    "            app_merged.CityName.str.cat(\n",
    "                app_merged.ProvinceName.str.cat(\n",
    "                    app_merged.Age.str.cat(\n",
    "                        app_merged.YearsOfExperience.str.cat(\n",
    "                            app_merged.Strengthness.str.cat(\n",
    "                                app_merged.Weaknesses.str.cat(\n",
    "                                    app_merged.JobDescription\n",
    "                                , sep=' ')\n",
    "                            , sep=' ')\n",
    "                        , sep=' ')\n",
    "                    , sep=' ')\n",
    "                , sep=' ')\n",
    "            , sep=' ')\n",
    "        , sep=' ')\n",
    "    , sep=' ')\n",
    ", sep=' ')\n",
    "\n",
    "\n",
    "'''recommender'''\n",
    "app_encoder = TfidfVectorizer()\n",
    "app_bank = app_encoder.fit_transform(app_train.Text)\n",
    "\n",
    "job_encoder = TfidfVectorizer()\n",
    "job_bank = job_encoder.fit_transform(job_train.Text)\n",
    "\n",
    "codes = job_encoder.transform([app_train.Text[0]])\n",
    "dist = cosine_similarity(codes, job_bank).T\n",
    "\n",
    "job_merged['Similarity'] = dist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemiripan applicant dan job harus ditingkatkan dengan nilai similarity. Pada hasil tersebut, nilai similaritynya 0.2 atau 20% meskipun track recordnya sangat sesuai. Normalnya bisa mencapai 75% ke atas. Untuk mendapatkan hal demikian diperlukan cleansing yang lebih akurat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Done, tinggal menambahkan improvement!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd510ecb61bc7b7b9b22deac1a7e1bf8f3fb19926c5bfcf2a8f3dfec3d6e7c3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
