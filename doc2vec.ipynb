{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import re\n",
    "import json\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix, WordEmbeddingSimilarityIndex\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "from googletrans import Translator\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from FlaskApp.transform import *\n",
    "\n",
    "from job_model import JobModel\n",
    "from app_model import AppModel\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = nltk.corpus.stopwords.words('indonesian')\n",
    "sastrawi_stopwords = StopWordRemoverFactory().get_stop_words()\n",
    "combined_stopwords = nltk_stopwords + sastrawi_stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "rootwords = [i[0] for i in pd.read_csv('data/rootwords.txt').values]\n",
    "stopwords = [i[0] for i in pd.read_csv('data/stopwords.csv').values]\n",
    "\n",
    "with open('data/slangwords.json', 'r') as file:\n",
    "    slangwords = json.load(file)\n",
    "\n",
    "with open('data/englishwords.json', 'r') as file:\n",
    "    englishwords = json.load(file)\n",
    "\n",
    "with open('data/slangjobs.json', 'r') as file:\n",
    "    slangjobs = json.load(file)\n",
    "\n",
    "with open('data/job_slangwords_phase1.json', 'r') as file:\n",
    "    job_slangwords_phase1 = json.load(file)\n",
    "\n",
    "with open('data/job_slangwords_phase2.json', 'r') as file:\n",
    "    job_slangwords_phase2 = json.load(file)\n",
    "\n",
    "job_stopwords = [i[0] for i in pd.read_csv('data/job_stopwords.txt').values]\n",
    "\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(stopwords: list, text: str):\n",
    "    list_text = text.split()\n",
    "\n",
    "    new_text = []\n",
    "    for word in list_text:\n",
    "        if word not in stopwords:\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'huda'\n",
    "password = 'Vancha12'\n",
    "host = '127.0.0.1'\n",
    "port = 1433\n",
    "database = 'HRSystemDB'\n",
    "\n",
    "\n",
    "def get_connection():         \n",
    "    return create_engine(\n",
    "        url=f\"mssql+pyodbc://{user}:{password}@{host}:{port}/{database}?driver=SQL Server\",\n",
    "    )\n",
    "\n",
    "engine = get_connection()\n",
    "conn = engine.connect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT Job.JobID, Job.UsiaMax, Job.SalaryMin, Job.SalaryMax, City.Name AS CityName, Province.Name AS ProvinceName, EducationLevel.EducationLevelName, Major.MajorName, Job.DriverLicenseType, Job.UsingGlasses, Job.Gender, Job.MaritalStatus, Job.JobTitle, FunctionPosition.FunctionPositionName, Job.Description, Job.Requirement\n",
    "    FROM (((((Job\n",
    "    RIGHT JOIN FunctionPosition ON Job.FunctionPositionID = FunctionPosition.FunctionPositionID)\n",
    "    RIGHT JOIN EducationLevel ON Job.EducationLevelID = EducationLevel.EducationLevelID)\n",
    "    RIGHT JOIN City ON Job.CityID = City.CityID)\n",
    "    RIGHT JOIN Province ON Job.ProvinceID = Province.ProvinceID)\n",
    "    RIGHT JOIN Major ON Job.MajorID = Major.MajorID)\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant_experience = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT ApplicantExperience.ApplicantID, ApplicantExperience.DateFrom, ApplicantExperience.DateTo, ApplicantExperience.Position, ApplicantExperience.JobDescription\n",
    "    FROM (ApplicantExperience\n",
    "    LEFT JOIN Pipeline ON ApplicantExperience.ApplicantID = Pipeline.ApplicantID)\n",
    "    \"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_str = ['CityName', 'ProvinceName', 'EducationLevelName', 'MajorName', 'DriverLicenseType', 'Gender', 'MaritalStatus', 'JobTitle', 'FunctionPositionName', 'Description', 'Requirement']\n",
    "job_num = ['UsiaMax', 'SalaryMin', 'SalaryMax']\n",
    "job_bol = ['UsingGlasses']\n",
    "\n",
    "'''general'''\n",
    "df_job.set_index(['JobID'], inplace=True)\n",
    "df_job.fillna('', inplace=True)\n",
    "\n",
    "'''str'''\n",
    "df_job[job_str] = df_job[job_str].applymap(str.lower)\n",
    "df_job.replace('none', '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''experience'''\n",
    "df_applicant_experience = df_applicant_experience.fillna('')\n",
    "\n",
    "# datetime column\n",
    "df_applicant_experience.DateFrom = pd.to_datetime(\n",
    "    df_applicant_experience.DateFrom.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_experience.DateTo = pd.to_datetime(\n",
    "    df_applicant_experience.DateTo.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_experience = df_applicant_experience[~(df_applicant_experience.DateFrom.isna()) & ~(df_applicant_experience.DateTo.isna())]\n",
    "\n",
    "# add YearsOfExperience column\n",
    "df_applicant_experience['YearsOfExperience'] = substract_months(\n",
    "    df_applicant_experience.DateFrom, df_applicant_experience.DateTo\n",
    ")\n",
    "df_applicant_experience = df_applicant_experience.sort_values('DateFrom').groupby(['ApplicantID']).agg({\n",
    "    'DateFrom': 'last',\n",
    "    'DateTo': 'last',\n",
    "    'JobDescription': ' '.join,\n",
    "    'Position': ' '.join,\n",
    "    'YearsOfExperience': 'sum',\n",
    "})\n",
    "df_applicant_experience.drop(columns=['DateFrom', 'DateTo'], inplace=True)\n",
    "\n",
    "df_applicant_experience = df_applicant_experience[df_applicant_experience.YearsOfExperience != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = df_job[['JobTitle', 'Description', 'Requirement']]\n",
    "df_applicant_experience = df_applicant_experience[['Position', 'JobDescription']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job['DescriptionRequirement'] = df_job.Description + ' ' + df_job.Requirement\n",
    "df_job.drop(columns=['Description', 'Requirement'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicant_experience = df_applicant_experience.applymap(str.lower)\n",
    "df_job = df_job.applymap(str.lower)\n",
    "\n",
    "df_job.DescriptionRequirement = df_job.DescriptionRequirement.map(clean_text)\n",
    "df_applicant_experience.JobDescription = df_applicant_experience.JobDescription.map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job.DescriptionRequirement = df_job.DescriptionRequirement.apply(lambda x: ' '.join([i for i in x.split() if i not in job_stopwords]))\n",
    "df_job.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_job.to_csv('data/lihat_job.csv', sep=';')\n",
    "# df_applicant_experience.to_csv('data/lihat_experience.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicant_experience.rename(columns={'Position': 'JobTitle', 'JobDescription': 'DescriptionRequirement'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([df_job, df_applicant_experience]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.JobTitle = train_data.JobTitle.map(\n",
    "    str.lower\n",
    ").map(\n",
    "    remove_parenthesesnumber\n",
    ").map(\n",
    "    remove_standalonesymbols\n",
    ").map(\n",
    "    remove_morespace\n",
    ").map(\n",
    "    str.strip\n",
    ").apply(\n",
    "    lambda x: ' '.join(list(set(x.split())))\n",
    ").apply(\n",
    "    lambda x: change_words(job_slangwords_phase1, x)\n",
    ").apply(\n",
    "    lambda x: remove_stopwords(job_stopwords, x)\n",
    ").map(\n",
    "    clean_text\n",
    ").apply(\n",
    "    lambda x: change_words(job_slangwords_phase2, x)\n",
    ")\n",
    "\n",
    "train_data.DescriptionRequirement = train_data.DescriptionRequirement.map(\n",
    "    clean_text\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(englishwords, x)\n",
    ").apply(\n",
    "    lambda x: ' '.join([i for i in x.split() if i not in combined_stopwords])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_data.DescriptionRequirement.map(str.split).values\n",
    "\n",
    "data = []\n",
    "for word in dataset:\n",
    "    data.append(word)\n",
    "\n",
    "def tagged_document(list_of_listwords, tags=None):\n",
    "    if tags is not None:\n",
    "        for x, listwords in zip(tags, list_of_listwords):\n",
    "            yield doc2vec.TaggedDocument(listwords, [x])\n",
    "    else:\n",
    "        for x, listwords in enumerate(list_of_listwords):\n",
    "            yield doc2vec.TaggedDocument(listwords, [x])\n",
    "\n",
    "data_train = list(tagged_document(data, train_data.JobTitle.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = doc2vec.Doc2Vec(vector_size=120, min_count=10, epochs=60, window=3)\n",
    "d2v_model.build_vocab(data_train)\n",
    "d2v_model.train(data_train, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_words = d2v_model.wv.index_to_key\n",
    "d2v_vectors = d2v_model.wv.vectors\n",
    "\n",
    "with open('data/d2v_vectors.tsv', 'w', encoding='utf-8') as f:\n",
    "    for i, word in enumerate(d2v_words):\n",
    "        vector_str = '\\t'.join([str(num) for num in d2v_vectors[i]])\n",
    "        f.write(f'{vector_str}\\n')\n",
    "\n",
    "with open('data/d2v_metadata.tsv', 'w', encoding='utf-8') as f:\n",
    "    for word in d2v_words:\n",
    "        f.write(f'{word}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job.JobTitle = df_job.JobTitle.map(\n",
    "    str.lower\n",
    ").map(\n",
    "    remove_parenthesesnumber\n",
    ").map(\n",
    "    remove_standalonesymbols\n",
    ").map(\n",
    "    remove_morespace\n",
    ").map(\n",
    "    str.strip\n",
    ").apply(\n",
    "    lambda x: ' '.join(list(set(x.split())))\n",
    ").apply(\n",
    "    lambda x: change_words(job_slangwords_phase1, x)\n",
    ").apply(\n",
    "    lambda x: remove_stopwords(job_stopwords, x)\n",
    ").map(\n",
    "    clean_text\n",
    ").apply(\n",
    "    lambda x: change_words(job_slangwords_phase2, x)\n",
    ")\n",
    "\n",
    "df_applicant_experience.Position = df_applicant_experience.Position.map(\n",
    "    str.lower\n",
    ").map(\n",
    "    remove_parenthesesnumber\n",
    ").map(\n",
    "    remove_standalonesymbols\n",
    ").map(\n",
    "    remove_morespace\n",
    ").map(\n",
    "    str.strip\n",
    ").apply(\n",
    "    lambda x: ' '.join(list(set(x.split())))\n",
    ").apply(\n",
    "    lambda x: change_words(job_slangwords_phase1, x)\n",
    ").apply(\n",
    "    lambda x: remove_stopwords(job_stopwords, x)\n",
    ").map(\n",
    "    clean_text\n",
    ").apply(\n",
    "    lambda x: change_words(job_slangwords_phase2, x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job.DescriptionRequirement = df_job.DescriptionRequirement.map(\n",
    "    clean_text\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(englishwords, x)\n",
    ").apply(\n",
    "    lambda x: ' '.join([i for i in x.split() if i not in stopwords])\n",
    ")\n",
    "\n",
    "df_applicant_experience.JobDescription = df_applicant_experience.JobDescription.map(\n",
    "    clean_text\n",
    ").apply(\n",
    "    lambda x: change_words(slangwords, x)\n",
    ").apply(\n",
    "    lambda x: change_words(englishwords, x)\n",
    ").apply(\n",
    "    lambda x: ' '.join([i for i in x.split() if i not in stopwords])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 26133\n",
    "\n",
    "df_view = df_job.copy()\n",
    "df_view['similarity'] = [d2v_model.similarity_unseen_docs(i.split(), df_applicant_experience.JobDescription.loc[index].split()) for i in df_job.DescriptionRequirement]\n",
    "df_view[df_view.JobTitle.str.contains('accountant')].sort_values('similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicant_experience.Position.loc[index], df_applicant_experience.JobDescription.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicant_experience['count'] = df_applicant_experience.JobDescription.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicant_experience.sort_values('count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job[df_job.JobTitle.str.contains('accountant')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
