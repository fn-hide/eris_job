{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eats\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from googletrans import Translator\n",
    "\n",
    "from transform_copy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'huda'\n",
    "password = 'Vancha12'\n",
    "host = '127.0.0.1'\n",
    "port = 1433\n",
    "database = 'HRSystemDB'\n",
    "\n",
    "\n",
    "def get_connection():         \n",
    "    return create_engine(\n",
    "        url=f\"mssql+pyodbc://{user}:{password}@{host}:{port}/{database}?driver=SQL Server\",\n",
    "    )\n",
    "\n",
    "engine = get_connection()\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ApplicantExperienceID', 'ApplicantID', 'DateTo', 'DateFrom',\n",
       "       'Industry', 'IsUntilPresent', 'CompanyName', 'JobDescription',\n",
       "       'Position', 'Salary', 'Supervisor', 'SupervisorContactNumber',\n",
       "       'SupervisorEmail'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT * FROM ApplicantExperience\n",
    "    \"\"\"\n",
    ")).columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
    "\n",
    "['', '', '', '', '', '', '', '', '']\n",
    "\n",
    "['', '', '', '', '', '', '', '', '', '', '', '', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "JOB>>>MATCH<<<APPLICANT\n",
    "\n",
    "Dob == UsiaMax\n",
    "SalaryMean == ExpectedSalary\n",
    "\n",
    "CityName == CurrentCityName\n",
    "ProvinceName == CurrentProvinceName\n",
    "DriverLicenseType\n",
    "EducationLevelID\n",
    "Gender\n",
    "MaritalStatus\n",
    "MajorName\n",
    "IsUsingGlasses\n",
    "\n",
    "JobTile, FunctionPositionName == Position\n",
    "Description, Requirement == JobDescription, Strengthness\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicant_id = 31790\n",
    "\n",
    "df_job = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT Job.JobID, Job.JobTitle, FunctionPosition.FunctionPositionName, EducationLevel.EducationLevelName, City.Name AS CityName, Province.Name AS ProvinceName, Major.MajorName, Job.Description, Job.Requirement\n",
    "    FROM (((((Job\n",
    "    RIGHT JOIN FunctionPosition ON Job.FunctionPositionID = FunctionPosition.FunctionPositionID)\n",
    "    RIGHT JOIN EducationLevel ON Job.EducationLevelID = EducationLevel.EducationLevelID)\n",
    "    RIGHT JOIN City ON Job.CityID = City.CityID)\n",
    "    RIGHT JOIN Province ON Job.ProvinceID = Province.ProvinceID)\n",
    "    RIGHT JOIN Major ON Job.MajorID = Major.MajorID)\n",
    "    WHERE JobStatus='Publish'\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT Applicant.ApplicantID, Applicant.Dob, Applicant.Strengthness, Applicant.Weaknesses, City.Name AS CityName, Province.Name AS ProvinceName\n",
    "    FROM ((Applicant\n",
    "    RIGHT JOIN City ON Applicant.CurrentAddressCityID = City.CityID)\n",
    "    RIGHT JOIN Province ON Applicant.CurrentAddressProvinceID = Province.ProvinceID)\n",
    "    WHERE ApplicantID={applicant_id}\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant_education = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT ApplicantEducation.ApplicantID, ApplicantEducation.DateStart, ApplicantEducation.DateEnd, EducationLevel.EducationLevelName, Major.MajorName\n",
    "    FROM ((ApplicantEducation\n",
    "    RIGHT JOIN EducationLevel ON ApplicantEducation.EducationLevelID = EducationLevel.EducationLevelID)\n",
    "    RIGHT JOIN Major ON ApplicantEducation.MajorID = Major.MajorID)\n",
    "    WHERE ApplicantID={applicant_id}\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant_experience = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT ApplicantExperience.ApplicantID, ApplicantExperience.DateFrom, ApplicantExperience.DateTo, ApplicantExperience.Industry, ApplicantExperience.JobDescription, ApplicantExperience.Position\n",
    "    FROM ApplicantExperience\n",
    "    WHERE ApplicantID={applicant_id}\n",
    "    \"\"\"\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicant = df_applicant.drop_duplicates()\n",
    "df_applicant = df_applicant.fillna('')\n",
    "df_applicant_education = df_applicant_education.fillna('')\n",
    "df_applicant_experience = df_applicant_experience.fillna('')\n",
    "\n",
    "'''applicant'''\n",
    "df_applicant['Age'] = pd.to_datetime(\n",
    "    df_applicant.Dob.map(pick_date).apply(lambda x: filter_date(x, 1958, 2006))\n",
    ").map(get_age)\n",
    "\n",
    "df_applicant.drop(columns=['Dob'], inplace=True)\n",
    "\n",
    "df_applicant.Age = df_applicant.Age.fillna(0).astype(int)\n",
    "\n",
    "'''education'''\n",
    "df_applicant_education.DateStart = pd.to_datetime(\n",
    "    df_applicant_education.DateStart.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "\n",
    "df_applicant_education.DateEnd = pd.to_datetime(\n",
    "    df_applicant_education.DateEnd.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "\n",
    "df_applicant_education = df_applicant_education[~(df_applicant_education.DateStart.isna()) & ~(df_applicant_education.DateEnd.isna())]\n",
    "df_applicant_education = df_applicant_education.sort_values('DateStart').groupby(['ApplicantID']).agg('last')\n",
    "\n",
    "df_applicant_education.drop(columns=['DateStart', 'DateEnd'], inplace=True)\n",
    "\n",
    "'''experience'''\n",
    "df_applicant_experience.DateFrom = pd.to_datetime(\n",
    "    df_applicant_experience.DateFrom.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "\n",
    "df_applicant_experience.DateTo = pd.to_datetime(\n",
    "    df_applicant_experience.DateTo.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "\n",
    "df_applicant_experience = df_applicant_experience[~(df_applicant_experience.DateFrom.isna()) & ~(df_applicant_experience.DateTo.isna())]\n",
    "\n",
    "# add YearsOfExperience column\n",
    "df_applicant_experience['YearsOfExperience'] = substract_months(\n",
    "    df_applicant_experience.DateFrom, df_applicant_experience.DateTo\n",
    ")\n",
    "\n",
    "df_applicant_experience = df_applicant_experience.sort_values('DateFrom').groupby(['ApplicantID']).agg({\n",
    "    'DateFrom': 'last',\n",
    "    'DateTo': 'last',\n",
    "    'Industry': ' '.join,\n",
    "    'JobDescription': ' '.join,\n",
    "    'Position': ' '.join,\n",
    "    'YearsOfExperience': 'sum',\n",
    "})\n",
    "\n",
    "df_applicant_experience.drop(columns=['DateFrom', 'DateTo'], inplace=True)\n",
    "\n",
    "'''merge'''\n",
    "df_applicant = pd.merge(df_applicant, df_applicant_experience, on=['ApplicantID'])\n",
    "df_applicant = pd.merge(df_applicant, df_applicant_education, on=['ApplicantID'])\n",
    "\n",
    "'''remove weaknesses'''\n",
    "df_applicant = df_applicant.drop(columns=['Weaknesses'])\n",
    "\n",
    "'''preprocessing'''\n",
    "df_applicant.set_index(['ApplicantID'], inplace=True)\n",
    "\n",
    "df_applicant[df_applicant.select_dtypes(object).columns] = df_applicant[df_applicant.select_dtypes(object).columns].applymap(str.lower)\n",
    "\n",
    "for col in ['Strengthness', 'JobDescription', 'Industry', 'Position']:\n",
    "    df_applicant[col] = df_applicant[col].map(clean_text)\n",
    "\n",
    "'''translate'''\n",
    "translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "for col in ['Strengthness', 'Industry', 'JobDescription', 'Position']:\n",
    "    df_applicant[col] = df_applicant[col].apply(lambda x: translator.translate(x, dest='id').text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strengthness</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ProvinceName</th>\n",
       "      <th>Age</th>\n",
       "      <th>Industry</th>\n",
       "      <th>JobDescription</th>\n",
       "      <th>Position</th>\n",
       "      <th>YearsOfExperience</th>\n",
       "      <th>EducationLevelName</th>\n",
       "      <th>MajorName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApplicantID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31790</th>\n",
       "      <td>pandai mengoperasikan multitasking komputer da...</td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>25</td>\n",
       "      <td>pendidikan pelayanan kesehatan</td>\n",
       "      <td>les privat siswa sd smp bagian jasa pelayanan ...</td>\n",
       "      <td>guru les privat mahasiswa magang</td>\n",
       "      <td>2</td>\n",
       "      <td>s1</td>\n",
       "      <td>akuntansi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Strengthness  CityName  \\\n",
       "ApplicantID                                                                \n",
       "31790        pandai mengoperasikan multitasking komputer da...  surabaya   \n",
       "\n",
       "            ProvinceName  Age                        Industry  \\\n",
       "ApplicantID                                                     \n",
       "31790         jawa timur   25  pendidikan pelayanan kesehatan   \n",
       "\n",
       "                                                JobDescription  \\\n",
       "ApplicantID                                                      \n",
       "31790        les privat siswa sd smp bagian jasa pelayanan ...   \n",
       "\n",
       "                                     Position  YearsOfExperience  \\\n",
       "ApplicantID                                                        \n",
       "31790        guru les privat mahasiswa magang                  2   \n",
       "\n",
       "            EducationLevelName  MajorName  \n",
       "ApplicantID                                \n",
       "31790                       s1  akuntansi  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job.set_index(['JobID'], inplace=True)\n",
    "df_job.fillna('', inplace=True)\n",
    "\n",
    "df_job = df_job.applymap(str.lower)\n",
    "df_job.EducationLevelName = df_job.EducationLevelName.replace('none', '')\n",
    "\n",
    "translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "\n",
    "df_job.JobTitle = df_job.JobTitle.apply(lambda x: translator.translate(x, dest='id').text.lower())\n",
    "df_job.FunctionPositionName = df_job.FunctionPositionName.apply(lambda x: translator.translate(x, dest='id').text.lower())\n",
    "df_job.MajorName = df_job.MajorName.apply(lambda x: translator.translate(x, dest='id').text.lower())\n",
    "\n",
    "df_job.Description = df_job.Description.map(clean_text).apply(lambda x: translator.translate(x, dest='id').text.lower())\n",
    "df_job.Requirement = df_job.Requirement.map(clean_text).apply(lambda x: translator.translate(x, dest='id').text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobTitle</th>\n",
       "      <th>FunctionPositionName</th>\n",
       "      <th>EducationLevelName</th>\n",
       "      <th>CityName</th>\n",
       "      <th>ProvinceName</th>\n",
       "      <th>MajorName</th>\n",
       "      <th>Description</th>\n",
       "      <th>Requirement</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>sekretaris direksi</td>\n",
       "      <td>sekretaris</td>\n",
       "      <td></td>\n",
       "      <td>surabaya</td>\n",
       "      <td>jawa timur</td>\n",
       "      <td>sekretaris</td>\n",
       "      <td>melakukan aktivitas kesekretariatan perusahaan...</td>\n",
       "      <td>usia maksimal 35 tahun pendidikan minimal s1 j...</td>\n",
       "      <td>0.176869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>staff desain</td>\n",
       "      <td>grafis desain</td>\n",
       "      <td>s1</td>\n",
       "      <td>jakarta</td>\n",
       "      <td>dki jakarta</td>\n",
       "      <td>desain grafis</td>\n",
       "      <td>membuat desain yang menarik untuk kebutuhan pe...</td>\n",
       "      <td>usia max 30 tahun pendidikan minimal s1 desain...</td>\n",
       "      <td>0.057073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 JobTitle FunctionPositionName EducationLevelName  CityName  \\\n",
       "JobID                                                                         \n",
       "2775   sekretaris direksi           sekretaris                     surabaya   \n",
       "2785         staff desain        grafis desain                 s1   jakarta   \n",
       "\n",
       "      ProvinceName      MajorName  \\\n",
       "JobID                               \n",
       "2775    jawa timur     sekretaris   \n",
       "2785   dki jakarta  desain grafis   \n",
       "\n",
       "                                             Description  \\\n",
       "JobID                                                      \n",
       "2775   melakukan aktivitas kesekretariatan perusahaan...   \n",
       "2785   membuat desain yang menarik untuk kebutuhan pe...   \n",
       "\n",
       "                                             Requirement  Similarity  \n",
       "JobID                                                                 \n",
       "2775   usia maksimal 35 tahun pendidikan minimal s1 j...    0.176869  \n",
       "2785   usia max 30 tahun pendidikan minimal s1 desain...    0.057073  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_job = tf.data.Dataset.from_tensor_slices(dict(df_job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobModel:\n",
    "    def __init__(self, user_text, output_mode='multi_hot', length=5):\n",
    "        if output_mode == 'int':\n",
    "            self.job_title = tf.keras.layers.TextVectorization(max_tokens=1_000, output_mode=output_mode, output_sequence_length=length)\n",
    "        else:\n",
    "            self.job_title = tf.keras.layers.TextVectorization(max_tokens=1_000, output_mode=output_mode)\n",
    "        self.job_title.adapt(ds_job.map(lambda x: x['JobTitle']))\n",
    "\n",
    "        self.job_title_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=self.job_title.vocabulary_size(),\n",
    "            output_dim=32,\n",
    "        )\n",
    "\n",
    "        self.job_title_model = tf.keras.Sequential([self.job_title, self.job_title_embedding])\n",
    "\n",
    "        # job_vector = job_title_model(np.array(df_job.JobTitle.values))\n",
    "        # user_vector = job_title_model(np.array(['asisten direksi']))\n",
    "\n",
    "        self.job_vector = self.job_title(np.array(df_job.JobTitle.values))\n",
    "        self.user_vector = self.job_title(np.array([user_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'staf keuangan'\n",
    "mod = ['multi_hot', 'count', 'tf_idf']\n",
    "\n",
    "for i in mod:\n",
    "    model = JobModel(txt, i)\n",
    "    df_job[str('Similarity ' + i)] = cosine_similarity(model.job_vector, model.user_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job[['JobTitle', 'Similarity multi_hot', 'Similarity count', 'Similarity tf_idf']].sort_values('Similarity tf_idf', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([42, 4]), TensorShape([1, 2]))"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.job_vector.shape, model.user_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = tf.keras.layers.TextVectorization(max_tokens=1_000, output_mode='tf_idf')\n",
    "job_title.adapt(ds_job.map(lambda x: x['JobTitle']))\n",
    "\n",
    "job_title_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=job_title.vocabulary_size(),\n",
    "    output_dim=32,\n",
    ")\n",
    "\n",
    "job_title_model = tf.keras.Sequential([job_title, job_title_embedding])\n",
    "\n",
    "# job_vector = job_title_model(np.array(df_job.JobTitle.values))\n",
    "# user_vector = job_title_model(np.array(['asisten direksi']))\n",
    "\n",
    "job_vector = job_title(np.array(df_job.JobTitle.values))\n",
    "user_vector = job_title(np.array(['supervisor proyek lapangan sekretaris manajer sekretaris']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job['Similarity'] = cosine_similarity(job_vector, user_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job[['JobTitle', 'Similarity']].sort_values('Similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''encoding'''\n",
    "job_title = tf.keras.layers.StringLookup()\n",
    "job_title.adapt(ds_job.map(lambda x: x['JobTitle']))\n",
    "\n",
    "job_function = tf.keras.layers.StringLookup()\n",
    "job_function.adapt(ds_job.map(lambda x: x['FunctionPositionName']))\n",
    "\n",
    "job_education = tf.keras.layers.StringLookup()\n",
    "job_education.adapt(ds_job.map(lambda x: x['EducationLevelName']))\n",
    "\n",
    "job_city = tf.keras.layers.StringLookup()\n",
    "job_city.adapt(ds_job.map(lambda x: x['CityName']))\n",
    "\n",
    "job_province = tf.keras.layers.StringLookup()\n",
    "job_province.adapt(ds_job.map(lambda x: x['ProvinceName']))\n",
    "\n",
    "job_major = tf.keras.layers.StringLookup()\n",
    "job_major.adapt(ds_job.map(lambda x: x['MajorName']))\n",
    "\n",
    "job_description = tf.keras.layers.TextVectorization(output_sequence_length=300)\n",
    "job_description.adapt(ds_job.map(lambda x: x['Description']))\n",
    "\n",
    "job_requirement = tf.keras.layers.TextVectorization()\n",
    "job_requirement.adapt(ds_job.map(lambda x: x['Requirement']))\n",
    "\n",
    "\n",
    "'''embedding'''\n",
    "job_title_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=job_title.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")\n",
    "\n",
    "job_function_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=job_function.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")\n",
    "\n",
    "job_education_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=job_education.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")\n",
    "\n",
    "job_city_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=job_city.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")\n",
    "\n",
    "job_province_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=job_province.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")\n",
    "\n",
    "job_major_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=job_major.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")\n",
    "\n",
    "job_description_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=job_description.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")\n",
    "\n",
    "job_requirement_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=job_requirement.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")\n",
    "\n",
    "\n",
    "'''model'''\n",
    "job_title_model = tf.keras.Sequential([job_title, job_title_embedding])\n",
    "job_function_model = tf.keras.Sequential([job_function, job_function_embedding])\n",
    "job_education_model = tf.keras.Sequential([job_education, job_education_embedding])\n",
    "job_city_model = tf.keras.Sequential([job_city, job_city_embedding])\n",
    "job_province_model = tf.keras.Sequential([job_province, job_province_embedding])\n",
    "job_major_model = tf.keras.Sequential([job_major, job_major_embedding])\n",
    "job_description_model = tf.keras.Sequential([job_description, job_description_embedding])\n",
    "job_requirement_model = tf.keras.Sequential([job_requirement, job_requirement_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['JobTitle', 'FunctionPositionName', 'EducationLevelName', 'CityName',\n",
       "        'ProvinceName', 'MajorName', 'Description', 'Requirement'],\n",
       "       dtype='object'),\n",
       " Index(['Strengthness', 'CityName', 'ProvinceName', 'Age', 'Industry',\n",
       "        'JobDescription', 'Position', 'YearsOfExperience', 'EducationLevelName',\n",
       "        'MajorName'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job.columns, df_applicant.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobTitle                                                     staff desain\n",
       "FunctionPositionName                                        grafis desain\n",
       "EducationLevelName                                                     s1\n",
       "CityName                                                          jakarta\n",
       "ProvinceName                                                  dki jakarta\n",
       "MajorName                                                   desain grafis\n",
       "Description             membuat desain yang menarik untuk kebutuhan pe...\n",
       "Requirement             usia max 30 tahun pendidikan minimal s1 desain...\n",
       "Name: 2785, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job.loc[2785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['staff desain']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['staff desain']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['grafis desain']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['grafis desain']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['s1']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['s1']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['jakarta']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['jakarta']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['dki jakarta']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['dki jakarta']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['desain grafis']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['desain grafis']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['membuat desain yang menarik untuk kebutuhan perusahaan melakukan pekerjaan sesuai yg diatahkan oleh atasan']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['membuat desain yang menarik untuk kebutuhan perusahaan melakukan pekerjaan sesuai yg diatahkan oleh atasan']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['usia max 30 tahun pendidikan minimal s1 desain komunikasi visual menguasai aplikasi dasar desain corel photshop pengalaman min 1 tahun terbiasa menggunakan komputer dan internet pengalaman dibidang yg sama lebih disukai terbiasa bekerja dibawah tekanan dan bekerja dengan target bertanggung jawab jujur kreatif']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['usia max 30 tahun pendidikan minimal s1 desain komunikasi visual menguasai aplikasi dasar desain corel photshop pengalaman min 1 tahun terbiasa menggunakan komputer dan internet pengalaman dibidang yg sama lebih disukai terbiasa bekerja dibawah tekanan dan bekerja dengan target bertanggung jawab jujur kreatif']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 6 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m job_embedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate((\n\u001b[0;32m      2\u001b[0m     job_title_model([df_job\u001b[39m.\u001b[39;49mloc[\u001b[39m2785\u001b[39;49m]\u001b[39m.\u001b[39;49mJobTitle]),\n\u001b[0;32m      3\u001b[0m     job_function_model([df_job\u001b[39m.\u001b[39;49mloc[\u001b[39m2785\u001b[39;49m]\u001b[39m.\u001b[39;49mFunctionPositionName]),\n\u001b[0;32m      4\u001b[0m     job_education_model([df_job\u001b[39m.\u001b[39;49mloc[\u001b[39m2785\u001b[39;49m]\u001b[39m.\u001b[39;49mEducationLevelName]),\n\u001b[0;32m      5\u001b[0m     job_city_model([df_job\u001b[39m.\u001b[39;49mloc[\u001b[39m2785\u001b[39;49m]\u001b[39m.\u001b[39;49mCityName]),\n\u001b[0;32m      6\u001b[0m     job_province_model([df_job\u001b[39m.\u001b[39;49mloc[\u001b[39m2785\u001b[39;49m]\u001b[39m.\u001b[39;49mProvinceName]),\n\u001b[0;32m      7\u001b[0m     job_major_model([df_job\u001b[39m.\u001b[39;49mloc[\u001b[39m2785\u001b[39;49m]\u001b[39m.\u001b[39;49mMajorName]),\n\u001b[0;32m      8\u001b[0m     job_description_model([df_job\u001b[39m.\u001b[39;49mloc[\u001b[39m2785\u001b[39;49m]\u001b[39m.\u001b[39;49mDescription]),\n\u001b[0;32m      9\u001b[0m     job_requirement_model([df_job\u001b[39m.\u001b[39;49mloc[\u001b[39m2785\u001b[39;49m]\u001b[39m.\u001b[39;49mRequirement]),\n\u001b[0;32m     10\u001b[0m ))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 6 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "job_embedding = np.concatenate((\n",
    "    job_title_model([df_job.loc[2785].JobTitle]),\n",
    "    job_function_model([df_job.loc[2785].FunctionPositionName]),\n",
    "    job_education_model([df_job.loc[2785].EducationLevelName]),\n",
    "    job_city_model([df_job.loc[2785].CityName]),\n",
    "    job_province_model([df_job.loc[2785].ProvinceName]),\n",
    "    job_major_model([df_job.loc[2785].MajorName]),\n",
    "    job_description_model([df_job.loc[2785].Description]),\n",
    "    job_requirement_model([df_job.loc[2785].Requirement]),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = tf.keras.losses.CosineSimilarity(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "model.add(job_title)\n",
    "\n",
    "model.predict(df_job.JobTitle.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x0000020942043E20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define user and job data\n",
    "user_text = \"I am good at programming\"\n",
    "job_text = \"We need a programmer\"\n",
    "user_cat = [\"Data Science\", \"Programming\"]\n",
    "job_cat = [\"Programming\", \"Web Development\"]\n",
    "user_num = [5, 7, 9]\n",
    "job_num = [3, 8, 7]\n",
    "\n",
    "text_vector = tf.keras.layers.TextVectorization(output_sequence_length=10)\n",
    "text_vector.adapt(job_text.split(' '))\n",
    "\n",
    "text_model = tf.keras.Sequential([\n",
    "    text_vector,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=text_vector.vocabulary_size(),\n",
    "        output_dim=10\n",
    "    )\n",
    "])\n",
    "\n",
    "user_text_embedding = text_model.predict(user_text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.00855603, -0.04862776,  0.00302802, -0.02810311,\n",
       "         -0.04780581, -0.02766582,  0.0056753 ,  0.02541116,\n",
       "         -0.02893522,  0.02540194],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765]],\n",
       "\n",
       "       [[-0.00855603, -0.04862776,  0.00302802, -0.02810311,\n",
       "         -0.04780581, -0.02766582,  0.0056753 ,  0.02541116,\n",
       "         -0.02893522,  0.02540194],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765]],\n",
       "\n",
       "       [[-0.00855603, -0.04862776,  0.00302802, -0.02810311,\n",
       "         -0.04780581, -0.02766582,  0.0056753 ,  0.02541116,\n",
       "         -0.02893522,  0.02540194],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765]],\n",
       "\n",
       "       [[-0.00855603, -0.04862776,  0.00302802, -0.02810311,\n",
       "         -0.04780581, -0.02766582,  0.0056753 ,  0.02541116,\n",
       "         -0.02893522,  0.02540194],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765]],\n",
       "\n",
       "       [[-0.00855603, -0.04862776,  0.00302802, -0.02810311,\n",
       "         -0.04780581, -0.02766582,  0.0056753 ,  0.02541116,\n",
       "         -0.02893522,  0.02540194],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765],\n",
       "        [ 0.01162858,  0.04382291,  0.02898641, -0.01834045,\n",
       "         -0.04317871,  0.00940644, -0.03661983, -0.03443255,\n",
       "         -0.03611128, -0.02730765]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'we', 'programmer', 'need', 'a']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
