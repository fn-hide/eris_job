{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import re\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix, WordEmbeddingSimilarityIndex\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# from googletrans import Translator\n",
    "# from deep_translator import GoogleTranslator\n",
    "\n",
    "from FlaskApp.transform import *\n",
    "\n",
    "from job_model import JobModel\n",
    "from app_model import AppModel\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "rootwords = [i[0] for i in pd.read_csv('data/rootwords.txt').values]\n",
    "stopwords = [i[0] for i in pd.read_csv('data/stopwords.csv').values]\n",
    "\n",
    "with open('data/slangwords.json', 'r') as file:\n",
    "    slangwords = json.load(file)\n",
    "\n",
    "with open('data/englishwords.json', 'r') as file:\n",
    "    englishwords = json.load(file)\n",
    "\n",
    "with open('data/slangjobs.json', 'r') as file:\n",
    "    slangjobs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'huda'\n",
    "password = 'Vancha12'\n",
    "host = '127.0.0.1'\n",
    "port = 1433\n",
    "database = 'HRSystemDB'\n",
    "\n",
    "\n",
    "def get_connection():         \n",
    "    return create_engine(\n",
    "        url=f\"mssql+pyodbc://{user}:{password}@{host}:{port}/{database}?driver=SQL Server\",\n",
    "    )\n",
    "\n",
    "engine = get_connection()\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicant_id = 31790\n",
    "\n",
    "df_job = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT Job.JobID, Job.UsiaMax, Job.SalaryMin, Job.SalaryMax, City.Name AS CityName, Province.Name AS ProvinceName, EducationLevel.EducationLevelName, Major.MajorName, Job.DriverLicenseType, Job.UsingGlasses, Job.Gender, Job.MaritalStatus, Job.JobTitle, FunctionPosition.FunctionPositionName, Job.Description, Job.Requirement\n",
    "    FROM (((((Job\n",
    "    RIGHT JOIN FunctionPosition ON Job.FunctionPositionID = FunctionPosition.FunctionPositionID)\n",
    "    RIGHT JOIN EducationLevel ON Job.EducationLevelID = EducationLevel.EducationLevelID)\n",
    "    RIGHT JOIN City ON Job.CityID = City.CityID)\n",
    "    RIGHT JOIN Province ON Job.ProvinceID = Province.ProvinceID)\n",
    "    RIGHT JOIN Major ON Job.MajorID = Major.MajorID)\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_function = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT FunctionPositionID, FunctionPositionName\n",
    "    FROM FunctionPosition\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_education = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT EducationLevelID, EducationLevelName\n",
    "    FROM EducationLevel\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_city = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT CityID, Name AS CityName\n",
    "    FROM City\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_province = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT ProvinceID, Name AS ProvinceName\n",
    "    FROM Province\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_major = pd.DataFrame(engine.execute(\n",
    "    \"\"\"\n",
    "    SELECT MajorID, MajorName\n",
    "    FROM Major\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT Applicant.ApplicantID, Applicant.Dob, Applicant.ExpectedSalary, City.Name AS CityName, Province.Name AS ProvinceName, Applicant.DriverLicenseType, Applicant.IsUsingGlasses, Applicant.Gender, Applicant.MaritalStatus, Applicant.Strengthness\n",
    "    FROM (((Applicant\n",
    "    RIGHT JOIN City ON Applicant.CurrentAddressCityID = City.CityID)\n",
    "    RIGHT JOIN Province ON Applicant.CurrentAddressProvinceID = Province.ProvinceID)\n",
    "    LEFT JOIN Pipeline ON Applicant.ApplicantID = Pipeline.ApplicantID)\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant_education = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT ApplicantEducation.ApplicantID, ApplicantEducation.DateStart, ApplicantEducation.DateEnd, EducationLevel.EducationLevelName, Major.MajorName\n",
    "    FROM (((ApplicantEducation\n",
    "    RIGHT JOIN EducationLevel ON ApplicantEducation.EducationLevelID = EducationLevel.EducationLevelID)\n",
    "    RIGHT JOIN Major ON ApplicantEducation.MajorID = Major.MajorID)\n",
    "    LEFT JOIN Pipeline ON ApplicantEducation.ApplicantID = Pipeline.ApplicantID)\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "df_applicant_experience = pd.DataFrame(engine.execute(\n",
    "    f\"\"\"\n",
    "    SELECT ApplicantExperience.ApplicantID, ApplicantExperience.DateFrom, ApplicantExperience.DateTo, ApplicantExperience.Position, ApplicantExperience.JobDescription\n",
    "    FROM (ApplicantExperience\n",
    "    LEFT JOIN Pipeline ON ApplicantExperience.ApplicantID = Pipeline.ApplicantID)\n",
    "    \"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_str = ['CityName', 'ProvinceName', 'EducationLevelName', 'MajorName', 'DriverLicenseType', 'Gender', 'MaritalStatus', 'JobTitle', 'FunctionPositionName', 'Description', 'Requirement']\n",
    "job_num = ['UsiaMax', 'SalaryMin', 'SalaryMax']\n",
    "job_bol = ['UsingGlasses']\n",
    "\n",
    "'''general'''\n",
    "df_job.set_index(['JobID'], inplace=True)\n",
    "df_job.fillna('', inplace=True)\n",
    "\n",
    "'''str'''\n",
    "df_job[job_str] = df_job[job_str].applymap(str.lower)\n",
    "df_job.replace('none', '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''applicant'''\n",
    "df_applicant = df_applicant.dropna(subset=['ApplicantID'])\n",
    "df_applicant.ApplicantID = df_applicant.ApplicantID.astype(int)\n",
    "df_applicant = df_applicant.drop_duplicates()\n",
    "df_applicant = df_applicant.fillna('')\n",
    "# age column\n",
    "df_applicant['Age'] = pd.to_datetime(\n",
    "    df_applicant.Dob.map(pick_date).apply(lambda x: filter_date(x, 1958, 2006))\n",
    ").map(get_age)\n",
    "\n",
    "df_applicant.drop(columns=['Dob'], inplace=True)\n",
    "\n",
    "df_applicant.Age = df_applicant.Age.fillna(0).astype(int)\n",
    "'''education'''\n",
    "df_applicant_education = df_applicant_education.fillna('')\n",
    "# datetime column\n",
    "df_applicant_education.DateStart = pd.to_datetime(\n",
    "    df_applicant_education.DateStart.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_education.DateEnd = pd.to_datetime(\n",
    "    df_applicant_education.DateEnd.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_education = df_applicant_education[~(df_applicant_education.DateStart.isna()) & ~(df_applicant_education.DateEnd.isna())]\n",
    "df_applicant_education = df_applicant_education.sort_values('DateStart').groupby(['ApplicantID']).agg('last')\n",
    "df_applicant_education.drop(columns=['DateStart', 'DateEnd'], inplace=True)\n",
    "'''experience'''\n",
    "df_applicant_experience = df_applicant_experience.fillna('')\n",
    "\n",
    "# datetime column\n",
    "df_applicant_experience.DateFrom = pd.to_datetime(\n",
    "    df_applicant_experience.DateFrom.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_experience.DateTo = pd.to_datetime(\n",
    "    df_applicant_experience.DateTo.map(pick_date).apply(lambda x: filter_date(x, 1980, 2023))\n",
    ")\n",
    "df_applicant_experience = df_applicant_experience[~(df_applicant_experience.DateFrom.isna()) & ~(df_applicant_experience.DateTo.isna())]\n",
    "\n",
    "# add YearsOfExperience column\n",
    "df_applicant_experience['YearsOfExperience'] = substract_months(\n",
    "    df_applicant_experience.DateFrom, df_applicant_experience.DateTo\n",
    ")\n",
    "df_applicant_experience = df_applicant_experience.sort_values('DateFrom').groupby(['ApplicantID']).agg({\n",
    "    'DateFrom': 'last',\n",
    "    'DateTo': 'last',\n",
    "    'JobDescription': ' '.join,\n",
    "    'Position': ' '.join,\n",
    "    'YearsOfExperience': 'sum',\n",
    "})\n",
    "df_applicant_experience.drop(columns=['DateFrom', 'DateTo'], inplace=True)\n",
    "'''merge'''\n",
    "df_applicant = pd.merge(df_applicant, df_applicant_experience, on=['ApplicantID'])\n",
    "df_applicant = pd.merge(df_applicant, df_applicant_education, on=['ApplicantID'])\n",
    "\n",
    "\n",
    "'''PRE-PROCESSING APPLICANT'''\n",
    "df_applicant.set_index(['ApplicantID'], inplace=True)\n",
    "\n",
    "app_str = ['CityName', 'ProvinceName', 'EducationLevelName', 'MajorName', 'DriverLicenseType', 'Gender', 'MaritalStatus', 'Position', 'JobDescription', 'Strengthness']\n",
    "app_num = ['Age', 'ExpectedSalary', 'YearsOfExperience']\n",
    "app_bol = ['IsUsingGlasses']\n",
    "\n",
    "df_applicant = df_applicant[app_num + app_bol + app_str]\n",
    "\n",
    "'''str'''\n",
    "df_applicant[app_str] = df_applicant[app_str].applymap(str.lower)\n",
    "\n",
    "\n",
    "'''bool'''\n",
    "df_applicant.IsUsingGlasses = df_applicant.IsUsingGlasses.astype(str).map(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = df_job[['JobTitle', 'Description', 'Requirement']]\n",
    "df_applicant = df_applicant[['Position', 'JobDescription', 'Strengthness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\febri\\miniconda3\\envs\\eris\\Lib\\site-packages\\bs4\\__init__.py:337: MarkupResemblesLocatorWarning: \"driver\" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\febri\\miniconda3\\envs\\eris\\Lib\\site-packages\\bs4\\__init__.py:337: MarkupResemblesLocatorWarning: \".\" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\febri\\miniconda3\\envs\\eris\\Lib\\site-packages\\bs4\\__init__.py:337: MarkupResemblesLocatorWarning: \". \" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "'''cleansing'''\n",
    "df_job.Description = df_job.Description.map(clean_text)\n",
    "df_job.Requirement = df_job.Requirement.map(clean_text)\n",
    "df_job.JobTitle = df_job.JobTitle.map(remove_insideparentheses).map(clean_text)\n",
    "\n",
    "df_applicant.JobDescription = df_applicant.JobDescription.map(clean_text)\n",
    "df_applicant.Strengthness = df_applicant.Strengthness.map(clean_text)\n",
    "df_applicant.Position = df_applicant.Position.map(remove_insideparentheses).map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cleansing'''\n",
    "df_job.Description = df_job.Description.apply(lambda x: change_words(slangwords, x))\n",
    "df_job.Requirement = df_job.Requirement.apply(lambda x: change_words(slangwords, x))\n",
    "df_job.JobTitle = df_job.JobTitle.apply(lambda x: change_words(slangwords, x))\n",
    "\n",
    "df_applicant.JobDescription = df_applicant.JobDescription.apply(lambda x: change_words(slangwords, x))\n",
    "df_applicant.Strengthness = df_applicant.Strengthness.apply(lambda x: change_words(slangwords, x))\n",
    "df_applicant.Position = df_applicant.Position.apply(lambda x: change_words(slangwords, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cleansing'''\n",
    "df_job.Description = df_job.Description.apply(lambda x: change_words(englishwords, x))\n",
    "df_job.Requirement = df_job.Requirement.apply(lambda x: change_words(englishwords, x))\n",
    "df_job.JobTitle = df_job.JobTitle.apply(lambda x: change_words(englishwords, x))\n",
    "\n",
    "df_applicant.JobDescription = df_applicant.JobDescription.apply(lambda x: change_words(englishwords, x))\n",
    "df_applicant.Strengthness = df_applicant.Strengthness.apply(lambda x: change_words(englishwords, x))\n",
    "df_applicant.Position = df_applicant.Position.apply(lambda x: change_words(englishwords, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cleansing'''\n",
    "df_job.Description = df_job.Description.apply(lambda x: ' '.join([i for i in x.split() if i not in stopwords]))\n",
    "df_job.Requirement = df_job.Requirement.apply(lambda x: ' '.join([i for i in x.split() if i not in stopwords]))\n",
    "df_job.JobTitle = df_job.JobTitle.apply(lambda x: ' '.join([i for i in x.split() if i not in stopwords]))\n",
    "\n",
    "df_applicant.JobDescription = df_applicant.JobDescription.apply(lambda x: ' '.join([i for i in x.split() if i not in stopwords]))\n",
    "df_applicant.Strengthness = df_applicant.Strengthness.apply(lambda x: ' '.join([i for i in x.split() if i not in stopwords]))\n",
    "df_applicant.Position = df_applicant.Position.apply(lambda x: ' '.join([i for i in x.split() if i not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cleansing'''\n",
    "df_job.Description = df_job.Description.apply(lambda x: stemmer_words(stemmer, x))\n",
    "# df_job.Requirement = df_job.Requirement.apply(lambda x: stemmer_words(stemmer, x))\n",
    "# df_job.JobTitle = df_job.JobTitle.apply(lambda x: stemmer_words(stemmer, x))\n",
    "\n",
    "df_applicant.JobDescription = df_applicant.JobDescription.apply(lambda x: stemmer_words(stemmer, x))\n",
    "# df_applicant.Strengthness = df_applicant.Strengthness.apply(lambda x: stemmer_words(stemmer, x))\n",
    "# df_applicant.Position = df_applicant.Position.apply(lambda x: stemmer_words(stemmer, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobTitle</th>\n",
       "      <th>Description</th>\n",
       "      <th>Requirement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malam audit</td>\n",
       "      <td>asisten kantor kelola surabaya</td>\n",
       "      <td>minimal alam posisi milik alam kuat pro sistem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buku jaga</td>\n",
       "      <td>buku jaga</td>\n",
       "      <td>sarjana derajat akuntansi tahun minimal alam p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>android programmer</td>\n",
       "      <td>kembang android aplikasi milik integrasi jasa ...</td>\n",
       "      <td>usia maksimal minimal didik sistem informasi k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sekretaris hukum</td>\n",
       "      <td>tugas sekretariat terminologi prosedur dokumen...</td>\n",
       "      <td>didik minimal hukum usia maksimal alam kerja m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sekretaris direktur</td>\n",
       "      <td>bantu tangan kerja atas surat surat atur jadwa...</td>\n",
       "      <td>usia maksimal didik minimal jurus jurus sekret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>kelola</td>\n",
       "      <td>pimpin motivator pegawai kelola operasional ha...</td>\n",
       "      <td>usia maksimal didik minimal jurus alam minimal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>pasar staf</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>kelola uang akuntansi</td>\n",
       "      <td>kuasa brevet lapor pajak audit lapor uang anal...</td>\n",
       "      <td>usia maksimal didik jurus akuntansi alam minim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>urus</td>\n",
       "      <td>erti paham atur atur laku serta proses urus ur...</td>\n",
       "      <td>pria wanita usia maksimal didik minimal jurus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>sosial media officer</td>\n",
       "      <td>pikir kreatif hasil ide ide konsep konsep kemb...</td>\n",
       "      <td>usia maksimal didik minimal desain komunikasi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    JobTitle  \\\n",
       "JobID                          \n",
       "1                malam audit   \n",
       "2                  buku jaga   \n",
       "3         android programmer   \n",
       "4           sekretaris hukum   \n",
       "5        sekretaris direktur   \n",
       "...                      ...   \n",
       "3090                  kelola   \n",
       "3091              pasar staf   \n",
       "3092   kelola uang akuntansi   \n",
       "3093                    urus   \n",
       "3099    sosial media officer   \n",
       "\n",
       "                                             Description  \\\n",
       "JobID                                                      \n",
       "1                         asisten kantor kelola surabaya   \n",
       "2                                              buku jaga   \n",
       "3      kembang android aplikasi milik integrasi jasa ...   \n",
       "4      tugas sekretariat terminologi prosedur dokumen...   \n",
       "5      bantu tangan kerja atas surat surat atur jadwa...   \n",
       "...                                                  ...   \n",
       "3090   pimpin motivator pegawai kelola operasional ha...   \n",
       "3091                                                       \n",
       "3092   kuasa brevet lapor pajak audit lapor uang anal...   \n",
       "3093   erti paham atur atur laku serta proses urus ur...   \n",
       "3099   pikir kreatif hasil ide ide konsep konsep kemb...   \n",
       "\n",
       "                                             Requirement  \n",
       "JobID                                                     \n",
       "1      minimal alam posisi milik alam kuat pro sistem...  \n",
       "2      sarjana derajat akuntansi tahun minimal alam p...  \n",
       "3      usia maksimal minimal didik sistem informasi k...  \n",
       "4      didik minimal hukum usia maksimal alam kerja m...  \n",
       "5      usia maksimal didik minimal jurus jurus sekret...  \n",
       "...                                                  ...  \n",
       "3090   usia maksimal didik minimal jurus alam minimal...  \n",
       "3091                                                      \n",
       "3092   usia maksimal didik jurus akuntansi alam minim...  \n",
       "3093   pria wanita usia maksimal didik minimal jurus ...  \n",
       "3099   usia maksimal didik minimal desain komunikasi ...  \n",
       "\n",
       "[1008 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 05:30:01,284 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d120,n5,w2,mc10,s0.001,t3>', 'datetime': '2023-04-19T05:30:01.284552', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n",
      "2023-04-19 05:30:01,285 : INFO : collecting all words and their counts\n",
      "2023-04-19 05:30:01,286 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-04-19 05:30:01,456 : INFO : collected 15238 word types and 5645 unique tags from a corpus of 5645 examples and 512213 words\n",
      "2023-04-19 05:30:01,457 : INFO : Creating a fresh vocabulary\n",
      "2023-04-19 05:30:01,479 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 3614 unique words (23.72% of original 15238, drops 11624)', 'datetime': '2023-04-19T05:30:01.479554', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-19 05:30:01,480 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 480936 word corpus (93.89% of original 512213, drops 31277)', 'datetime': '2023-04-19T05:30:01.480521', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-19 05:30:01,546 : INFO : deleting the raw counts dictionary of 15238 items\n",
      "2023-04-19 05:30:01,548 : INFO : sample=0.001 downsamples 53 most-common words\n",
      "2023-04-19 05:30:01,551 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 394734.575568811 word corpus (82.1%% of prior 480936)', 'datetime': '2023-04-19T05:30:01.551329', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-19 05:30:01,630 : INFO : estimated required memory for 3614 words and 120 dimensions: 9115040 bytes\n",
      "2023-04-19 05:30:01,631 : INFO : resetting layer weights\n",
      "2023-04-19 05:30:01,639 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 3614 vocabulary and 120 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2023-04-19T05:30:01.639095', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "2023-04-19 05:30:02,613 : INFO : EPOCH 0: training on 512213 raw words (400533 effective words) took 1.0s, 416187 effective words/s\n",
      "2023-04-19 05:30:03,652 : INFO : EPOCH 1 - PROGRESS: at 74.17% examples, 256755 words/s, in_qsize 5, out_qsize 1\n",
      "2023-04-19 05:30:03,972 : INFO : EPOCH 1: training on 512213 raw words (400378 effective words) took 1.4s, 296317 effective words/s\n",
      "2023-04-19 05:30:04,908 : INFO : EPOCH 2: training on 512213 raw words (400466 effective words) took 0.9s, 430980 effective words/s\n",
      "2023-04-19 05:30:05,841 : INFO : EPOCH 3: training on 512213 raw words (400269 effective words) took 0.9s, 430981 effective words/s\n",
      "2023-04-19 05:30:06,769 : INFO : EPOCH 4: training on 512213 raw words (400323 effective words) took 0.9s, 434088 effective words/s\n",
      "2023-04-19 05:30:07,722 : INFO : EPOCH 5: training on 512213 raw words (400248 effective words) took 0.9s, 423074 effective words/s\n",
      "2023-04-19 05:30:08,734 : INFO : EPOCH 6 - PROGRESS: at 94.51% examples, 366209 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-19 05:30:08,893 : INFO : EPOCH 6: training on 512213 raw words (400377 effective words) took 1.2s, 344019 effective words/s\n",
      "2023-04-19 05:30:09,855 : INFO : EPOCH 7: training on 512213 raw words (400556 effective words) took 1.0s, 417718 effective words/s\n",
      "2023-04-19 05:30:10,874 : INFO : EPOCH 8 - PROGRESS: at 95.45% examples, 370849 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-19 05:30:10,916 : INFO : EPOCH 8: training on 512213 raw words (400227 effective words) took 1.1s, 379784 effective words/s\n",
      "2023-04-19 05:30:11,927 : INFO : EPOCH 9 - PROGRESS: at 94.51% examples, 366757 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-19 05:30:11,983 : INFO : EPOCH 9: training on 512213 raw words (400483 effective words) took 1.1s, 378144 effective words/s\n",
      "2023-04-19 05:30:13,005 : INFO : EPOCH 10 - PROGRESS: at 95.45% examples, 369296 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-19 05:30:13,052 : INFO : EPOCH 10: training on 512213 raw words (400218 effective words) took 1.1s, 376213 effective words/s\n",
      "2023-04-19 05:30:13,986 : INFO : EPOCH 11: training on 512213 raw words (400372 effective words) took 0.9s, 432069 effective words/s\n",
      "2023-04-19 05:30:14,912 : INFO : EPOCH 12: training on 512213 raw words (400525 effective words) took 0.9s, 436441 effective words/s\n",
      "2023-04-19 05:30:15,815 : INFO : EPOCH 13: training on 512213 raw words (400415 effective words) took 0.9s, 445594 effective words/s\n",
      "2023-04-19 05:30:16,729 : INFO : EPOCH 14: training on 512213 raw words (400636 effective words) took 0.9s, 440648 effective words/s\n",
      "2023-04-19 05:30:17,633 : INFO : EPOCH 15: training on 512213 raw words (400256 effective words) took 0.9s, 444978 effective words/s\n",
      "2023-04-19 05:30:18,533 : INFO : EPOCH 16: training on 512213 raw words (400204 effective words) took 0.9s, 447301 effective words/s\n",
      "2023-04-19 05:30:19,450 : INFO : EPOCH 17: training on 512213 raw words (400254 effective words) took 0.9s, 439245 effective words/s\n",
      "2023-04-19 05:30:20,362 : INFO : EPOCH 18: training on 512213 raw words (400108 effective words) took 0.9s, 440453 effective words/s\n",
      "2023-04-19 05:30:21,264 : INFO : EPOCH 19: training on 512213 raw words (400587 effective words) took 0.9s, 447224 effective words/s\n",
      "2023-04-19 05:30:22,164 : INFO : EPOCH 20: training on 512213 raw words (400436 effective words) took 0.9s, 447355 effective words/s\n",
      "2023-04-19 05:30:23,080 : INFO : EPOCH 21: training on 512213 raw words (400601 effective words) took 0.9s, 440321 effective words/s\n",
      "2023-04-19 05:30:23,980 : INFO : EPOCH 22: training on 512213 raw words (400372 effective words) took 0.9s, 447334 effective words/s\n",
      "2023-04-19 05:30:24,881 : INFO : EPOCH 23: training on 512213 raw words (400709 effective words) took 0.9s, 446952 effective words/s\n",
      "2023-04-19 05:30:25,772 : INFO : EPOCH 24: training on 512213 raw words (400563 effective words) took 0.9s, 451471 effective words/s\n",
      "2023-04-19 05:30:26,676 : INFO : EPOCH 25: training on 512213 raw words (400406 effective words) took 0.9s, 446170 effective words/s\n",
      "2023-04-19 05:30:27,570 : INFO : EPOCH 26: training on 512213 raw words (400192 effective words) took 0.9s, 449947 effective words/s\n",
      "2023-04-19 05:30:28,476 : INFO : EPOCH 27: training on 512213 raw words (400515 effective words) took 0.9s, 444725 effective words/s\n",
      "2023-04-19 05:30:29,377 : INFO : EPOCH 28: training on 512213 raw words (400337 effective words) took 0.9s, 446959 effective words/s\n",
      "2023-04-19 05:30:30,277 : INFO : EPOCH 29: training on 512213 raw words (400161 effective words) took 0.9s, 446948 effective words/s\n",
      "2023-04-19 05:30:30,278 : INFO : Doc2Vec lifecycle event {'msg': 'training on 15366390 raw words (12011727 effective words) took 28.6s, 419412 effective words/s', 'datetime': '2023-04-19T05:30:30.278794', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "dataset = list(df_job.Description.apply(lambda x: x.split()).values) + list(df_job.Requirement.apply(lambda x: x.split()).values) + list(df_applicant.JobDescription.apply(lambda x: x.split()).values)\n",
    "data =[]\n",
    "for w in dataset:\n",
    "    data.append(w)\n",
    "\n",
    "def tagged_document(list_of_ListOfWords):\n",
    "    for x, ListOfWords in enumerate(list_of_ListOfWords):\n",
    "        yield doc2vec.TaggedDocument(ListOfWords, [x])\n",
    "\n",
    "data_train = list(tagged_document(data))\n",
    "\n",
    "\n",
    "d2v_model = doc2vec.Doc2Vec(vector_size=120, min_count=10, epochs=30, window=2)\n",
    "\n",
    "d2v_model.build_vocab(data_train)\n",
    "d2v_model.train(data_train, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.024087548"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean text\n",
    "d2v_model.similarity_unseen_docs(df_job.Description.loc[1607].split(), df_applicant.JobDescription.loc[39348].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48006448"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean text > slangwords\n",
    "d2v_model.similarity_unseen_docs(df_job.Description.loc[1607].split(), df_applicant.JobDescription.loc[39348].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37745318"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean text > slangwords > englishwords\n",
    "d2v_model.similarity_unseen_docs(df_job.Description.loc[1607].split(), df_applicant.JobDescription.loc[39348].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1910725"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean text > slangwords > englishwords > stopwords\n",
    "d2v_model.similarity_unseen_docs(df_job.Description.loc[1607].split(), df_applicant.JobDescription.loc[39348].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.049069412"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean text > slangwords > englishwords > stopwords > stemm\n",
    "d2v_model.similarity_unseen_docs(df_job.Description.loc[1607].split(), df_applicant.JobDescription.loc[39348].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-ku',\n",
       " '-nya',\n",
       " '9',\n",
       " 'abk',\n",
       " 'above',\n",
       " 'absen',\n",
       " 'absence',\n",
       " 'absensi',\n",
       " 'absent',\n",
       " 'acara',\n",
       " 'acces',\n",
       " 'access',\n",
       " 'accomodation',\n",
       " 'accompanying',\n",
       " 'according',\n",
       " 'accountant',\n",
       " 'accruing',\n",
       " 'accuracy',\n",
       " 'accurately',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieving',\n",
       " 'acquisition',\n",
       " 'acting',\n",
       " 'actions',\n",
       " 'activation',\n",
       " 'actively',\n",
       " 'actual',\n",
       " 'acuan',\n",
       " 'ada',\n",
       " 'adalah',\n",
       " 'adanya',\n",
       " 'adapun',\n",
       " 'add',\n",
       " 'additional',\n",
       " 'adjust',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administrasi',\n",
       " 'administratif',\n",
       " 'administrator',\n",
       " 'adobe',\n",
       " 'advance',\n",
       " 'advisor',\n",
       " 'advokasi',\n",
       " 'advokat',\n",
       " 'against',\n",
       " 'agama',\n",
       " 'agar',\n",
       " 'agen',\n",
       " 'agendas',\n",
       " 'agensi',\n",
       " 'agensty',\n",
       " 'agreed',\n",
       " 'agreements',\n",
       " 'agunan',\n",
       " 'agung',\n",
       " 'agustus',\n",
       " 'ahli',\n",
       " 'ahu',\n",
       " 'air',\n",
       " 'ajb',\n",
       " 'ajukan',\n",
       " 'akad',\n",
       " 'akan',\n",
       " 'akhir',\n",
       " 'aki',\n",
       " 'akomodasi',\n",
       " 'akrab',\n",
       " 'akses',\n",
       " 'akta',\n",
       " 'akte',\n",
       " 'aktif',\n",
       " 'aktiva',\n",
       " 'aktivasi',\n",
       " 'aktivitas',\n",
       " 'akun',\n",
       " 'akuntansi',\n",
       " 'akurat',\n",
       " 'alam',\n",
       " 'alamat',\n",
       " 'alarm',\n",
       " 'alasan',\n",
       " 'alat',\n",
       " 'alcoholic',\n",
       " 'alker',\n",
       " 'allows',\n",
       " 'along',\n",
       " 'alternatif',\n",
       " 'alur',\n",
       " 'am',\n",
       " 'aman',\n",
       " 'ambil',\n",
       " 'ambon',\n",
       " 'amounts',\n",
       " 'anak',\n",
       " 'anak-anak',\n",
       " 'analis',\n",
       " 'analisis',\n",
       " 'analyst',\n",
       " 'analyzes',\n",
       " 'anda',\n",
       " 'andil',\n",
       " 'android',\n",
       " 'aneka',\n",
       " 'anggaran',\n",
       " 'anggota',\n",
       " 'anggunan',\n",
       " 'angka',\n",
       " 'angkasa',\n",
       " 'angkutan',\n",
       " 'angsuran',\n",
       " 'animasi',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'antara',\n",
       " 'anti',\n",
       " 'antivirus',\n",
       " 'anything',\n",
       " 'apa',\n",
       " 'apabila',\n",
       " 'apakah',\n",
       " 'apar',\n",
       " 'aparat',\n",
       " 'apartemen',\n",
       " 'apht',\n",
       " 'api',\n",
       " 'apiary',\n",
       " 'aplication',\n",
       " 'aplikasi',\n",
       " 'apotek',\n",
       " 'apoteker',\n",
       " 'app',\n",
       " 'apple',\n",
       " 'appraisal',\n",
       " 'appraissal',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'april',\n",
       " 'arahan',\n",
       " 'archive',\n",
       " 'archiving',\n",
       " 'armada',\n",
       " 'around',\n",
       " 'arranged',\n",
       " 'arsip',\n",
       " 'arsitek',\n",
       " 'arsitektur',\n",
       " 'article',\n",
       " 'artikel',\n",
       " 'artist',\n",
       " 'arus',\n",
       " 'aset',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asing',\n",
       " 'asisten',\n",
       " 'asking',\n",
       " 'asli',\n",
       " 'aspect',\n",
       " 'aspek',\n",
       " 'assembly',\n",
       " 'assigning',\n",
       " 'assignment',\n",
       " 'assisted',\n",
       " 'assisting',\n",
       " 'associate',\n",
       " 'associates',\n",
       " 'assurance',\n",
       " 'asuransi',\n",
       " 'atas',\n",
       " 'atasan',\n",
       " 'atau',\n",
       " 'ataupun',\n",
       " 'atlet',\n",
       " 'atm',\n",
       " 'attend',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attorney',\n",
       " 'aturan',\n",
       " 'audiences',\n",
       " 'audit',\n",
       " 'auditors',\n",
       " 'audits',\n",
       " 'autocad',\n",
       " 'availability',\n",
       " 'awak',\n",
       " 'awal',\n",
       " 'ayat',\n",
       " 'ba',\n",
       " 'badan',\n",
       " 'bagaimana',\n",
       " 'bagi',\n",
       " 'bagian',\n",
       " 'bagus',\n",
       " 'bahan',\n",
       " 'bahan-bahan',\n",
       " 'bahasa',\n",
       " 'bahaya',\n",
       " 'bahwa',\n",
       " 'baik',\n",
       " 'bakar',\n",
       " 'baku',\n",
       " 'balai',\n",
       " 'balances',\n",
       " 'balancing',\n",
       " 'balasan',\n",
       " 'bali',\n",
       " 'baliho',\n",
       " 'balik',\n",
       " 'bandara',\n",
       " 'banding',\n",
       " 'bandung',\n",
       " 'bandwidth',\n",
       " 'bang',\n",
       " 'bangun',\n",
       " 'bangunan',\n",
       " 'bank',\n",
       " 'banks',\n",
       " 'banten',\n",
       " 'bantu',\n",
       " 'bantuan',\n",
       " 'banyak',\n",
       " 'bap',\n",
       " 'bapak',\n",
       " 'bar',\n",
       " 'bara',\n",
       " 'barang',\n",
       " 'barat',\n",
       " 'barcode',\n",
       " 'baru',\n",
       " 'bas',\n",
       " 'basis',\n",
       " 'batas',\n",
       " 'batu',\n",
       " 'bawah',\n",
       " 'bawahan',\n",
       " 'bayar',\n",
       " 'bbm',\n",
       " 'bca',\n",
       " 'bea',\n",
       " 'beauty',\n",
       " 'beban',\n",
       " 'bebek',\n",
       " 'beberapa',\n",
       " 'became',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beginning',\n",
       " 'being',\n",
       " 'bekas',\n",
       " 'bekasi',\n",
       " 'bekerja',\n",
       " 'belajar',\n",
       " 'belanja',\n",
       " 'beli',\n",
       " 'belum',\n",
       " 'benar',\n",
       " 'bencana',\n",
       " 'benda',\n",
       " 'benefits',\n",
       " 'bengkel',\n",
       " 'bensin',\n",
       " 'bentuk',\n",
       " 'bepergian',\n",
       " 'ber',\n",
       " 'beracara',\n",
       " 'berada',\n",
       " 'berat',\n",
       " 'berbagai',\n",
       " 'berbasis',\n",
       " 'berbeda',\n",
       " 'berbicara',\n",
       " 'berdagang',\n",
       " 'berdasarkan',\n",
       " 'berfungsi',\n",
       " 'bergabung',\n",
       " 'bergerak',\n",
       " 'berhalangan',\n",
       " 'berharap',\n",
       " 'berhasil',\n",
       " 'berhenti',\n",
       " 'berhubungan',\n",
       " 'berikan',\n",
       " 'berikut',\n",
       " 'berikutnya',\n",
       " 'berinteraksi',\n",
       " 'berisi',\n",
       " 'berita',\n",
       " 'berjalan',\n",
       " 'berjalannya',\n",
       " 'berkaitan',\n",
       " 'berkala',\n",
       " 'berkas',\n",
       " 'berkembang',\n",
       " 'berkolaborasi',\n",
       " 'berkomunikasi',\n",
       " 'berkoordinasi',\n",
       " 'berkordinasi',\n",
       " 'berkualitas',\n",
       " 'berkunjung',\n",
       " 'berlaku',\n",
       " 'berlakunya',\n",
       " 'berlangganan',\n",
       " 'berlangsung',\n",
       " 'berlangsungnya',\n",
       " 'bermacam-macam',\n",
       " 'bermasalah',\n",
       " 'bermotor',\n",
       " 'bernegosiasi',\n",
       " 'beroperasi',\n",
       " 'berorientasi',\n",
       " 'berpartisipasi',\n",
       " 'berpengalaman',\n",
       " 'berperan',\n",
       " 'berpesta',\n",
       " 'berpikir',\n",
       " 'berprestasi',\n",
       " 'bersama',\n",
       " 'bersangkutan',\n",
       " 'bersatu',\n",
       " 'bersedia',\n",
       " 'bersidang',\n",
       " 'bersifat',\n",
       " 'bersih',\n",
       " 'bertahun-tahun',\n",
       " 'bertemu',\n",
       " 'bertindak',\n",
       " 'bertugas',\n",
       " 'bertujuan',\n",
       " 'berupa',\n",
       " 'berurusan',\n",
       " 'berusaha',\n",
       " 'berwenang',\n",
       " 'besar',\n",
       " 'beserta',\n",
       " 'besi',\n",
       " 'beton',\n",
       " 'better',\n",
       " 'between',\n",
       " 'bg',\n",
       " 'biasa',\n",
       " 'biaya',\n",
       " 'bidang',\n",
       " 'bidding',\n",
       " 'bikin',\n",
       " 'bila',\n",
       " 'bilyet',\n",
       " 'bimbingan',\n",
       " 'binamarga',\n",
       " 'biodata',\n",
       " 'biro',\n",
       " 'bisa',\n",
       " 'bisnis',\n",
       " 'bkpm',\n",
       " 'blc',\n",
       " 'blitar',\n",
       " 'blog',\n",
       " 'bni',\n",
       " 'board',\n",
       " 'bod',\n",
       " 'bogor',\n",
       " 'bolt',\n",
       " 'bon',\n",
       " 'bonus',\n",
       " 'books',\n",
       " 'booth',\n",
       " 'boq',\n",
       " 'borrowing',\n",
       " 'bos',\n",
       " 'boss',\n",
       " 'box',\n",
       " 'bphtb',\n",
       " 'bpkb',\n",
       " 'bpom',\n",
       " 'branch',\n",
       " 'branches',\n",
       " 'breakdown',\n",
       " 'bri',\n",
       " 'bridge',\n",
       " 'brief',\n",
       " 'brochure',\n",
       " 'brochures',\n",
       " 'brosur',\n",
       " 'btl',\n",
       " 'bts',\n",
       " 'buah',\n",
       " 'buat',\n",
       " 'budaya',\n",
       " 'bug',\n",
       " 'bugar',\n",
       " 'built',\n",
       " 'buka',\n",
       " 'bukan',\n",
       " 'bukopin',\n",
       " 'bukti',\n",
       " 'buku',\n",
       " 'bulan',\n",
       " 'bulanan',\n",
       " 'bulannya',\n",
       " 'buletin',\n",
       " 'bumi',\n",
       " 'bumn',\n",
       " 'bunga',\n",
       " 'bupati',\n",
       " 'bur',\n",
       " 'buruh',\n",
       " 'buruk',\n",
       " 'bus',\n",
       " 'bussiness',\n",
       " 'buy',\n",
       " 'buyers',\n",
       " 'buying',\n",
       " 'cabang',\n",
       " 'cable',\n",
       " 'cabling',\n",
       " 'cadangan',\n",
       " 'cafe',\n",
       " 'cakupan',\n",
       " 'calculate',\n",
       " 'calculation',\n",
       " 'calculations',\n",
       " 'calling',\n",
       " 'calon',\n",
       " 'campus',\n",
       " 'canvassing',\n",
       " 'capabilities',\n",
       " 'capacity',\n",
       " 'capital',\n",
       " 'car',\n",
       " 'cara',\n",
       " 'card',\n",
       " 'career',\n",
       " 'cargo',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cars',\n",
       " 'catat',\n",
       " 'catatan',\n",
       " 'catering',\n",
       " 'cc',\n",
       " 'ccpl',\n",
       " 'cctv',\n",
       " 'cek',\n",
       " 'center',\n",
       " 'centers',\n",
       " 'cepat',\n",
       " 'cerdas',\n",
       " 'cerewet',\n",
       " 'certificate',\n",
       " 'cetak',\n",
       " 'chain',\n",
       " 'changes',\n",
       " 'channel',\n",
       " 'charges',\n",
       " 'chat',\n",
       " 'checked',\n",
       " 'checks',\n",
       " 'chemical',\n",
       " 'cina',\n",
       " 'ciputra',\n",
       " 'cisco',\n",
       " 'citra',\n",
       " 'city',\n",
       " 'claims',\n",
       " 'class',\n",
       " 'clean',\n",
       " 'clien',\n",
       " 'closely',\n",
       " 'cloud',\n",
       " 'club',\n",
       " 'cluster',\n",
       " 'cnc',\n",
       " 'co',\n",
       " 'coaching',\n",
       " 'coba',\n",
       " 'cocok',\n",
       " 'cod',\n",
       " 'coding',\n",
       " 'coffee',\n",
       " 'collateral',\n",
       " 'collected',\n",
       " 'collecting',\n",
       " 'collector',\n",
       " 'com',\n",
       " 'come',\n",
       " 'commission',\n",
       " 'committee',\n",
       " 'companies',\n",
       " 'compare',\n",
       " 'competency',\n",
       " 'competitions',\n",
       " 'competitor',\n",
       " 'compile',\n",
       " 'complaint',\n",
       " 'complaints',\n",
       " 'completed',\n",
       " 'completeness',\n",
       " 'completing',\n",
       " 'completion',\n",
       " 'complex',\n",
       " 'compliance',\n",
       " 'comply',\n",
       " 'comprehensive',\n",
       " 'computers',\n",
       " 'concept',\n",
       " 'condition',\n",
       " 'conditioner',\n",
       " 'conditions',\n",
       " 'conducted',\n",
       " 'conference',\n",
       " 'configuration',\n",
       " 'configure',\n",
       " 'configuring',\n",
       " 'confirm',\n",
       " 'connection',\n",
       " 'consolidated',\n",
       " 'consolidation',\n",
       " 'constantly',\n",
       " 'construction',\n",
       " 'consultant',\n",
       " 'consulting',\n",
       " 'consumer',\n",
       " 'consumers',\n",
       " 'consumption',\n",
       " 'container',\n",
       " 'contents',\n",
       " 'contoh',\n",
       " 'contractor',\n",
       " 'contracts',\n",
       " 'controling',\n",
       " 'controlled',\n",
       " 'controls',\n",
       " 'coordinated',\n",
       " 'corel',\n",
       " 'correct',\n",
       " 'correctly',\n",
       " 'costing',\n",
       " 'costs',\n",
       " 'costumer',\n",
       " 'could',\n",
       " 'counselors',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'coverage',\n",
       " 'covered',\n",
       " 'covid',\n",
       " 'coworking',\n",
       " 'cpu',\n",
       " 'crane',\n",
       " 'created',\n",
       " 'crimping',\n",
       " 'crm',\n",
       " 'cross',\n",
       " 'cs',\n",
       " 'csr',\n",
       " 'cukai',\n",
       " 'cukup',\n",
       " 'custom',\n",
       " 'customs',\n",
       " 'custumer',\n",
       " 'cuti',\n",
       " 'cutting',\n",
       " 'daerah',\n",
       " 'daftar',\n",
       " 'dagang',\n",
       " 'daging',\n",
       " 'dahulu',\n",
       " 'dalam',\n",
       " 'dalamnya',\n",
       " 'damaged',\n",
       " 'dan',\n",
       " 'dana',\n",
       " 'danamon',\n",
       " 'dapat',\n",
       " 'dapur',\n",
       " 'dari',\n",
       " 'daring',\n",
       " 'darurat',\n",
       " 'dasar',\n",
       " 'data',\n",
       " 'databases',\n",
       " 'datang',\n",
       " 'dates',\n",
       " 'daya',\n",
       " 'deadlines',\n",
       " 'dealer',\n",
       " 'debet',\n",
       " 'debitur',\n",
       " 'decoding',\n",
       " 'ded',\n",
       " 'deed',\n",
       " 'deeds',\n",
       " 'defect',\n",
       " 'define',\n",
       " 'deliver',\n",
       " 'delivering',\n",
       " 'delivers',\n",
       " 'delivery',\n",
       " 'demand',\n",
       " 'demands',\n",
       " 'demi',\n",
       " 'demo',\n",
       " 'demosi',\n",
       " 'demotion',\n",
       " 'denda',\n",
       " 'dengan',\n",
       " 'depan',\n",
       " 'departemen',\n",
       " 'deployment',\n",
       " 'depok',\n",
       " 'deposito',\n",
       " 'deposits',\n",
       " 'depresiasi',\n",
       " 'deputy',\n",
       " 'desa',\n",
       " 'desain',\n",
       " 'desainer',\n",
       " 'designed',\n",
       " 'designing',\n",
       " 'designs',\n",
       " 'deskripsi',\n",
       " 'desktop',\n",
       " 'detail',\n",
       " 'detailed',\n",
       " 'developed',\n",
       " 'developments',\n",
       " 'device',\n",
       " 'devices',\n",
       " 'devising',\n",
       " 'dgn',\n",
       " 'di',\n",
       " 'dia',\n",
       " 'diadakan',\n",
       " 'diagram',\n",
       " 'dialami',\n",
       " 'diambil',\n",
       " 'dianggap',\n",
       " 'dianggarkan',\n",
       " 'diantaranya',\n",
       " 'diaries',\n",
       " 'dibandingkan',\n",
       " 'dibangun',\n",
       " 'dibayar',\n",
       " 'dibayarkan',\n",
       " 'diberikan',\n",
       " 'dibidang',\n",
       " 'dibuat',\n",
       " 'dibuatkan',\n",
       " 'dibutuhkan',\n",
       " 'did',\n",
       " 'didalam',\n",
       " 'didirikan',\n",
       " 'diesel',\n",
       " 'digital',\n",
       " 'digunakan',\n",
       " 'dihadapi',\n",
       " 'dihasilkan',\n",
       " 'diinginkan',\n",
       " 'dijadikan',\n",
       " 'dijalankan',\n",
       " 'dijual',\n",
       " 'dikantor',\n",
       " 'dikelola',\n",
       " 'dikeluarkan',\n",
       " 'dikerjakan',\n",
       " 'dikirim',\n",
       " 'dikirimkan',\n",
       " 'dilaksanakan',\n",
       " 'dilakukan',\n",
       " 'dilapangan',\n",
       " 'diligence',\n",
       " 'diluar',\n",
       " 'dimana',\n",
       " 'dimiliki',\n",
       " 'diminta',\n",
       " 'dimulai',\n",
       " 'dimutakhirkan',\n",
       " 'dinas',\n",
       " 'dining',\n",
       " 'diolah',\n",
       " 'dipakai',\n",
       " 'dipemeriksaan',\n",
       " 'diperlukan',\n",
       " 'diperoleh',\n",
       " 'dipertanggungkan',\n",
       " 'diperusahaan',\n",
       " 'dipesankan',\n",
       " 'dipimpin',\n",
       " 'diproduksi',\n",
       " 'directing',\n",
       " 'direction',\n",
       " 'directors',\n",
       " 'directory',\n",
       " 'direktur',\n",
       " 'diri',\n",
       " 'disajikan',\n",
       " 'disampaikan',\n",
       " 'disbursement',\n",
       " 'disc',\n",
       " 'discount',\n",
       " 'discrepancies',\n",
       " 'discuss',\n",
       " 'disediakan',\n",
       " 'diselenggarakan',\n",
       " 'diselesaikan',\n",
       " 'diseluruh',\n",
       " 'disepakati',\n",
       " 'diserahkan',\n",
       " 'disesuaikan',\n",
       " 'disewa',\n",
       " 'disewakan',\n",
       " 'disimpan',\n",
       " 'disini',\n",
       " 'disiplin',\n",
       " 'diskon',\n",
       " 'diskusi',\n",
       " 'dismantle',\n",
       " 'disnaker',\n",
       " 'dispenda',\n",
       " 'display',\n",
       " 'disposal',\n",
       " 'dispute',\n",
       " 'distribusi',\n",
       " 'distributing',\n",
       " 'distribution',\n",
       " 'distributor',\n",
       " 'disyaratkan',\n",
       " 'ditanda',\n",
       " 'ditangani',\n",
       " 'ditempatkan',\n",
       " 'ditemui',\n",
       " 'ditentukan',\n",
       " 'diterapkan',\n",
       " 'diterima',\n",
       " 'ditetapkan',\n",
       " 'ditugaskan',\n",
       " 'dituju',\n",
       " 'ditujukan',\n",
       " 'ditunjuk',\n",
       " 'dituntut',\n",
       " 'divisi',\n",
       " 'dki',\n",
       " 'dns',\n",
       " 'do',\n",
       " 'dobel',\n",
       " 'doc',\n",
       " 'doctor',\n",
       " 'document',\n",
       " 'documented',\n",
       " 'doing',\n",
       " 'dokter',\n",
       " 'dokumen',\n",
       " 'dokument',\n",
       " 'dokumentasi',\n",
       " 'domain',\n",
       " 'domestic',\n",
       " 'domisili',\n",
       " 'donatur',\n",
       " 'done',\n",
       " 'dosen',\n",
       " 'dprd',\n",
       " 'draf',\n",
       " 'drafter',\n",
       " 'drawings',\n",
       " 'drilling',\n",
       " 'drinks',\n",
       " 'driver',\n",
       " 'drop',\n",
       " 'du',\n",
       " 'dua',\n",
       " 'due',\n",
       " 'dukungan',\n",
       " 'dunia',\n",
       " 'duplik',\n",
       " 'during',\n",
       " 'dus',\n",
       " 'duta',\n",
       " 'ea',\n",
       " 'earn',\n",
       " 'east',\n",
       " 'economic',\n",
       " 'ed',\n",
       " 'edisi',\n",
       " 'edition',\n",
       " 'editor',\n",
       " 'educational',\n",
       " 'edukasi',\n",
       " 'ee',\n",
       " 'efaktur',\n",
       " 'efektif',\n",
       " 'efektivitas',\n",
       " 'effective',\n",
       " 'effectively',\n",
       " 'effectiveness',\n",
       " 'efficient',\n",
       " 'efisien',\n",
       " 'efisiensi',\n",
       " 'either',\n",
       " 'ekonomi',\n",
       " 'eksekusi',\n",
       " 'eksekutif',\n",
       " 'ekspedisi',\n",
       " 'ekspor',\n",
       " 'eksternal',\n",
       " 'ela',\n",
       " 'electronic',\n",
       " 'elektrik',\n",
       " 'elektronik',\n",
       " 'elements',\n",
       " 'elite',\n",
       " 'emailing',\n",
       " 'emails',\n",
       " 'emas',\n",
       " 'emberian',\n",
       " 'emberikan',\n",
       " 'embuat',\n",
       " 'employed',\n",
       " 'employees',\n",
       " 'employement',\n",
       " 'employment',\n",
       " 'energi',\n",
       " 'enerima',\n",
       " 'eng',\n",
       " 'engine',\n",
       " 'engineers',\n",
       " 'ensuring',\n",
       " 'enters',\n",
       " 'entri',\n",
       " 'entries',\n",
       " 'eo',\n",
       " 'episode',\n",
       " 'error',\n",
       " 'ertanggung',\n",
       " 'especially',\n",
       " 'establishing',\n",
       " 'establishment',\n",
       " 'estate',\n",
       " 'estimasi',\n",
       " 'estimation',\n",
       " 'et',\n",
       " 'evaluasi',\n",
       " 'evaluating',\n",
       " 'every',\n",
       " 'everyday',\n",
       " 'everything',\n",
       " 'evidence',\n",
       " 'ex',\n",
       " 'example',\n",
       " 'exchange',\n",
       " 'executing',\n",
       " 'exel',\n",
       " 'exhibitions',\n",
       " 'expanding',\n",
       " 'expatriate',\n",
       " 'expedisi',\n",
       " 'expedition',\n",
       " 'expenditure',\n",
       " 'expense',\n",
       " 'expired',\n",
       " 'explain',\n",
       " 'explaining',\n",
       " 'explore',\n",
       " 'expo',\n",
       " 'export',\n",
       " 'exterior',\n",
       " 'externally',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'facilitating',\n",
       " 'factory',\n",
       " 'fair',\n",
       " 'faks',\n",
       " 'fakta',\n",
       " 'faktor',\n",
       " 'faktur',\n",
       " 'fakultas',\n",
       " 'farmasi',\n",
       " 'fase',\n",
       " 'fashion',\n",
       " 'fasilitas',\n",
       " 'fasilitasi',\n",
       " 'fasilitator',\n",
       " 'fax',\n",
       " 'februari',\n",
       " 'feed',\n",
       " 'ff',\n",
       " 'fiber',\n",
       " 'fidusia',\n",
       " 'fill',\n",
       " 'film',\n",
       " 'filter',\n",
       " 'find',\n",
       " 'finding',\n",
       " 'findings',\n",
       " 'fingerprint',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'finishing',\n",
       " 'finnace',\n",
       " 'firewall',\n",
       " 'first',\n",
       " 'fisik',\n",
       " 'fisika',\n",
       " 'fiskal',\n",
       " 'fix',\n",
       " 'flag',\n",
       " 'flight',\n",
       " 'flowchart',\n",
       " 'flows',\n",
       " 'flyer',\n",
       " 'fo',\n",
       " 'fococopy',\n",
       " 'focus',\n",
       " 'folder',\n",
       " 'follows',\n",
       " 'followup',\n",
       " 'force',\n",
       " 'forecast',\n",
       " 'foreign',\n",
       " 'formal',\n",
       " 'format',\n",
       " 'forms',\n",
       " 'formulir',\n",
       " 'forum',\n",
       " 'foto',\n",
       " 'fotografer',\n",
       " 'fotografi',\n",
       " 'freelance',\n",
       " 'frisian',\n",
       " 'frontliner',\n",
       " 'fu',\n",
       " 'fulfilling',\n",
       " 'fully',\n",
       " 'fun',\n",
       " 'funding',\n",
       " 'funds',\n",
       " 'fungsi',\n",
       " 'furniture',\n",
       " 'further',\n",
       " 'gabungan',\n",
       " 'gaji',\n",
       " 'gambar',\n",
       " 'gambaran',\n",
       " 'games',\n",
       " 'gangguan',\n",
       " 'ganti',\n",
       " 'gap',\n",
       " 'garis',\n",
       " 'garuda',\n",
       " 'gas',\n",
       " 'gate',\n",
       " 'gave',\n",
       " 'gedung',\n",
       " 'genset',\n",
       " 'gerai',\n",
       " 'gerbang',\n",
       " 'get',\n",
       " 'getah',\n",
       " 'gi',\n",
       " 'gigi',\n",
       " 'girder',\n",
       " 'girl',\n",
       " 'giro',\n",
       " 'given',\n",
       " 'giving',\n",
       " 'global',\n",
       " 'gm',\n",
       " 'go',\n",
       " 'goal',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'goods',\n",
       " 'google',\n",
       " 'goreng',\n",
       " 'gornasgor',\n",
       " 'got',\n",
       " 'grade',\n",
       " 'grafis',\n",
       " 'greet',\n",
       " 'gresik',\n",
       " 'groups',\n",
       " 'growth',\n",
       " 'grup',\n",
       " 'gt',\n",
       " 'guarantee',\n",
       " 'gubernur',\n",
       " 'gudang',\n",
       " 'guest',\n",
       " 'guests',\n",
       " 'guide',\n",
       " 'guna',\n",
       " 'gunakan',\n",
       " ...]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(d2v_model.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('kembang aplikasi ios integrasi layan layan guna analis optimal kode aplikasi efisiensi andal kerja',\n",
       " 'riset validation mengadakan domain riset cbl challenge berdasarkan belajar kerangka mengatur them into solution konsep aplikasi perkembangan mengembangkan aplikasi technically cepat pemrograman bahasa supported ios kerangka jasa pengguna usability pengujian mengatur pengujian scenarios find prospective users aplikasi pengujian process improvements berdasarkan evaluasi results proyek presentasi hadiah aplikasi hasil peserta mentors apple reviewers')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job.Description.loc[1607], df_applicant.JobDescription.loc[39348]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>JobDescription</th>\n",
       "      <th>Strengthness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApplicantID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jawa situs web pengembang android pengembang</td>\n",
       "      <td>cakupan responsibility menganalisa mengembangk...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>mendukung mendukung mendukung mendukung menduk...</td>\n",
       "      <td>bertugas mengisi berisi situs web intern klien...</td>\n",
       "      <td>belajar motto dipelajari hidup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18385</th>\n",
       "      <td>staf</td>\n",
       "      <td>penyelesaian jaringan perangkat keras mengemba...</td>\n",
       "      <td>cepat belajar ramah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21102</th>\n",
       "      <td>magang staf magang staf magang staf</td>\n",
       "      <td>proyek perangkat android pkbl lapangan perangk...</td>\n",
       "      <td>rajin suka belajar keras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22239</th>\n",
       "      <td>teknisi android permainan pengembang</td>\n",
       "      <td>merawat instalasi jaringan komputer penarikan ...</td>\n",
       "      <td>sabar teliti grusa grusu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>penjualan pemasaran staf freelance programmer</td>\n",
       "      <td>penjualan pemasaran menganalisis pasar penjual...</td>\n",
       "      <td>analisis kuat teliti mudah bersosialisasi adap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35606</th>\n",
       "      <td>internship</td>\n",
       "      <td>situs web berdasarkan android devepment proyek...</td>\n",
       "      <td>hardworker multitasking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Position  \\\n",
       "ApplicantID                                                      \n",
       "21                jawa situs web pengembang android pengembang   \n",
       "3367         mendukung mendukung mendukung mendukung menduk...   \n",
       "18385                                                     staf   \n",
       "21102                      magang staf magang staf magang staf   \n",
       "22239                     teknisi android permainan pengembang   \n",
       "26272            penjualan pemasaran staf freelance programmer   \n",
       "35606                                               internship   \n",
       "\n",
       "                                                JobDescription  \\\n",
       "ApplicantID                                                      \n",
       "21           cakupan responsibility menganalisa mengembangk...   \n",
       "3367         bertugas mengisi berisi situs web intern klien...   \n",
       "18385        penyelesaian jaringan perangkat keras mengemba...   \n",
       "21102        proyek perangkat android pkbl lapangan perangk...   \n",
       "22239        merawat instalasi jaringan komputer penarikan ...   \n",
       "26272        penjualan pemasaran menganalisis pasar penjual...   \n",
       "35606        situs web berdasarkan android devepment proyek...   \n",
       "\n",
       "                                                  Strengthness  \n",
       "ApplicantID                                                     \n",
       "21                                                              \n",
       "3367                            belajar motto dipelajari hidup  \n",
       "18385                                      cepat belajar ramah  \n",
       "21102                                 rajin suka belajar keras  \n",
       "22239                                 sabar teliti grusa grusu  \n",
       "26272        analisis kuat teliti mudah bersosialisasi adap...  \n",
       "35606                                  hardworker multitasking  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicant[df_applicant.JobDescription.str.contains(' android ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobTitle</th>\n",
       "      <th>Description</th>\n",
       "      <th>Requirement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>android programmer</td>\n",
       "      <td>mengembangkan android aplikasi milik integrasi...</td>\n",
       "      <td>usia maksimal minimal pendidikan sistem inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>android programmer</td>\n",
       "      <td>mengembangkan aplikasi android integrasinya la...</td>\n",
       "      <td>usia maksimal minimal pendidikan sistem inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>android programmer</td>\n",
       "      <td>mengembangkan aplikasi android integrasinya la...</td>\n",
       "      <td>usia maksimal minimal pendidikan sistem inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>android programmer</td>\n",
       "      <td>mengembangkan aplikasi android integrasinya la...</td>\n",
       "      <td>usia maksimal minimal pendidikan sistem inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>android programmer</td>\n",
       "      <td>mengembangkan aplikasi android integrasinya la...</td>\n",
       "      <td>usia maksimal minimal pendidikan sistem inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>android programmer</td>\n",
       "      <td>mengembangkan aplikasi android integrasinya la...</td>\n",
       "      <td>usia maksimal minimal pendidikan sistem inform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 JobTitle                                        Description  \\\n",
       "JobID                                                                          \n",
       "3      android programmer  mengembangkan android aplikasi milik integrasi...   \n",
       "156    android programmer  mengembangkan aplikasi android integrasinya la...   \n",
       "2736   android programmer  mengembangkan aplikasi android integrasinya la...   \n",
       "2738   android programmer  mengembangkan aplikasi android integrasinya la...   \n",
       "2848   android programmer  mengembangkan aplikasi android integrasinya la...   \n",
       "2996   android programmer  mengembangkan aplikasi android integrasinya la...   \n",
       "\n",
       "                                             Requirement  \n",
       "JobID                                                     \n",
       "3      usia maksimal minimal pendidikan sistem inform...  \n",
       "156    usia maksimal minimal pendidikan sistem inform...  \n",
       "2736   usia maksimal minimal pendidikan sistem inform...  \n",
       "2738   usia maksimal minimal pendidikan sistem inform...  \n",
       "2848   usia maksimal minimal pendidikan sistem inform...  \n",
       "2996   usia maksimal minimal pendidikan sistem inform...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job[df_job.Description.str.contains(' android ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 22:16:56,186 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=360, alpha=0.03>', 'datetime': '2023-04-18T22:16:56.186588', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n",
      "2023-04-18 22:16:56,196 : INFO : collecting all words and their counts\n",
      "2023-04-18 22:16:56,197 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-18 22:16:56,214 : INFO : collected 1732 word types from a corpus of 38772 raw words and 1008 sentences\n",
      "2023-04-18 22:16:56,215 : INFO : Creating a fresh vocabulary\n",
      "2023-04-18 22:16:56,226 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 734 unique words (42.38% of original 1732, drops 998)', 'datetime': '2023-04-18T22:16:56.225519', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-18 22:16:56,229 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 35359 word corpus (91.20% of original 38772, drops 3413)', 'datetime': '2023-04-18T22:16:56.229475', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-18 22:16:56,243 : INFO : deleting the raw counts dictionary of 1732 items\n",
      "2023-04-18 22:16:56,244 : INFO : sample=6e-05 downsamples 734 most-common words\n",
      "2023-04-18 22:16:56,245 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 8118.704769445668 word corpus (23.0%% of prior 35359)', 'datetime': '2023-04-18T22:16:56.245430', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-18 22:16:56,264 : INFO : estimated required memory for 734 words and 360 dimensions: 2480920 bytes\n",
      "2023-04-18 22:16:56,266 : INFO : resetting layer weights\n",
      "2023-04-18 22:16:56,271 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-18T22:16:56.271363', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'}\n",
      "2023-04-18 22:16:56,282 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 734 vocabulary and 360 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2 shrink_windows=True', 'datetime': '2023-04-18T22:16:56.282332', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "2023-04-18 22:16:56,353 : INFO : EPOCH 0: training on 38772 raw words (8082 effective words) took 0.1s, 143934 effective words/s\n",
      "2023-04-18 22:16:56,442 : INFO : EPOCH 1: training on 38772 raw words (8220 effective words) took 0.1s, 106889 effective words/s\n",
      "2023-04-18 22:16:56,518 : INFO : EPOCH 2: training on 38772 raw words (8010 effective words) took 0.1s, 123561 effective words/s\n",
      "2023-04-18 22:16:56,605 : INFO : EPOCH 3: training on 38772 raw words (8217 effective words) took 0.1s, 113651 effective words/s\n",
      "2023-04-18 22:16:56,697 : INFO : EPOCH 4: training on 38772 raw words (8203 effective words) took 0.1s, 109457 effective words/s\n",
      "2023-04-18 22:16:56,758 : INFO : EPOCH 5: training on 38772 raw words (8194 effective words) took 0.1s, 148475 effective words/s\n",
      "2023-04-18 22:16:56,831 : INFO : EPOCH 6: training on 38772 raw words (8157 effective words) took 0.1s, 126803 effective words/s\n",
      "2023-04-18 22:16:56,917 : INFO : EPOCH 7: training on 38772 raw words (8231 effective words) took 0.1s, 108191 effective words/s\n",
      "2023-04-18 22:16:57,004 : INFO : EPOCH 8: training on 38772 raw words (7990 effective words) took 0.1s, 105319 effective words/s\n",
      "2023-04-18 22:16:57,100 : INFO : EPOCH 9: training on 38772 raw words (8154 effective words) took 0.1s, 94842 effective words/s\n",
      "2023-04-18 22:16:57,318 : INFO : EPOCH 10: training on 38772 raw words (8080 effective words) took 0.1s, 92752 effective words/s\n",
      "2023-04-18 22:16:57,402 : INFO : EPOCH 11: training on 38772 raw words (8146 effective words) took 0.1s, 119501 effective words/s\n",
      "2023-04-18 22:16:57,478 : INFO : EPOCH 12: training on 38772 raw words (8070 effective words) took 0.1s, 129665 effective words/s\n",
      "2023-04-18 22:16:57,548 : INFO : EPOCH 13: training on 38772 raw words (8069 effective words) took 0.1s, 128066 effective words/s\n",
      "2023-04-18 22:16:57,637 : INFO : EPOCH 14: training on 38772 raw words (8074 effective words) took 0.1s, 103851 effective words/s\n",
      "2023-04-18 22:16:57,719 : INFO : EPOCH 15: training on 38772 raw words (8000 effective words) took 0.1s, 141301 effective words/s\n",
      "2023-04-18 22:16:57,778 : INFO : EPOCH 16: training on 38772 raw words (7930 effective words) took 0.1s, 153431 effective words/s\n",
      "2023-04-18 22:16:57,845 : INFO : EPOCH 17: training on 38772 raw words (8029 effective words) took 0.1s, 131793 effective words/s\n",
      "2023-04-18 22:16:57,944 : INFO : EPOCH 18: training on 38772 raw words (8188 effective words) took 0.1s, 126780 effective words/s\n",
      "2023-04-18 22:16:58,018 : INFO : EPOCH 19: training on 38772 raw words (8105 effective words) took 0.1s, 144356 effective words/s\n",
      "2023-04-18 22:16:58,084 : INFO : EPOCH 20: training on 38772 raw words (8233 effective words) took 0.1s, 150804 effective words/s\n",
      "2023-04-18 22:16:58,141 : INFO : EPOCH 21: training on 38772 raw words (8128 effective words) took 0.1s, 157246 effective words/s\n",
      "2023-04-18 22:16:58,203 : INFO : EPOCH 22: training on 38772 raw words (8050 effective words) took 0.1s, 152285 effective words/s\n",
      "2023-04-18 22:16:58,276 : INFO : EPOCH 23: training on 38772 raw words (8240 effective words) took 0.1s, 133413 effective words/s\n",
      "2023-04-18 22:16:58,344 : INFO : EPOCH 24: training on 38772 raw words (8119 effective words) took 0.1s, 139104 effective words/s\n",
      "2023-04-18 22:16:58,400 : INFO : EPOCH 25: training on 38772 raw words (8135 effective words) took 0.0s, 163085 effective words/s\n",
      "2023-04-18 22:16:58,452 : INFO : EPOCH 26: training on 38772 raw words (8127 effective words) took 0.0s, 171845 effective words/s\n",
      "2023-04-18 22:16:58,509 : INFO : EPOCH 27: training on 38772 raw words (8070 effective words) took 0.0s, 165242 effective words/s\n",
      "2023-04-18 22:16:58,576 : INFO : EPOCH 28: training on 38772 raw words (7979 effective words) took 0.1s, 139593 effective words/s\n",
      "2023-04-18 22:16:58,645 : INFO : EPOCH 29: training on 38772 raw words (7990 effective words) took 0.1s, 130850 effective words/s\n",
      "2023-04-18 22:16:58,698 : INFO : EPOCH 30: training on 38772 raw words (8065 effective words) took 0.0s, 167299 effective words/s\n",
      "2023-04-18 22:16:58,750 : INFO : EPOCH 31: training on 38772 raw words (8134 effective words) took 0.0s, 176219 effective words/s\n",
      "2023-04-18 22:16:58,817 : INFO : EPOCH 32: training on 38772 raw words (8138 effective words) took 0.1s, 140401 effective words/s\n",
      "2023-04-18 22:16:58,895 : INFO : EPOCH 33: training on 38772 raw words (8168 effective words) took 0.1s, 126103 effective words/s\n",
      "2023-04-18 22:16:58,953 : INFO : EPOCH 34: training on 38772 raw words (8017 effective words) took 0.1s, 154673 effective words/s\n",
      "2023-04-18 22:16:59,018 : INFO : EPOCH 35: training on 38772 raw words (7989 effective words) took 0.1s, 142408 effective words/s\n",
      "2023-04-18 22:16:59,100 : INFO : EPOCH 36: training on 38772 raw words (8134 effective words) took 0.1s, 119199 effective words/s\n",
      "2023-04-18 22:16:59,166 : INFO : EPOCH 37: training on 38772 raw words (8151 effective words) took 0.1s, 143801 effective words/s\n",
      "2023-04-18 22:16:59,218 : INFO : EPOCH 38: training on 38772 raw words (8142 effective words) took 0.0s, 172006 effective words/s\n",
      "2023-04-18 22:16:59,279 : INFO : EPOCH 39: training on 38772 raw words (8130 effective words) took 0.1s, 153272 effective words/s\n",
      "2023-04-18 22:16:59,339 : INFO : EPOCH 40: training on 38772 raw words (8141 effective words) took 0.1s, 151862 effective words/s\n",
      "2023-04-18 22:16:59,403 : INFO : EPOCH 41: training on 38772 raw words (8210 effective words) took 0.1s, 150605 effective words/s\n",
      "2023-04-18 22:16:59,465 : INFO : EPOCH 42: training on 38772 raw words (8059 effective words) took 0.1s, 154671 effective words/s\n",
      "2023-04-18 22:16:59,515 : INFO : EPOCH 43: training on 38772 raw words (8126 effective words) took 0.0s, 183017 effective words/s\n",
      "2023-04-18 22:16:59,578 : INFO : EPOCH 44: training on 38772 raw words (8142 effective words) took 0.1s, 156333 effective words/s\n",
      "2023-04-18 22:16:59,646 : INFO : EPOCH 45: training on 38772 raw words (8122 effective words) took 0.1s, 142375 effective words/s\n",
      "2023-04-18 22:16:59,707 : INFO : EPOCH 46: training on 38772 raw words (8011 effective words) took 0.1s, 144306 effective words/s\n",
      "2023-04-18 22:16:59,769 : INFO : EPOCH 47: training on 38772 raw words (8257 effective words) took 0.1s, 155181 effective words/s\n",
      "2023-04-18 22:16:59,827 : INFO : EPOCH 48: training on 38772 raw words (8183 effective words) took 0.1s, 161215 effective words/s\n",
      "2023-04-18 22:16:59,895 : INFO : EPOCH 49: training on 38772 raw words (8010 effective words) took 0.1s, 133445 effective words/s\n",
      "2023-04-18 22:16:59,960 : INFO : EPOCH 50: training on 38772 raw words (7938 effective words) took 0.1s, 141987 effective words/s\n",
      "2023-04-18 22:17:00,035 : INFO : EPOCH 51: training on 38772 raw words (8159 effective words) took 0.1s, 123088 effective words/s\n",
      "2023-04-18 22:17:00,097 : INFO : EPOCH 52: training on 38772 raw words (8175 effective words) took 0.1s, 154532 effective words/s\n",
      "2023-04-18 22:17:00,153 : INFO : EPOCH 53: training on 38772 raw words (8077 effective words) took 0.1s, 158672 effective words/s\n",
      "2023-04-18 22:17:00,217 : INFO : EPOCH 54: training on 38772 raw words (7989 effective words) took 0.1s, 144302 effective words/s\n",
      "2023-04-18 22:17:00,288 : INFO : EPOCH 55: training on 38772 raw words (7996 effective words) took 0.1s, 132079 effective words/s\n",
      "2023-04-18 22:17:00,349 : INFO : EPOCH 56: training on 38772 raw words (8306 effective words) took 0.1s, 157988 effective words/s\n",
      "2023-04-18 22:17:00,407 : INFO : EPOCH 57: training on 38772 raw words (8250 effective words) took 0.0s, 173450 effective words/s\n",
      "2023-04-18 22:17:00,460 : INFO : EPOCH 58: training on 38772 raw words (8068 effective words) took 0.0s, 170447 effective words/s\n",
      "2023-04-18 22:17:00,511 : INFO : EPOCH 59: training on 38772 raw words (8032 effective words) took 0.0s, 173798 effective words/s\n",
      "2023-04-18 22:17:00,565 : INFO : EPOCH 60: training on 38772 raw words (8367 effective words) took 0.0s, 173220 effective words/s\n",
      "2023-04-18 22:17:00,620 : INFO : EPOCH 61: training on 38772 raw words (8177 effective words) took 0.0s, 168959 effective words/s\n",
      "2023-04-18 22:17:00,676 : INFO : EPOCH 62: training on 38772 raw words (8144 effective words) took 0.0s, 171105 effective words/s\n",
      "2023-04-18 22:17:00,729 : INFO : EPOCH 63: training on 38772 raw words (8151 effective words) took 0.0s, 169773 effective words/s\n",
      "2023-04-18 22:17:00,781 : INFO : EPOCH 64: training on 38772 raw words (8054 effective words) took 0.0s, 172409 effective words/s\n",
      "2023-04-18 22:17:00,831 : INFO : EPOCH 65: training on 38772 raw words (8045 effective words) took 0.0s, 178015 effective words/s\n",
      "2023-04-18 22:17:00,882 : INFO : EPOCH 66: training on 38772 raw words (8034 effective words) took 0.0s, 178122 effective words/s\n",
      "2023-04-18 22:17:00,933 : INFO : EPOCH 67: training on 38772 raw words (8099 effective words) took 0.0s, 186261 effective words/s\n",
      "2023-04-18 22:17:00,983 : INFO : EPOCH 68: training on 38772 raw words (8164 effective words) took 0.0s, 180603 effective words/s\n",
      "2023-04-18 22:17:01,031 : INFO : EPOCH 69: training on 38772 raw words (8091 effective words) took 0.0s, 203163 effective words/s\n",
      "2023-04-18 22:17:01,083 : INFO : EPOCH 70: training on 38772 raw words (8134 effective words) took 0.0s, 194847 effective words/s\n",
      "2023-04-18 22:17:01,132 : INFO : EPOCH 71: training on 38772 raw words (8214 effective words) took 0.0s, 185540 effective words/s\n",
      "2023-04-18 22:17:01,180 : INFO : EPOCH 72: training on 38772 raw words (8103 effective words) took 0.0s, 185545 effective words/s\n",
      "2023-04-18 22:17:01,228 : INFO : EPOCH 73: training on 38772 raw words (8198 effective words) took 0.0s, 190661 effective words/s\n",
      "2023-04-18 22:17:01,272 : INFO : EPOCH 74: training on 38772 raw words (8061 effective words) took 0.0s, 212055 effective words/s\n",
      "2023-04-18 22:17:01,343 : INFO : EPOCH 75: training on 38772 raw words (8155 effective words) took 0.1s, 128347 effective words/s\n",
      "2023-04-18 22:17:01,399 : INFO : EPOCH 76: training on 38772 raw words (8154 effective words) took 0.0s, 175353 effective words/s\n",
      "2023-04-18 22:17:01,447 : INFO : EPOCH 77: training on 38772 raw words (8132 effective words) took 0.0s, 186276 effective words/s\n",
      "2023-04-18 22:17:01,497 : INFO : EPOCH 78: training on 38772 raw words (7997 effective words) took 0.0s, 175861 effective words/s\n",
      "2023-04-18 22:17:01,546 : INFO : EPOCH 79: training on 38772 raw words (8070 effective words) took 0.0s, 181735 effective words/s\n",
      "2023-04-18 22:17:01,596 : INFO : EPOCH 80: training on 38772 raw words (8036 effective words) took 0.0s, 178848 effective words/s\n",
      "2023-04-18 22:17:01,642 : INFO : EPOCH 81: training on 38772 raw words (8134 effective words) took 0.0s, 198858 effective words/s\n",
      "2023-04-18 22:17:01,684 : INFO : EPOCH 82: training on 38772 raw words (8017 effective words) took 0.0s, 203680 effective words/s\n",
      "2023-04-18 22:17:01,733 : INFO : EPOCH 83: training on 38772 raw words (8130 effective words) took 0.0s, 212017 effective words/s\n",
      "2023-04-18 22:17:01,782 : INFO : EPOCH 84: training on 38772 raw words (8038 effective words) took 0.0s, 197192 effective words/s\n",
      "2023-04-18 22:17:01,830 : INFO : EPOCH 85: training on 38772 raw words (8134 effective words) took 0.0s, 187074 effective words/s\n",
      "2023-04-18 22:17:01,877 : INFO : EPOCH 86: training on 38772 raw words (8000 effective words) took 0.0s, 188111 effective words/s\n",
      "2023-04-18 22:17:01,961 : INFO : EPOCH 87: training on 38772 raw words (8193 effective words) took 0.1s, 104788 effective words/s\n",
      "2023-04-18 22:17:02,098 : INFO : EPOCH 88: training on 38772 raw words (8135 effective words) took 0.1s, 161128 effective words/s\n",
      "2023-04-18 22:17:02,160 : INFO : EPOCH 89: training on 38772 raw words (8201 effective words) took 0.0s, 176831 effective words/s\n",
      "2023-04-18 22:17:02,162 : INFO : Word2Vec lifecycle event {'msg': 'training on 3489480 raw words (730101 effective words) took 5.9s, 124191 effective words/s', 'datetime': '2023-04-18T22:17:02.162398', 'gensim': '4.3.0', 'python': '3.11.0 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(730101, 3489480)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Word2Vec(min_count=10, window=2, vector_size=360, sample=6e-5,  alpha=0.03,  min_alpha=0.0007,  negative=20, workers=cores-1)\n",
    "\n",
    "model.build_vocab(df_job.Description.map(str.split).values, progress_per=10000)\n",
    "model.train(df_job.Description.map(str.split).values, total_examples=model.corpus_count, epochs=90, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hukum' in list(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('utamanya', 0.8720858693122864),\n",
       " ('mengimplementasikan', 0.8421112298965454),\n",
       " ('pengoperasian', 0.7789627313613892),\n",
       " ('prima', 0.7574916481971741),\n",
       " ('disyaratkan', 0.7399214506149292),\n",
       " ('memenuhi', 0.7397032380104065),\n",
       " ('baku', 0.7390581369400024),\n",
       " ('peralatan', 0.7315595746040344),\n",
       " ('keselamatan', 0.7274753451347351),\n",
       " ('seminggu', 0.7268062233924866)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
